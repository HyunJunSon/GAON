# -*- coding: utf-8 -*-
import json, uuid, re, unicodedata
from pathlib import Path
import fitz  # pip install pymupdf

ROOT     = Path(__file__).resolve().parent
PDF_DIR  = ROOT / "pdfë³€í™˜_downloads"
OUT_DIR  = ROOT / "toc_out"
OUT_DIR.mkdir(parents=True, exist_ok=True)
ALL_JSON = OUT_DIR / "book_toc_all.jsonl"

SAFE = re.compile(r'[\\/:*?"<>|]+')

# ðŸ“Œ ë¸”ëž™ë¦¬ìŠ¤íŠ¸ ê°•í™”: í”„ë¡¤ë¡œê·¸/ë¨¸ë¦¬ë§/ì²˜ìŒìœ¼ë¡œ/ì¶”ì²œì‚¬ë„ ì œì™¸
# ðŸ“Œ ì •í™• ì¼ì¹˜ ë¸”ëž™ë¦¬ìŠ¤íŠ¸ (ì˜¤íƒ ë°©ì§€ìš©)
BLACK_TITLES = {
    "ì°¨ë¡€", "ëª©ì°¨", "íŒê¶Œ", "í‘œì§€",
    "í”„ë¡¤ë¡œê·¸", "ë¨¸ë¦¬ë§", "ì¶”ì²œì‚¬",
    "ì €ìž ì†Œê°œ", "ì—¬ëŠ” ë§",
    "ì±…ì˜ ì‹œìž‘", "ì²˜ìŒìœ¼ë¡œ",
}

# ë¶™ì—¬ì“°ê¸° ë“± ìžì£¼ ë‚˜ì˜¤ëŠ” ë³€í˜• êµì •
NORMALIZE_MAP = {
    "ì €ìžì†Œê°œ": "ì €ìž ì†Œê°œ",
    "ì—¬ëŠ”ë§": "ì—¬ëŠ” ë§",
}

def is_blacklisted_title(raw_title: str) -> bool:
    # ë²ˆí˜¸/ë¶ˆë¦¿ ì œê±° í¬í•¨í•œ ë„ˆì˜ norm_title ì´ìš©
    t = norm_title(raw_title)
    # ë¶™ì—¬ì“°ê¸° ë³´ì •
    t = NORMALIZE_MAP.get(t, t)
    # ì •í™• ì¼ì¹˜ë¡œë§Œ ë¸”ëž™ ì²˜ë¦¬
    return t in BLACK_TITLES


def nfkc(s: str) -> str:
    return unicodedata.normalize("NFKC", s or "")

def safe_name(s: str) -> str:
    return SAFE.sub("_", nfkc(s)).strip()

def norm_title(s: str) -> str:
    s = nfkc(s).strip()

    # PART n / ì œnìž¥ / ì•žë²ˆí˜¸ 01. 1.1. ë“± ì œê±°
    s = re.sub(r"^\s*(PART|Part)\s*\d+\s*[:.\-]?\s*", "", s)
    s = re.sub(r"^\s*ì œ\s*\d+\s*ìž¥\s*[:.\-]?\s*", "", s)
    s = re.sub(r"^\s*\d+(\.\d+)*\s*[:.\-]?\s*", "", s)

    # ì„ í–‰ ë¶ˆë¦¿ë¥˜(ì—¬ëŸ¬ ìœ ë‹ˆì½”ë“œ) ì œê±°
    s = re.sub(r"^[\u00B7\u2022\u2027\u2219\-\â€“\â€”\.\s]+", "", s)

    # ì¤‘ë³µ ê³µë°± ì •ë¦¬
    s = re.sub(r"\s+", " ", s).strip()
    return s

def compute_ranges(toc, last_page: int):
    out = []
    for i, (lvl, title, p) in enumerate(toc):
        # PyMuPDF TOC ê°’ ì •ê·œí™”
        lvl = int(lvl)
        title = nfkc(title).strip()
        s = max(1, int(p))
        e = int(toc[i + 1][2] - 1) if i + 1 < len(toc) else int(last_page)

        # íŽ˜ì´ì§€ ë³´ì •
        if e < s:
            # ë‹¤ìŒ ë¶ë§ˆí¬ê°€ ì—­ì „ì¼ ë•Œ 0í­ìœ¼ë¡œ ë³´ì •
            e = s
        if e > last_page:
            e = last_page

        out.append((lvl, title, s, e))
    return out

def make_book_id(title: str) -> str:
    NAMESPACE = uuid.UUID("11111111-1111-1111-1111-111111111111")
    key = re.sub(r"\s+", " ", nfkc(title).strip().lower())
    return str(uuid.uuid5(NAMESPACE, key))

def make_toc_id(book_id: str, title: str, page_start: int) -> str:
    NAMESPACE = uuid.UUID("00000000-0000-0000-0000-000000000000")
    return str(uuid.uuid5(NAMESPACE, f"{book_id}|{nfkc(title)}|{int(page_start)}"))

def run():
    pdfs = sorted(list(PDF_DIR.glob("*.pdf")) + list(PDF_DIR.glob("*.PDF")))
    if not pdfs:
        raise FileNotFoundError(f"âŒ PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {PDF_DIR}")

    # í•©ë³¸ ì¤‘ë³µ ë°©ì§€ ì„¸íŠ¸(ì„¸ì…˜ ë‚´)
    seen_all = set()  # (book_id, toc_id)

    with open(ALL_JSON, "w", encoding="utf-8") as fall:
        for pdf in pdfs:
            book_name = pdf.stem
            book_id   = make_book_id(book_name)
            out_json  = OUT_DIR / f"book_toc_{safe_name(book_name)}.jsonl"

            print(f"\nðŸ“˜ {book_name} ì²˜ë¦¬ ì¤‘...")

            try:
                doc = fitz.open(str(pdf))
                toc = doc.get_toc(simple=True)
                if not toc:
                    print(f"[WARN] TOC ì—†ìŒ: {pdf.name}")
                    continue

                ranges = compute_ranges(toc, doc.page_count)
                stack  = []  # [(level, toc_id)]
                order  = 0

                seen_book = set()  # (lvl, title, page_start) ì¤‘ë³µ ë°©ì§€

                with open(out_json, "w", encoding="utf-8") as fw:
                    for lvl, title, s, e in ranges:
                        key_local = (lvl, title, s)
                        if key_local in seen_book:
                            # ê°™ì€ í•­ëª©ì´ ì—¬ëŸ¬ ë²ˆ ì°ížˆëŠ” ê²½ìš° ìŠ¤í‚µ
                            continue
                        seen_book.add(key_local)

                        order += 1
                        t_norm  = norm_title(title)
                        toc_id  = make_toc_id(book_id, title, s)

                        # ë¶€ëª¨ ì—°ê²°(ë£¨íŠ¸ ë³´í˜¸)
                        while stack and int(stack[-1][0]) >= int(lvl):
                            stack.pop()
                        parent_id = stack[-1][1] if stack else None
                        stack.append((int(lvl), toc_id))

                        rec = {
                            "book_id": book_id,
                            "book_title": nfkc(book_name),
                            "toc_id": toc_id,
                            "level": int(lvl),
                            "title": nfkc(title),
                            "norm_title": t_norm,
                            "parent_toc_id": parent_id,
                            "page_start": int(s),
                            "page_end": int(e),
                            "order_ix": int(order),
                            "source_file": pdf.name,
                            "is_blacklisted": is_blacklisted_title(title),
                        }

                        # í•©ë³¸ ì¤‘ë³µ ë°©ì§€
                        k = (book_id, toc_id)
                        if k not in seen_all:
                            seen_all.add(k)
                            fall.write(json.dumps(rec, ensure_ascii=False) + "\n")

                        fw.write(json.dumps(rec, ensure_ascii=False) + "\n")

                print(f"âœ… ì €ìž¥ ì™„ë£Œ: {out_json}")

            except Exception as ex:
                print(f"[ERROR] {pdf.name}: {ex}")
            finally:
                try:
                    doc.close()
                except:
                    pass

    print(f"\nðŸ“¦ í•©ë³¸ ì €ìž¥: {ALL_JSON}")

if __name__ == "__main__":
    run()
