# backend/app/llm/agent/Feedback/nodes.py
# -*- coding: utf-8 -*-

from __future__ import annotations
from dataclasses import dataclass
from typing import TYPE_CHECKING, Dict, Any, List

import os
import json
import psycopg2
import psycopg2.extras as extras
import pandas as pd
from sqlalchemy.orm import Session
from openai import OpenAI
from langchain_openai import ChatOpenAI

from app.core.database import engine
from app.core.config import settings
from app.llm.agent.crud import get_analysis_by_conv_id, save_feedback

if TYPE_CHECKING:
    from .graph_feedback import FeedbackState

# 1ï¸âƒ£ summary + ì ìˆ˜ ë¡œë”©
@dataclass
class SummaryLoaderNode:
    verbose: bool = True

    def __call__(self, state: "FeedbackState") -> "FeedbackState":
        db: Session = state.db
        conv_id = state.conv_id

        if not db:
            raise ValueError("âŒ SummaryLoaderNode: db ì„¸ì…˜ ì—†ìŒ")
        if not conv_id:
            raise ValueError("âŒ SummaryLoaderNode: conv_id ì—†ìŒ")

        row = get_analysis_by_conv_id(db, conv_id)
        if not row:
            raise ValueError(f"âŒ analysis_result ì—†ìŒ: conv_id={conv_id}")

        state.analysis_row = row
        state.analysis_id = row["analysis_id"]
        state.summary = (row.get("summary") or "").strip()
        state.score = float(row.get("score", 0.0))
        state.confidence_score = float(row.get("confidence_score", 0.0))

        if not state.summary:
            raise ValueError("âŒ SummaryLoaderNode: summary ë¹„ì–´ ìˆìŒ")

        if self.verbose:
            print("\nğŸ“¥ [SummaryLoaderNode] ë¶„ì„ ê²°ê³¼ ë¡œë”© ì™„ë£Œ")
            print(f"   â†’ analysis_id: {state.analysis_id}")
            print(f"   â†’ score={state.score:.2f}, confidence={state.confidence_score:.2f}")
            print(f"   â†’ summary ê¸¸ì´={len(state.summary)}ì")

        return state

# 2ï¸âƒ£ summary â†’ ì±… ê²€ìƒ‰ìš© ì¿¼ë¦¬ ë³€í™˜ (LLM)
@dataclass
class SummaryToBookQueryNode:
    verbose: bool = True

    def __call__(self, state: "FeedbackState") -> "FeedbackState":
        summary = state.summary

        if not summary:
            raise ValueError("âŒ SummaryToBookQueryNode: summary ì—†ìŒ")

        llm = ChatOpenAI(
            model="gpt-4o-mini",
            api_key=settings.openai_api_key,
        )

        prompt = f"""
ë„ˆëŠ” ìƒë‹´ ê´€ë ¨ ì±…ê³¼ ëŒ€í™”ë²• ì±…ì„ ì˜ ì•„ëŠ” 'ì „ë¬¸ ì‚¬ì„œ'ì´ë‹¤.

ì•„ë˜ í…ìŠ¤íŠ¸ëŠ” í•­ìƒ ë‹¤ìŒ êµ¬ì¡°ë¥¼ ê°€ì§„ 'ëŒ€í™” ë¶„ì„ ë¦¬í¬íŠ¸'ì´ë‹¤:

1) ë§í•˜ê¸° ì ìˆ˜ / ë‹¨ì–´ ìˆ˜ / ë¬¸ì¥ ê¸¸ì´ / ê³ ìœ  ë‹¨ì–´ / ìì£¼ ì“°ëŠ” ë‹¨ì–´ ë“± **í†µê³„/ì ìˆ˜**
2) ë§íˆ¬ ë¶„ì„ (ì˜ˆ: ë°˜ë§/ì¡´ëŒ“ë§, í‘œí˜„ ìŠ¤íƒ€ì¼, ë¬¸ë²• ë“±)
3) ê°ì •/ì„±í–¥ ë¶„ì„ (ì˜ˆ: ê°€ì¡±ì— ëŒ€í•œ ì• ì •, ìƒì‹¤ê°, ë¶ˆì•ˆ, ìš°ìš¸, ë¶„ë…¸, íšŒí”¼, ê°œë°©ì„± ë“±)
4) ì¢…í•© í‰ê°€ (ê°•ì  / ê°œì„ ì  / ì¶”ì²œ ì‚¬í•­)

[ëŒ€í™” ë¶„ì„ ë¦¬í¬íŠ¸]
\"\"\"{summary}\"\"\"

ì„ë² ë”©ëœ ì±… í…ìŠ¤íŠ¸ëŠ” í•­ìƒ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ì„ ê°€ì§„ë‹¤:

[ëŒ€ì œëª© > ì¤‘ì œëª© > ì†Œì œëª©] ë³¸ë¬¸ ë‚´ìš©...

ë”°ë¼ì„œ, ë„¤ê°€ ë§Œë“¤ì–´ì•¼ í•  ê²€ìƒ‰ ì¿¼ë¦¬ë„ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ì—¬ì•¼ í•œë‹¤:

- í•œ ì¤„: 'ëŒ€ì œëª© ë˜ëŠ” (ëŒ€ì œëª© > ì¤‘ì œëª©)ì²˜ëŸ¼ ì“¸ ìˆ˜ ìˆëŠ” ì§§ì€ ì œëª© ë¬¸ì¥'
- ê·¸ ì•„ë˜: ê´€ë ¨ëœ ìƒë‹´/ëŒ€í™” ìƒí™©ì„ 2~4ë¬¸ì¥ ì •ë„ë¡œ ì„¤ëª…í•˜ëŠ” ë³¸ë¬¸

### 1) counsel_query (ìƒë‹´ì±…ìš©)
- ì´ ë‚´ë‹´ìì˜ ì‹¬ë¦¬, ê°ì • íŒ¨í„´, ê´€ê³„, ìƒì‹¤Â·ë¶ˆì•ˆÂ·ì• ì°©, ì˜ˆë¯¼í•¨ ë“±ì„ ë°˜ì˜í•´
  'ìƒë‹´/ì‹¬ë¦¬ ì±…ì˜ ì¥ ì œëª© + ë³¸ë¬¸'ì²˜ëŸ¼ ì¿¼ë¦¬ë¥¼ ë§Œë“¤ì–´ë¼.

ì˜ˆì‹œ ìŠ¤íƒ€ì¼:
"í˜•ì œ ìƒì‹¤ì„ ê²ªì€ ì•„ì´ì˜ ì• ë„ì™€ ê°€ì¡±ì— ëŒ€í•œ ë¶ˆì•ˆ
ì–¸ë‹ˆë¥¼ êµí†µì‚¬ê³ ë¡œ ìƒì€ ì•„ì´ê°€ ê°€ì¡±ê³¼ì˜ ì¼ìƒ ëŒ€í™”ì—ì„œëŠ” ë°ê³  ì˜ ì§€ë‚´ëŠ” ëª¨ìŠµì„ ë³´ì´ì§€ë§Œ, ë§ˆìŒ í•œí¸ìœ¼ë¡œëŠ” ë¶€ëª¨ê°€ ìì‹ ì„ ë– ë‚ ê¹Œ ê±±ì •í•˜ë©° ì•…ëª½ê³¼ ê°€ìŠ´ ë‘ê·¼ê±°ë¦¼ì„ ê²ªê³  ìˆë‹¤. ì´ëŸ° ì•„ì´ì˜ ìŠ¬í””ê³¼ ë¶ˆì•ˆì„ ì–´ë–»ê²Œ ì´í•´í•˜ê³ , ì• ë„ ê³¼ì •ê³¼ ì• ì°©ì„ ë‹¤ë£¨ì–´ ì¤„ ê²ƒì¸ì§€ì— ëŒ€í•œ ìƒë‹´ ì´ë¡ ê³¼ ì‚¬ë¡€ê°€ í•„ìš”í•˜ë‹¤."

### 2) talk_query (ëŒ€í™”ì±…ìš©)
- ì´ ë‚´ë‹´ìì™€ ëŒ€í™”í•  ë•Œ í•„ìš”í•œ ë§í•˜ê¸°/ë“£ê¸°/ì§ˆë¬¸ ê¸°ìˆ ì„,
  'ëŒ€í™”ë²• ì±…ì˜ ì¥ ì œëª© + ë³¸ë¬¸'ì²˜ëŸ¼ ì¿¼ë¦¬ë¡œ ë§Œë“¤ì–´ë¼.

ì˜ˆì‹œ ìŠ¤íƒ€ì¼:
"ìƒì‹¤ì„ ê²½í—˜í•œ ì•„ì´ì—ê²Œ ì•ˆì „ê°ì„ ì£¼ëŠ” ì§ˆë¬¸ê³¼ ê³µê° ëŒ€í™”ë²•
ì–¸ë‹ˆë¥¼ ìƒì€ ì´í›„ ë¶€ëª¨ë¥¼ ìƒì„ê¹Œ ê±±ì •í•˜ì§€ë§Œ ê²‰ìœ¼ë¡œëŠ” ë°ê²Œ ì§€ë‚´ëŠ” ì•„ì´ì—ê²Œ, ìƒë‹´ìë‚˜ ë¶€ëª¨ê°€ ì–´ë–¤ ë§íˆ¬ì™€ ì§ˆë¬¸ìœ¼ë¡œ ë§ˆìŒì„ ì—´ê²Œ ë„ì™€ì¤„ ìˆ˜ ìˆì„ì§€ ê³ ë¯¼ëœë‹¤. ì•„ì´ê°€ ëŠë¼ëŠ” ìŠ¬í””ê³¼ ë¶ˆì•ˆì„ ì¡´ì¤‘í•˜ë©´ì„œë„ ê¸ì •ì ì¸ ê²½í—˜(ê°€ì¡±ê³¼ì˜ ì‹œê°„, ì¹œêµ¬ì™€ì˜ ë†€ì´, ìœ íŠœë¸Œ ê¿ˆ)ì„ í™œìš©í•´ ì•ˆì „ê°ì„ ì „í•˜ê³ , ê°ì •ì„ ë§ë¡œ í‘œí˜„í•˜ëŠ” ì—°ìŠµì„ ë•ëŠ” êµ¬ì²´ì ì¸ ê³µê°Â·ê²½ì²­Â·ì§ˆë¬¸ ëŒ€í™”ë²•ì´ í•„ìš”í•˜ë‹¤."

ì£¼ì˜:
- ì ìˆ˜/ë‹¨ì–´ ìˆ˜/ë¬¸ì¥ ê¸¸ì´ ê°™ì€ í†µê³„ëŠ” ë¬´ì‹œí•˜ê³ ,
  ê°ì •Â·ì„±í–¥Â·ê°•ì Â·ê°œì„ ì  ì„¤ëª…ì—ë§Œ ì§‘ì¤‘í•´ì„œ ì£¼ì œë¥¼ ë½‘ì•„ë¼.
- ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ë‹µí•´ì•¼ í•œë‹¤:

{{
  "counsel_query": "ìƒë‹´ì±… ê²€ìƒ‰ìš©: [ì œëª©\\në³¸ë¬¸...] í˜•íƒœì˜ ë¬¸ìì—´",
  "talk_query": "ëŒ€í™”ì±… ê²€ìƒ‰ìš©: [ì œëª©\\në³¸ë¬¸...] í˜•íƒœì˜ ë¬¸ìì—´"
}}
"""

        if self.verbose:
            print("\nğŸ§  [SummaryToBookQueryNode] ì±… ê²€ìƒ‰ìš© ì¿¼ë¦¬ ìƒì„± ì¤‘...")

        resp = llm.invoke(prompt)
        content = resp.content if hasattr(resp, "content") else str(resp)

        try:
            content = content.strip()

            # 1) "json\n{...}" í˜•ì‹ ì²˜ë¦¬
            if content.lower().startswith("json"):
                # ì²« ì¤„ "json" ë–¼ê³  ë‚˜ë¨¸ì§€ ì „ì²´
                parts = content.split("\n", 1)
                if len(parts) == 2:
                    content = parts[1].strip()

            # 2) ```json ... ``` ê°™ì€ ì½”ë“œë¸”ë¡ ì²˜ë¦¬
            if "```" in content:
                # ì˜ˆ: ```json\n{...}\n``` í˜•íƒœ â†’ ì¤‘ê°„ ë¶€ë¶„ë§Œ
                chunks = content.split("```")
                # ê¸¸ì´ì— ë”°ë¼ ì•ˆì „í•˜ê²Œ ê°€ìš´ë° JSON ë¶€ë¶„ì„ ê³ ë¥´ê¸°
                if len(chunks) >= 3:
                    content = chunks[1].strip()
                else:
                    content = chunks[-1].strip()

            data = json.loads(content)
        except Exception as e:
            print(f"   âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            print(f"   ì›ë³¸ ì‘ë‹µ ì¼ë¶€: {content[:200]}...")
            data = {
                "counsel_query": summary,
                "talk_query": summary,
            }

        state.counsel_query = (data.get("counsel_query") or summary).strip()
        state.talk_query = (data.get("talk_query") or summary).strip()

        if self.verbose:
            print("   âœ… counsel_query:", state.counsel_query[:80], "...")
            print("   âœ… talk_query:", state.talk_query[:80], "...")

        return state

# 3ï¸âƒ£ ideal_answerì—ì„œ ìƒë‹´/ëŒ€í™”ë²• RAG + JSON ì¡°ì–¸ + feedback ì €ì¥
@dataclass
class RAGAndAdviceNode:
    verbose: bool = True

    def _make_query_embedding(self, client: OpenAI, text: str, model="text-embedding-3-small") -> list:
        t = (text or "").strip()
        if not t:
            raise ValueError("query is empty")
        return client.embeddings.create(model=model, input=[t]).data[0].embedding

    def _knn_search(
        self,
        conn,
        qvec: list,
        table: str,
        limit: int = 50,
        for_counsel: bool | None = None,
    ):
        # for_counsel:
        #   True  â†’ ìƒë‹´ ì±…ë§Œ
        #   False â†’ ìƒë‹´ ì•„ë‹Œ ì±…ë§Œ
        #   None  â†’ ì „ì²´
        where = ""
        if for_counsel is True:
            where = "WHERE book_title LIKE '%%ìƒë‹´%%'"
        elif for_counsel is False:
            where = "WHERE (book_title NOT LIKE '%%ìƒë‹´%%' OR book_title IS NULL)"

        sql = f"""
          SELECT snippet_id,
                 section_id,
                 canonical_path,
                 chunk_ix,
                 page_start,
                 page_end,
                 citation,
                 full_text,
                 book_title,
                 (embedding <=> %s::vector) AS distance
          FROM {table}
          {where}
          ORDER BY distance
          LIMIT %s
        """
        with conn.cursor(cursor_factory=extras.RealDictCursor) as cur:
            # âš ï¸ ì—¬ê¸° íŒŒë¼ë¯¸í„°ëŠ” ë‘ ê°œë§Œ!
            cur.execute(sql, (qvec, limit))
            return cur.fetchall()

    def _fetch_full_sections(self, conn, table: str, section_ids: list[str]) -> list[dict]:
        if not section_ids:
            return []

        sql = f"""
          SELECT section_id, canonical_path, chunk_ix,
                 page_start, page_end, citation, full_text, book_title
          FROM {table}
          WHERE section_id = ANY(%s)
          ORDER BY section_id, chunk_ix, page_start, page_end
        """
        with conn.cursor(cursor_factory=extras.RealDictCursor) as cur:
            cur.execute(sql, (section_ids,))
            rows = cur.fetchall()

        by: Dict[str, Any] = {}
        for r in rows:
            g = by.setdefault(r["section_id"], {
                "section_id": r["section_id"],
                "canonical_path": r["canonical_path"],
                "book_title": r.get("book_title"),
                "snippets": [],
                "citations": set(),
            })
            g["snippets"].append(r)
            if r.get("citation"):
                g["citations"].add(r["citation"])

        sections = []
        for sec in by.values():
            text = "\n\n".join(x["full_text"] for x in sec["snippets"] if x.get("full_text"))
            sections.append({
                "section_id": sec["section_id"],
                "canonical_path": sec["canonical_path"],
                "book_title": sec["book_title"],
                "text": text.strip(),
                "citations": sorted(sec["citations"]),
            })
        return sections

    def _build_sections_with_filter(
        self,
        qvec: list,
        table: str,
        sim_threshold: float,
        for_counsel: bool | None = None,
    ) -> List[Dict[str, Any]]:
        conn = engine.raw_connection()
        try:
            rows = self._knn_search(conn, qvec, table=table, limit=50, for_counsel=for_counsel)
        finally:
            conn.close()

        if self.verbose:
            print(f"\nğŸ” [RAG] knn ê²°ê³¼ {len(rows)}ê°œ (for_counsel={for_counsel})")
            for r in rows[:10]:
                d = float(r["distance"])
                sim = 1.0 - d
                print(
                    f"   section_id={r['section_id']}, "
                    f"book_title={r.get('book_title')}, "
                    f"distance={d:.4f}, sim={sim:.4f}"
                )

        filtered_ids = set()
        best_dist_map: Dict[str, float] = {}

        for r in rows:
            d = r.get("distance")
            if d is None:
                continue
            d = float(d)
            sim = 1.0 - d

            if sim < sim_threshold:
                continue

            sid = r["section_id"]
            filtered_ids.add(sid)
            if sid not in best_dist_map or d < best_dist_map[sid]:
                best_dist_map[sid] = d

        if self.verbose:
            print(f"   ğŸ” sim_threshold={sim_threshold}, í†µê³¼ section ìˆ˜={len(filtered_ids)}")

        if not filtered_ids:
            return []

        conn2 = engine.raw_connection()
        try:
            sections = self._fetch_full_sections(conn2, table, sorted(filtered_ids))
        finally:
            conn2.close()

        for s in sections:
            s["best_dist"] = best_dist_map.get(s["section_id"])

        sections.sort(
            key=lambda z: (
                float("inf") if z.get("best_dist") is None else z["best_dist"]
            )
        )
        return sections[:6]


    def __call__(self, state: "FeedbackState") -> "FeedbackState":
        API_KEY = os.getenv("OPENAI_API_KEY") or settings.openai_api_key
        TABLE   = os.getenv("IDEAL_ANSWER_TABLE") or "ideal_answer"
        SIM_TH  = float(os.getenv("RAG_SIM_THRESHOLD") or 0.45)  # ìœ ì‚¬ë„ 0.45 ì´ìƒë§Œ ì‚¬ìš©

        if not API_KEY:
            raise ValueError("âŒ OPENAI_API_KEY í•„ìš”")

        analysis_id = state.analysis_id
        summary = state.summary
        counsel_query = state.counsel_query or summary
        talk_query = state.talk_query or summary
        db: Session = state.db
        conversation_df = state.conversation_df

        if not analysis_id:
            raise ValueError("âŒ RAGAndAdviceNode: analysis_id ì—†ìŒ")
        if not summary:
            raise ValueError("âŒ RAGAndAdviceNode: summary ì—†ìŒ")
        if not db:
            raise ValueError("âŒ RAGAndAdviceNode: db ì„¸ì…˜ ì—†ìŒ")

        client = OpenAI(api_key=API_KEY)

        # 1) ì¿¼ë¦¬ ì„ë² ë”©
        qvec_counsel = self._make_query_embedding(client, counsel_query)
        qvec_talk    = self._make_query_embedding(client, talk_query)

        # 2) ideal_answerì—ì„œ ì„¹ì…˜ ê°€ì ¸ì˜¤ê¸° (ìœ ì‚¬ë„ 0.45 ì´ìƒë§Œ)
        sections_cand_counsel = self._build_sections_with_filter(
            qvec_counsel, TABLE, SIM_TH, for_counsel=True
        )
        sections_cand_talk    = self._build_sections_with_filter(
            qvec_talk,    TABLE, SIM_TH, for_counsel=False
        )
        
        # 3)ì´ì œëŠ” ì´ë¯¸ KNNì—ì„œ ìƒë‹´/ë¹„ìƒë‹´ ë‚˜ëˆ ì¡Œìœ¼ë‹ˆê¹Œ ê·¸ëŒ€ë¡œ ì”€
        counsel_sections = sections_cand_counsel
        talk_sections    = sections_cand_talk

        state.counsel_sections = counsel_sections
        state.talk_sections    = talk_sections

        # 4) ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ ë§Œë“¤ê¸°
        def ctx_block(prefix: str, sections: List[Dict[str, Any]]) -> str:
            if not sections:
                return f"(ê´€ë ¨ {prefix} ë¬¸ë§¥ ì—†ìŒ)"
            blocks = []
            for i, s in enumerate(sections, 1):
                txt = s["text"]
                cite = "; ".join(s["citations"]) or "(no explicit page)"
                title = s.get("book_title") or ""
                blocks.append(
                    f"[{prefix} Context {i}] {title} / {s['canonical_path']}\n"
                    f"{txt}\n(ì¶œì²˜: {cite})"
                )
            return "\n\n".join(blocks)

        counsel_ctx_str = ctx_block("ìƒë‹´", counsel_sections)
        talk_ctx_str    = ctx_block("ëŒ€í™”", talk_sections)

        # 5) LLM JSON ì¡°ì–¸ ìƒì„±
        llm = ChatOpenAI(model="gpt-4o-mini", api_key=API_KEY)

        if conversation_df is not None and not conversation_df.empty:
            conv_text = "\n".join(
                f"[ì°¸ì„ì {row['speaker']}] {row['text']}"
                for _, row in conversation_df.iterrows()
            )[:4000]
        else:
            conv_text = "(ì›ë³¸ ëŒ€í™”ëŠ” ìƒëµë¨)"

        prompt = f"""
ë‹¹ì‹ ì€ ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì§€ê¸ˆ ë§Œë“œëŠ” ë¦¬í¬íŠ¸ëŠ”
'ë‚´ë‹´ìì—ê²Œ ë“¤ë ¤ì¤„ ìˆ˜ ìˆëŠ” í”¼ë“œë°±'ì„ ì •ë¦¬í•œ ê²ƒì…ë‹ˆë‹¤.

[ë‚´ë‹´ì ê´€ì  ëŒ€í™” ìš”ì•½]
{summary}

[ì›ë³¸ ëŒ€í™” ì¼ë¶€]
ì•„ë˜ëŠ” ì‹¤ì œ ëŒ€í™”ì˜ ì¤‘ìš”í•œ ì¼ë¶€ì…ë‹ˆë‹¤. ì¡°ì–¸ì„ ë§Œë“¤ ë•Œ ì—¬ê¸°ì„œ ë“œëŸ¬ë‚˜ëŠ” ë§íˆ¬, ê°ì •, ìƒí˜¸ì‘ìš©ì„ ë°˜ë“œì‹œ ë°˜ì˜í•˜ì„¸ìš”.

\"\"\"{conv_text}\"\"\"

[ìƒë‹´/ì‹¬ë¦¬ ë¬¸ë§¥]
{counsel_ctx_str}

[ëŒ€í™” ê¸°ìˆ /í‘œí˜„ ë¬¸ë§¥]
{talk_ctx_str}

--------------------------------
ì‘ì„± ëª©í‘œ
--------------------------------
1) ë‚´ë‹´ìê°€ ìì‹ ì˜ ìƒíƒœ, ê°ì •, ê°•ì ì„ 'ìŠ¤ìŠ¤ë¡œ ì´í•´'í•  ìˆ˜ ìˆê²Œ ë„ì™€ì¤€ë‹¤.
2) ë‹¹ì¥ ì¼ìƒì—ì„œ ì¨ë¨¹ì„ ìˆ˜ ìˆëŠ” 'êµ¬ì²´ì ì¸ ë§/í–‰ë™ ì—°ìŠµ'ì„ ì œì•ˆí•œë‹¤.
3) ì±…ì—ì„œ ê°€ì ¸ì˜¨ ìƒë‹´/ëŒ€í™” ì´ë¡ ì€ ì°¸ê³ ë§Œ í•˜ê³ , 
   ë‚´ë‹´ìì˜ ì‹¤ì œ ëŒ€í™” ë‚´ìš©ê³¼ ìƒí™©ì— ê¼­ ë§ê²Œ ì¬êµ¬ì„±í•œë‹¤.

--------------------------------
ì‘ì„± ì›ì¹™
--------------------------------
- 1ì°¨ ê¸°ì¤€ì€ [ë‚´ë‹´ì ê´€ì  ëŒ€í™” ìš”ì•½]ê³¼ [ì›ë³¸ ëŒ€í™” ì¼ë¶€]ì…ë‹ˆë‹¤.
  [ìƒë‹´/ì‹¬ë¦¬ ë¬¸ë§¥], [ëŒ€í™” ê¸°ìˆ /í‘œí˜„ ë¬¸ë§¥]ì€ 
  ì„¤ëª…ì„ ë” ê¹Šê³  êµ¬ì²´ì ìœ¼ë¡œ ë§Œë“¤ê¸° ìœ„í•œ ì°¸ê³  ìë£Œë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
- ë§íˆ¬:
  - ê¸°ë³¸ì ìœ¼ë¡œ 'ë„ˆ'ë¥¼ ì£¼ì–´ë¡œ ì“°ëŠ” ë”°ëœ»í•œ ë°˜ë§ ìƒë‹´ í†¤ì„ ì‚¬ìš©í•˜ì„¸ìš”.
  - ë‹¤ë§Œ, ë‚´ë‹´ìê°€ ë¶€ëª¨/ì„±ì¸ìœ¼ë¡œ ì¶”ë¡ ë˜ë©´ ì¡´ëŒ“ë§(ì˜ˆ: "~í•˜ì‹œëŠ” ì ì´ ì°¸ ì¢‹ìœ¼ì„¸ìš”.")ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë°”ê¿” ì“°ì„¸ìš”.
- ë¹„ë‚œ/íŒë‹¨/ë‚™ì¸ì€ ì ˆëŒ€ ê¸ˆì§€:
  - "ë¬¸ì œê°€ ìˆë‹¤", "ì˜ëª»í•˜ê³  ìˆë‹¤" ëŒ€ì‹ 
    "ì´ë¯¸ ~ë¥¼ ì˜í•˜ê³  ìˆê³ , ì•ìœ¼ë¡œëŠ” ~ë¥¼ ì—°ìŠµí•´ ë³´ë©´ ì¢‹ê² ë‹¤"ì²˜ëŸ¼ ì œì•ˆí˜•ìœ¼ë¡œ í‘œí˜„í•˜ì„¸ìš”.
- ìœ„í—˜ ì‹ í˜¸(ê·¹ì‹¬í•œ ìš°ìš¸, ìí•´/ìì‚´ ìƒê°, ì‹¬í•œ ê³µí¬ ë“±)ê°€ ì•”ì‹œë  ê²½ìš°,
  "warnings"ì— 'í˜¼ì ë²„í‹°ì§€ ë§ê³  ë„ì›€ì„ ìš”ì²­í•´ì•¼ í•œë‹¤'ëŠ” ì•ˆì „ ì•ˆë‚´ë¥¼ ê¼­ í¬í•¨í•˜ì„¸ìš”.
- [ëŒ€í™” ê¸°ìˆ /í‘œí˜„ ë¬¸ë§¥]ì€ íŠ¹íˆ "improvements", "action_steps", "checklist"ì—ì„œ
  ë°”ë¡œ ë”°ë¼ í•  ìˆ˜ ìˆëŠ” ë¬¸ì¥/ì§ˆë¬¸ ì˜ˆì‹œë¥¼ ë§Œë“¤ ë•Œ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•˜ì„¸ìš”.

ì£¼ì˜:
- ì˜ˆì‹œ JSONì˜ ì„¤ëª… ë¬¸ì¥ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ê±°ë‚˜ ë¹„ìŠ·í•˜ê²Œ ë³€í˜•í•˜ì§€ ë§ˆì„¸ìš”.
- ì‹¤ì œ ë‹µë³€ì—ì„œëŠ” ë°˜ë“œì‹œ ì´ ë‚´ë‹´ìì˜ ëŒ€í™” ë‚´ìš©, ê°ì •, ìƒí™©ì„ ë°˜ì˜í•œ 'ìƒˆë¡œìš´ ë¬¸ì¥'ì„ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
- summary_for_client, strengths, improvements, action_steps, warnings, checklist ëª¨ë‘ì—ì„œ
  ìµœì†Œ í•œ ë²ˆ ì´ìƒ [ë‚´ë‹´ì ê´€ì  ëŒ€í™” ìš”ì•½] ë˜ëŠ” [ì›ë³¸ ëŒ€í™” ì¼ë¶€]ì˜ êµ¬ì²´ì ì¸ ìƒí™©ì„ ì–¸ê¸‰í•˜ì„¸ìš”.
- [ìƒë‹´/ì‹¬ë¦¬ ë¬¸ë§¥], [ëŒ€í™” ê¸°ìˆ /í‘œí˜„ ë¬¸ë§¥]ì— ë“±ì¥í•˜ëŠ” ê°œë…ì´ë‚˜ ì•„ì´ë””ì–´ë¥¼,
  ì±… ì œëª©/í˜ì´ì§€ë¥¼ ì–¸ê¸‰í•˜ì§€ ì•Šê³  ë‚´ë‹´ìì—ê²Œ ë§ê²Œ í’€ì–´ì„œ ì„¤ëª…í•˜ëŠ” ë¬¸ì¥ì„ ì ì–´ë„ í•œ ë¬¸ì¥ ì´ìƒ í¬í•¨í•˜ì„¸ìš”.

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.

--------------------------------
ì¶œë ¥ í˜•ì‹ (JSON)
--------------------------------
ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.
JSON ë°”ê¹¥ì—ëŠ” ì–´ë–¤ í…ìŠ¤íŠ¸ë„ ì“°ì§€ ë§ˆì„¸ìš”.

ê° í•„ë“œëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë©°, ì˜ˆì‹œëŠ” 'í˜•ì‹ê³¼ ìˆ˜ì¤€'ë§Œ ì°¸ê³ í•˜ì„¸ìš”.

{{
  "summary_for_client": "ì´ ëŒ€í™”ì—ì„œ ë“œëŸ¬ë‚œ ë‚´ë‹´ìì˜ ìƒí™©ê³¼ ê°ì •ì„, ë‚´ë‹´ìì—ê²Œ ì§ì ‘ ë§í•´ì£¼ëŠ” í†¤ìœ¼ë¡œ 3~6ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”. ë°˜ë“œì‹œ êµ¬ì²´ì ì¸ ìƒí™© 1~2ê°œ(ì˜ˆ: 'ì—„ë§ˆì™€ì˜ í†µí™”ì—ì„œ ~ë¼ê³  ë§í–ˆì„ ë•Œ')ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.",
  "strengths": "ì´ ë‚´ë‹´ìê°€ ì‹¤ì œ ëŒ€í™”ì—ì„œ ì´ë¯¸ ì˜í•˜ê³  ìˆëŠ” ì  2~3ê°€ì§€ë¥¼ í•œ ë¬¸ë‹¨ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ë°˜ë“œì‹œ [ì›ë³¸ ëŒ€í™” ì¼ë¶€]ì—ì„œ ê´€ì°°ëœ í–‰ë™ì´ë‚˜ ë§ì„ ì˜ˆë¡œ ë“¤ë©´ì„œ ì¹­ì°¬í•´ì•¼ í•©ë‹ˆë‹¤.",
  "improvements": "ì•ìœ¼ë¡œ ì—°ìŠµí•´ ë³´ë©´ ì¢‹ì„ ì ì„ 2~4ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. 'ë¬´ì—‡ì„ ë°”ê¾¸ì–´ì•¼ í•œë‹¤'ê°€ ì•„ë‹ˆë¼ 'ë¬´ì—‡ì„ ì—°ìŠµí•˜ë©´ ë” í¸í•´ì§ˆì§€'ì— ì´ˆì ì„ ë§ì¶”ê³ , ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì ì¸ ìƒí™©ì„ ì˜ˆë¡œ ë“œì„¸ìš”.",
  "action_steps": "ë‚´ë‹´ìê°€ ì¼ìƒì—ì„œ ë°”ë¡œ í•´ë³¼ ìˆ˜ ìˆëŠ” ì•„ì£¼ êµ¬ì²´ì ì¸ í–‰ë™/ë§ ì—°ìŠµì„ 2~4ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. 'ì–¸ì œ, ëˆ„êµ¬ì—ê²Œ, ì–´ë–¤ ë§/í–‰ë™ì„'ê¹Œì§€ ëª…í™•í•˜ê²Œ ì ì–´ì•¼ í•˜ë©°, [ì›ë³¸ ëŒ€í™” ì¼ë¶€]ì™€ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.",
  "warnings": "ë‚´ë‹´ìê°€ ìŠ¤ìŠ¤ë¡œë¥¼ ì§€í‚¤ê¸° ìœ„í•´ ê¸°ì–µí•˜ë©´ ì¢‹ì€ ì£¼ì˜ì‚¬í•­ì„ 1~3ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ë§Œì•½ ëŒ€í™”ì—ì„œ ê·¹ì‹¬í•œ ìš°ìš¸, ìí•´/ìì‚´ ìƒê°, ê³µí¬ ë“±ì´ ì•”ì‹œë˜ì—ˆë‹¤ë©´ ë°˜ë“œì‹œ 'í˜¼ì ë²„í‹°ì§€ ë§ê³  ë„ì›€ì„ ìš”ì²­í•´ì•¼ í•œë‹¤'ëŠ” ë©”ì‹œì§€ë¥¼ í¬í•¨í•˜ì„¸ìš”.",
  "checklist": "ë‚´ë‹´ìê°€ ì—°ìŠµ ëª¨ë“œì—ì„œ ì²´í¬í•´ ë³¼ ìˆ˜ ìˆëŠ” ì•„ì£¼ êµ¬ì²´ì ì¸ í–‰ë™ í•­ëª© 3ê°œë¥¼ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•´ ì ìœ¼ì„¸ìš”. ê° í•­ëª©ì€ '- 'ë¡œ ì‹œì‘í•˜ê³ , [action_steps]ì™€ ì—°ê²°ëœ í–‰ë™ì´ì–´ì•¼ í•©ë‹ˆë‹¤.",
  "sources": []
}}

ê·œì¹™ ì •ë¦¬:
- ë°˜ë“œì‹œ ìœ„ JSON êµ¬ì¡°ì™€ ë™ì¼í•œ í‚¤ ì´ë¦„ì„ ì‚¬ìš©í•˜ì„¸ìš”.
- ê°’ì€ ëª¨ë‘ ë¬¸ìì—´ì´ì–´ì•¼ í•˜ë©°, "sources"ë§Œ ë°˜ë“œì‹œ ë¦¬ìŠ¤íŠ¸([]) í˜•íƒœë¡œ ë‘ì„¸ìš”.
- ì¤„ë°”ê¿ˆì´ í•„ìš”í•˜ë©´ ë¬¸ìì—´ ì•ˆì— ê·¸ëŒ€ë¡œ ì¤„ë°”ê¿ˆì„ ì‚¬ìš©í•´ë„ ë©ë‹ˆë‹¤.
- JSON ì™¸ì˜ ë‹¤ë¥¸ ì„¤ëª…, ì£¼ì„, ì¸ì‚¿ë§ì€ ì ˆëŒ€ ì“°ì§€ ë§ˆì„¸ìš”.
"""

        if self.verbose:
            print("\nğŸ§  [RAGAndAdviceNode] JSON ì¡°ì–¸ ìƒì„± ì¤‘...")

        resp = llm.invoke(prompt)
        content = resp.content if hasattr(resp, "content") else str(resp)

        # 6) JSON íŒŒì‹±
        try:
            content = content.strip()
            if "```" in content:
                content = content.split("```")[1].strip()
            advice_obj = json.loads(content)
        except Exception as e:
            print(f"   âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            print(f"   ì›ë³¸ ì‘ë‹µ ì¼ë¶€: {content[:200]}...")
            advice_obj = {
                "summary_for_client": summary,
                "strengths": [],
                "improvements": [],
                "action_steps": [],
                "warnings": [],
                "checklist": [],
                "sources": [],
            }

        # 7) ideal_answer ê¸°ë°˜ ì‹¤ì œ sources ìƒì„±
        sources: List[str] = []
        seen: set[tuple] = set()

        def collect_sources(sections: List[Dict[str, Any]]):
            for s in sections:
                book_title = (s.get("book_title") or "").strip()
                path = (s.get("canonical_path") or "").strip()
                cites = s.get("citations") or []

                # ì•„ë¬´ ì •ë³´ë„ ì—†ìœ¼ë©´ ìŠ¤í‚µ
                if not book_title and not path and not cites:
                    continue

                if cites:
                    for c in cites:
                        c = (c or "").strip()
                        key = (book_title, path, c)
                        if key in seen:
                            continue
                        seen.add(key)
                        if path:
                            label = f"{book_title} | {path} | {c}"
                        else:
                            label = f"{book_title} | {c}" if book_title else c
                        sources.append(label)
                else:
                    key = (book_title, path, None)
                    if key in seen:
                        continue
                    seen.add(key)
                    label = f"{book_title} | {path}" if path else book_title
                    if label:
                        sources.append(label)

        collect_sources(counsel_sections)
        collect_sources(talk_sections)

        advice_obj["sources"] = sources

        advice_json_str = json.dumps(advice_obj, ensure_ascii=False, indent=2)

        if self.verbose:
            print("   âœ… ì¡°ì–¸(JSON) ìƒì„± ì™„ë£Œ (ì• 200ì):")
            print(advice_json_str[:200], "...")

        # 8) feedback ì»¬ëŸ¼ì— JSON ë¬¸ìì—´ ì €ì¥
        saved = save_feedback(
            db=db,
            analysis_id=analysis_id,
            feedback=advice_json_str,
        )

        if not saved:
            raise ValueError(f"âŒ feedback ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: analysis_id={analysis_id}")

        if self.verbose:
            print("\nğŸ’¾ [RAGAndAdviceNode] feedback(JSON) ì €ì¥ ì™„ë£Œ")
            print(f"   â†’ analysis_id: {saved['analysis_id']}")
            print(f"   â†’ feedback ê¸¸ì´: {len(saved['feedback'])}ì")

        state.advice_text = advice_json_str
        state.save_result = saved

        return state

