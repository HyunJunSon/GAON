# app/agent/Cleaner/nodes.py
from __future__ import annotations
from dataclasses import dataclass
from datetime import datetime
from typing import Any, Dict, List, Tuple
from app.core.config import settings  # âœ… LLM í‚¤ ì‚¬ìš©
from langchain_openai import ChatOpenAI  # âœ… LLM ì—°ê²°
import uuid

try:
    import pandas as pd
except Exception:
    pd = None

# âœ… DB ì—°ë™ ì¶”ê°€
from sqlalchemy.orm import Session
from app.llm.agent.crud import (
    get_conversation_by_id,
    get_conversation_by_pk,
    conversation_to_dataframe,
)


# =========================================
# âœ… RawFetcher (DB ì—°ë™)
# =========================================
@dataclass
class RawFetcher:
    """
    âœ… DBì—ì„œ conversation ì¡°íšŒ
    
    ë³€ê²½ ì‚¬í•­:
    - ê¸°ì¡´: SAMPLE_DIALOG (í•˜ë“œì½”ë”©)
    - ë³€ê²½: DBì—ì„œ conversation ì¡°íšŒ
    """
    def fetch(self, db: Session = None, conv_id: str = None, *args, **kwargs) -> Any:
        if db is None:
            raise ValueError("âŒ RawFetcher: db ì„¸ì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        if not conv_id:
            raise ValueError("âŒ RawFetcher: conv_id(UUID)ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        conversation = get_conversation_by_id(db, conv_id)
        if not conversation:
            raise ValueError(f"âŒ RawFetcher: conversationì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (conv_id={conv_id})")

        print(f"âœ… [RawFetcher] ëŒ€í™” ì¡°íšŒ ì„±ê³µ: {conversation['title'][:50]}...")
        df = conversation_to_dataframe(conversation)
        print(f"   â†’ DataFrame ìƒì„±: {len(df)}ê°œ ë°œí™”")
        return df



# =========================================
# âœ… RawInspector (ê¸°ì¡´ ìœ ì§€)
# =========================================
@dataclass
class RawInspector:
    """í™”ì, ì—…ë¡œë”(id) ê²€ì¦"""
    def inspect(self, raw: Any, state=None) -> Tuple[Any, List[str]]:
        issues: List[str] = []
        if pd is not None and isinstance(raw, pd.DataFrame):
            df = raw.copy()
            
            # speaker ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            if "speaker" not in df.columns:
                # speaker ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ìƒì„±
                df["speaker"] = "User"  # ë˜ëŠ” ì ì ˆí•œ ê¸°ë³¸ê°’
                issues.append("missing_speaker_column")
            
            unique_speakers = set(df["speaker"].astype(str))

            # âœ… í™”ì 2ëª… ì´ìƒì¸ì§€ í™•ì¸
            if len(unique_speakers) < 2:
                issues.append("not_enough_speakers")

            # âœ… ì—…ë¡œë”(id)ê°€ í™”ì ì¤‘ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            if state and getattr(state, "id", None):
                if str(state.id) not in unique_speakers:
                    issues.append("uploader_not_in_speakers")
            else:
                issues.append("missing_user_id")

            # âœ… timestamp ëˆ„ë½ ì—¬ë¶€
            if "timestamp" not in df.columns or df["timestamp"].isnull().any():
                issues.append("missing_timestamp")

            # âœ… ì°¸ì—¬ì ëª©ë¡(user_ids) ê°±ì‹ 
            if state:
                state.user_ids = list(unique_speakers)

            return df, issues

        return raw, ["unsupported_raw_type"]


# =========================================
# âœ… ConversationCleaner (ê¸°ì¡´ ìœ ì§€)
# =========================================
@dataclass
class ConversationCleaner:
    """LLMì„ ì‚¬ìš©í•´ ë¬¸ì¥ ì •ì œ ë° ë…¸ì´ì¦ˆ ì œê±°"""
    verbose: bool = False
    _cache: dict = None  # ìºì‹œ ì €ì¥ì†Œ
    
    def __post_init__(self):
        if self._cache is None:
            self._cache = {}

    def clean(self, df: Any, state=None) -> Any:
        if pd is not None and isinstance(df, pd.DataFrame):
            out = df.copy()
            llm = ChatOpenAI(model="gpt-4o-mini", api_key=settings.openai_api_key)

            # ğŸš€ ë³‘ë ¬ ì²˜ë¦¬ + ìºì‹±ìœ¼ë¡œ ì†ë„ ìµœì í™”
            from concurrent.futures import ThreadPoolExecutor
            import hashlib
            
            def get_cache_key(text):
                """í…ìŠ¤íŠ¸ì˜ í•´ì‹œê°’ìœ¼ë¡œ ìºì‹œ í‚¤ ìƒì„±"""
                return hashlib.md5(text.encode()).hexdigest()
            
            def clean_single_text(text):
                """ë‹¨ì¼ í…ìŠ¤íŠ¸ ì •ì œ (ìºì‹± ì ìš©)"""
                # ìºì‹œ í™•ì¸
                cache_key = get_cache_key(text)
                if cache_key in self._cache:
                    if self.verbose:
                        print(f"ğŸ’¾ [ìºì‹œ ì‚¬ìš©] {text}")
                    return self._cache[cache_key]
                
                prompt = f"ë‹¤ìŒ ë¬¸ì¥ì—ì„œ ì² ì ì˜¤ë¥˜ë‚˜ ì´ìƒí•œ ê¸°í˜¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìˆ˜ì •í•´ì¤˜:\n{text}"
                if self.verbose:
                    print(f"ğŸª¶ [Cleaner LLM ì…ë ¥] {text}")
                try:
                    response = llm.invoke(prompt)
                    cleaned_text = (
                        response.content
                        if hasattr(response, "content")
                        else str(response)
                    )
                    # ìºì‹œì— ì €ì¥
                    self._cache[cache_key] = cleaned_text
                    if self.verbose:
                        print(f"âœ… [Cleaner LLM ê²°ê³¼] {cleaned_text}")
                    return cleaned_text
                except Exception as e:
                    if self.verbose:
                        print(f"âš ï¸ LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                    return text

            # ë³‘ë ¬ ì²˜ë¦¬ (ìµœëŒ€ 5ê°œ ë™ì‹œ ì²˜ë¦¬) + ìºì‹±
            texts = out["text"].tolist()
            with ThreadPoolExecutor(max_workers=5) as executor:
                cleaned = list(executor.map(clean_single_text, texts))
            
            out["text"] = cleaned
            return out
        return df


# =========================================
# âœ… ConversationValidator (ê¸°ì¡´ ìœ ì§€)
# =========================================
@dataclass
class ConversationValidator:
    """ëŒ€í™”ì˜ ë¶„ì„ ê°€ëŠ¥ì„± íŒë‹¨"""
    verbose: bool = False

    def validate(self, df: Any, state=None) -> Tuple[bool, List[str]]:
        issues: List[str] = []
        if pd is not None and isinstance(df, pd.DataFrame):
            # âœ… í‹°í‚¤íƒ€ì¹´ 3ì„¸íŠ¸(6íšŒ ì´ìƒ) ì—¬ë¶€
            speakers = df["speaker"].tolist()
            tiktaka = sum(speakers[i] != speakers[i - 1] for i in range(1, len(speakers)))
            if tiktaka < 6:
                issues.append("not_enough_tiktaka")

            llm_ok, reason = self._llm_judge(df)
            if not llm_ok:
                issues.append(f"llm_rejected:{reason}")
            return (len(issues) == 0), issues
        return False, ["unsupported_type"]

    def _llm_judge(self, df: Any) -> Tuple[bool, str]:
        """LLMìœ¼ë¡œ ê°ì • ë¶„ì„ ì í•© ì—¬ë¶€ íŒë‹¨"""
        llm = ChatOpenAI(model="gpt-4o-mini", api_key=settings.openai_api_key)
        text = "\n".join(df["text"].astype(str).tolist()[:6])
        prompt = f"ë‹¤ìŒ ëŒ€í™”ê°€ ê°ì •ë¶„ì„ì— ì í•©í•œê°€? 'ì í•©' ë˜ëŠ” 'ë¶€ì í•©'ìœ¼ë¡œë§Œ ëŒ€ë‹µ:\n{text}"
        try:
            response = llm.invoke(prompt)
            reply = response.content if hasattr(response, "content") else str(response)
            if self.verbose:
                print(f"ğŸ¤– [Validator LLM ì‘ë‹µ] {reply}")
            return "ë¶€ì í•©" not in reply, reply
        except Exception as e:
            return False, str(e)


# =========================================
# âœ… ConversationSaver (ìˆ˜ì • - DB ì´ë¯¸ ìˆìœ¼ë¯€ë¡œ ìŠ¤í‚µ)
# =========================================
@dataclass
class ConversationSaver:
    """
    âœ… conversation í…Œì´ë¸”ì— ì €ì¥ (ì´ë¯¸ DBì— ìˆìœ¼ë¯€ë¡œ í˜„ì¬ëŠ” ìŠ¤í‚µ)
    
    ë³€ê²½ ì‚¬í•­:
    - ê¸°ì¡´: DataFrame â†’ conversation í…Œì´ë¸” INSERT
    - ë³€ê²½: ì´ë¯¸ DBì— ìˆìœ¼ë¯€ë¡œ ë©”íƒ€ë°ì´í„°ë§Œ stateì— ì €ì¥
    """
    def save(self, df: Any, state=None) -> Dict[str, Any]:
        """
        ì´ë¯¸ DBì— conversationì´ ì¡´ì¬í•˜ë¯€ë¡œ ìŠ¤í‚µ
        stateì— ë©”íƒ€ë°ì´í„°ë§Œ ì €ì¥
        """
        try:
            # âœ… ì´ë¯¸ DBì— ì €ì¥ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ë©”íƒ€ì •ë³´ë§Œ ë°˜í™˜
            if state and hasattr(state, "conv_id"):
                return {
                    "status": "already_saved",
                    "conversation_id": state.conv_id,
                    "message": "ëŒ€í™”ëŠ” ì´ë¯¸ DBì— ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
                }
            
            return {"status": "skipped"}

        except Exception as e:
            return {"status": "error", "error": str(e)}


# =========================================
# âœ… ExceptionHandler ê·¸ëŒ€ë¡œ ìœ ì§€
# =========================================
@dataclass
class ExceptionHandler:
    """ì˜ˆì™¸ë¥¼ í‘œì¤€í™”í•˜ì—¬ ë°˜í™˜"""
    def handle(self, err: Exception) -> Dict[str, Any]:
        return {"status": "error", "error": str(err)}