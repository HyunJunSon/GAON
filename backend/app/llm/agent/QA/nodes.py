# app/agent/QA/nodes.py
from __future__ import annotations
from dataclasses import dataclass
from typing import Any, Dict
from app.core.config import settings
from langchain_openai import ChatOpenAI
import pandas as pd
from sqlalchemy.orm import Session
import logging

from app.llm.agent.crud import update_analysis_result, get_analysis_by_conv_id
from app.llm.cloud_functions.rag_trigger.rag.vector_db.vector_db_manager import VectorDBManager, EmbeddingService

logger = logging.getLogger(__name__)


# =====================================
# âœ… ScoreEvaluator (LLM ê¸°ë°˜ ì‹ ë¢°ë„ í‰ê°€)
# =====================================
@dataclass
class ScoreEvaluator:
    """ì ìˆ˜ í‰ê°€"""
    verbose: bool = False

    def evaluate(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ì˜ ì ìˆ˜ì™€ ì‹ ë¢°ë„ í‰ê°€"""
        llm = ChatOpenAI(model="gpt-4o-mini", api_key=settings.openai_api_key)
        
        score = result.get("score", 0.0)
        summary = result.get("summary", "")
        statistics = result.get("statistics", {})
        style_analysis = result.get("style_analysis", {})
        
        prompt = f"""
ë‹¹ì‹ ì€ ëŒ€í™” ë¶„ì„ í’ˆì§ˆ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ì˜ **ì‹ ë¢°ë„**ë¥¼ 0.0~1.0 ì‚¬ì´ë¡œ í‰ê°€í•˜ì„¸ìš”.

**ì£¼ì˜: scoreëŠ” ì‚¬ìš©ìì˜ ë§í•˜ê¸° ëŠ¥ë ¥ ì ìˆ˜ì…ë‹ˆë‹¤ (confidenceê°€ ì•„ë‹˜)**

**ë¶„ì„ ê²°ê³¼:**
- ë§í•˜ê¸° ëŠ¥ë ¥ ì ìˆ˜: {score:.2f}
- ìš”ì•½: {summary[:200]}...
- í†µê³„: {statistics}
- ìŠ¤íƒ€ì¼ ë¶„ì„: {style_analysis}

**í‰ê°€ ê¸°ì¤€:**
1. ë¶„ì„ ë‚´ìš©ì´ êµ¬ì²´ì ì´ê³  ê·¼ê±°ê°€ ëª…í™•í•œê°€?
2. í†µê³„ ë°ì´í„°ì™€ ë¶„ì„ ë‚´ìš©ì´ ì¼ì¹˜í•˜ëŠ”ê°€?
3. ìŠ¤íƒ€ì¼ ë¶„ì„ì´ ì‹¤ì œ ë°œí™”ë¥¼ ë°˜ì˜í•˜ëŠ”ê°€?
4. style_analysisì˜ ê° í•­ëª©(ë§íˆ¬, ì„±í–¥, ê´€ì‹¬ì‚¬)ì´ êµ¬ì²´ì ì´ê³  ì¼ê´€ì„± ìˆëŠ”ê°€?
5. summaryê°€ ëŒ€í™” ë‚´ìš©ì„ ì •í™•í•˜ê²Œ ìš”ì•½í•˜ê³  ìˆëŠ”ê°€?
6. ë¶„ì„ ë‚´ìš©ì´ ì¶©ë¶„íˆ ìƒì„¸í•˜ê³  ê·¼ê±°ê°€ ëª…í™•í•œê°€?

**ì‘ë‹µ í˜•ì‹:** ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”
{{
  "confidence": 0.85,
  "reason": "ë¶„ì„ì´ êµ¬ì²´ì ì´ê³  í†µê³„ ë°ì´í„°ì™€ ì¼ì¹˜í•¨"
}}
"""
        
        try:
            response = llm.invoke(prompt)
            content = response.content if hasattr(response, "content") else str(response)
    
            # âœ… ë””ë²„ê¹… ë¡œê·¸
            if self.verbose:
                print(f"[DEBUG] AI ì›ë³¸ ì‘ë‹µ:")
                print(f"--- ì‹œì‘ ---")
                print(content)
                print(f"--- ë ---\n")
            
            import json
            try:
                # JSON ì½”ë“œ ë¸”ë¡ ì œê±° ì‹œë„
                if "```json" in content:
                    content = content.split("```json")[1].split("```")[0].strip()
                elif "```" in content:
                    content = content.split("```")[1].split("```")[0].strip()
                
                evaluation = json.loads(content)
                confidence = float(evaluation.get("confidence", 0.7))
                reason = evaluation.get("reason", "í‰ê°€ ì™„ë£Œ")
                
                # ì‹ ë¢°ë„ ë²”ìœ„ ê²€ì¦
                confidence = max(0.0, min(1.0, confidence))
                
                if self.verbose:
                    print(f"   âœ… íŒŒì‹± ì„±ê³µ: confidence={confidence:.2f}")
                
            except Exception as parse_error:
                # íŒŒì‹± ì‹¤íŒ¨ ì‹œ 0.5ë¡œ ì„¤ì • â†’ ì¬ë¶„ì„ íŠ¸ë¦¬ê±°
                print(f"   âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {parse_error}")
                print(f"   â†’ íŒŒì‹± ì‹œë„ ë‚´ìš©: {content[:200]}...")
                confidence = 0.5  # â† 0.6ë³´ë‹¤ ë‚®ê²Œ!
                reason = f"í‰ê°€ íŒŒì‹± ì‹¤íŒ¨: {str(parse_error)}"
            
            if self.verbose:
                print(f"   ğŸ“Š [QA Evaluation] confidence={confidence:.2f}, reason={reason[:50]}...")
            
            return {
                "confidence": confidence,
                "reason": reason,
                "needs_reanalysis": confidence < 0.6
            }
            
        except Exception as e:
            print(f"âš ï¸ QA í‰ê°€ ì‹¤íŒ¨: {e}")
            return {
                "confidence": 0.5,  # â† ì¬ë¶„ì„ íŠ¸ë¦¬ê±°
                "reason": f"í‰ê°€ ì‹¤íŒ¨: {str(e)}",
                "needs_reanalysis": True
            }


# =====================================
# âœ… ReAnalyzer (LLM ì¬ë¶„ì„ ìˆ˜í–‰)
# =====================================
@dataclass
class ReAnalyzer:
    """ì¬ë¶„ì„ ìˆ˜í–‰"""
    verbose: bool = False

    def reanalyze(self, conversation_df: pd.DataFrame, prev_result: Dict[str, Any]) -> Dict[str, Any]:
        """ëŒ€í™”ë¥¼ ë‹¤ì‹œ ë¶„ì„"""
        llm = ChatOpenAI(model="gpt-4o-mini", api_key=settings.openai_api_key)
        text = "\n".join(conversation_df["text"].tolist())
        
        prompt = f"""
ì•„ë˜ ëŒ€í™” ë‚´ìš©ì„ ë‹¤ì‹œ ë¶„ì„í•´ì¤˜.
ì´ì „ ë¶„ì„ ê²°ê³¼ëŠ” ì°¸ê³ ìš©ì´ì•¼. 
ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì¤˜.
{{
    "summary": "string",
    "style_analysis": {{"emotion": "string", "tone": "string"}},
    "score": float,
    "reason": "string"
}}

ëŒ€í™” ë‚´ìš©:
{text}

ì´ì „ ë¶„ì„ ê²°ê³¼:
{prev_result}
"""
        try:
            response = llm.invoke(prompt)
            content = response.content if hasattr(response, "content") else str(response)
            import json, re

            try:
                parsed = json.loads(content)
            except json.JSONDecodeError:
                parsed = {}
                match = re.search(r"([0-1]\.\d+|\d\.\d+|\d)", content)
                parsed["score"] = float(match.group(1)) if match else 0.75
                parsed["reason"] = content.strip()[:200]

            result = {
                "summary": parsed.get("summary", prev_result.get("summary", "ëŒ€í™” ì¬ë¶„ì„ ê²°ê³¼")),
                "style_analysis": parsed.get(
                    "style_analysis",
                    prev_result.get("style_analysis", {"emotion": "ê¸ì •ì ", "tone": "ì°¨ë¶„í•¨"})
                ),
                "statistics": prev_result.get("statistics", {}),  # â† statistics ìœ ì§€!
                "score": parsed.get("score", 0.75),
                "reason": parsed.get("reason", "ì¬ë¶„ì„ ê²°ê³¼ì— ëŒ€í•œ ê·¼ê±° ì—†ìŒ"),
            }

            if self.verbose:
                print(f"ğŸ§  [ReAnalyzer LLM ì‘ë‹µ] {content[:200]}...")
                print(f"ğŸ’¬ [ì¬ë¶„ì„ ê·¼ê±°] {result['reason']}")

            return result

        except Exception as e:
            print(f"âš ï¸ ì¬ë¶„ì„ ì‹¤íŒ¨: {e}")
            return prev_result


# =====================================
# âœ… AnalysisSaver (DB ì—°ë™ - UPDATE)
# =====================================
@dataclass
class AnalysisSaver:
    """
    ìµœì¢… ê²°ê³¼ DB ì €ì¥ (UPDATE)
    summaryì— QA í‰ê°€ ì •ë³´ ì¶”ê°€
    """
    verbose: bool = False  # â† ì´ê²Œ í•„ìš”í•´ìš”!
    
    def save_final(self, db: Session, conv_id: str, result: Dict[str, Any], confidence: float, reason: str) -> Dict[str, Any]:
        """
        QA ìµœì¢… ê²°ê³¼ë¥¼ DBì— UPDATE
        
        Args:
            db: SQLAlchemy ì„¸ì…˜
            conv_id: ëŒ€í™” ID
            result: QA ìµœì¢… ê²°ê³¼
            confidence: ì‹ ë¢°ë„ ì ìˆ˜
            reason: í‰ê°€ ê·¼ê±°
        """
        if not db:
            raise ValueError("âŒ AnalysisSaver: db ì„¸ì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤!")
        
        if not conv_id:
            raise ValueError("âŒ AnalysisSaver: conv_idê°€ í•„ìš”í•©ë‹ˆë‹¤!")
        
        try:
            if self.verbose:
                print("\nğŸ’¾ [AnalysisSaver] ìµœì¢… ê²°ê³¼ ì €ì¥ ì¤‘...")
            
            # âœ… ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            existing = get_analysis_by_conv_id(db, conv_id)
            
            if not existing:
                print(f"   âš ï¸ conv_id={conv_id}ì— í•´ë‹¹í•˜ëŠ” ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return {"status": "not_found", "conv_id": conv_id}
            
            # âœ… ì—…ë°ì´íŠ¸í•  ë°ì´í„° ì¤€ë¹„
            summary = result.get("summary", existing.get("summary", ""))
            style_analysis = result.get("style_analysis", existing.get("style_analysis"))
            statistics = result.get("statistics", existing.get("statistics"))
            score = result.get("score", existing.get("score"))
            
            # âœ… summaryì— QA ì„¹ì…˜ ì¶”ê°€
            qa_section = f"""

{'=' * 50}
ğŸ” QA í’ˆì§ˆ í‰ê°€
{'=' * 50}

[ì‹ ë¢°ë„ ì ìˆ˜] {confidence:.2f}/1.00

[í‰ê°€ ê·¼ê±°]
  {reason}
"""
            
            if "reason" in result and result["reason"]:
                qa_section += f"""
[ì¬ë¶„ì„ ìˆ˜í–‰]
  ì‚¬ìœ : {result['reason']}
  â†’ ì¬ë¶„ì„ í›„ í’ˆì§ˆì´ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤.
"""
            
            qa_section += f"\n{'=' * 50}\n"
            
            enhanced_summary = summary + qa_section
            
            # âœ… DB UPDATE ì‹¤í–‰
            updated = update_analysis_result(
                db=db,
                conv_id=conv_id,
                summary=enhanced_summary,
                style_analysis=style_analysis,
                statistics=statistics,
                score=score,
                confidence_score=confidence,
                feedback=None,  # RAGì—ì„œ ìƒì„±
            )
            
            if updated:
                if self.verbose:
                    print(f"   âœ… [AnalysisSaver] DB ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                    print(f"      â†’ analysis_id: {updated['analysis_id']}")
                    print(f"      â†’ summary: {len(enhanced_summary)}ì")
                    print(f"      â†’ score: {updated['score']:.2f}")
                    print(f"      â†’ confidence_score: {updated['confidence_score']:.2f}")
                    print(f"      â†’ feedback: NULL (RAG íŒŒíŠ¸ì—ì„œ ìƒì„± ì˜ˆì •)")
                
                return {
                    "status": "updated",
                    "analysis_id": updated["analysis_id"],
                    "score": updated["score"],
                    "confidence_score": updated["confidence_score"],
                    "summary_length": len(enhanced_summary)
                }
            else:
                print(f"   âš ï¸ DB ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")
                return {"status": "update_failed", "conv_id": conv_id}
        
        except Exception as e:
            print(f"   âŒ [AnalysisSaver] DB ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return {"status": "error", "error": str(e)}


# =====================================
# âœ… RAG ê¸°ë°˜ í”¼ë“œë°± ìƒì„±ê¸°
# =====================================
@dataclass
class RAGFeedbackGenerator:
    """RAGë¥¼ í™œìš©í•œ í”¼ë“œë°± ìƒì„±"""
    verbose: bool = False

    def generate_feedback(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ RAG ê²€ìƒ‰ í›„ í”¼ë“œë°± ìƒì„±"""
        try:
            if self.verbose:
                print(f"   ğŸ¤– [RAGFeedbackGenerator] í”¼ë“œë°± ìƒì„± ì‹œì‘")
            
            # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            vector_db_manager = VectorDBManager()
            embedding_service = EmbeddingService(vector_db_manager)
            
            # ë¶„ì„ ê²°ê³¼ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
            summary = analysis_result.get("summary", "")
            statistics = analysis_result.get("statistics", {})
            
            # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (ëŒ€í™”ì˜ í•µì‹¬ ë¬¸ì œì ê³¼ ê°œì„  í•„ìš” ì˜ì—­)
            search_query = f"""
            ê°€ì¡± ëŒ€í™” ë¶„ì„:
            {summary}
            
            ì£¼ìš” ì´ìŠˆ:
            - ê°ì • í‘œí˜„: {statistics.get('emotion_distribution', {})}
            - ëŒ€í™” íŒ¨í„´: ì´ {statistics.get('total_utterances', 0)}íšŒ ë°œí™”
            - ì†Œí†µ ìŠ¤íƒ€ì¼ ê°œì„  í•„ìš”
            """
            
            # RAGì—ì„œ ê´€ë ¨ ì±… ì¡°ì–¸ ê²€ìƒ‰
            book_advice = []
            try:
                # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
                query_embedding = embedding_service.create_embedding(search_query)
                
                # ê´€ë ¨ ì¡°ì–¸ ê²€ìƒ‰ (60% ì´ìƒ ìœ ì‚¬ë„ë§Œ)
                similar_results = vector_db_manager.find_similar(
                    query_embedding=query_embedding,
                    top_k=3,
                    threshold=0.6  # 60% ì´ìƒ ìœ ì‚¬ë„
                )
                
                book_advice = [
                    {
                        "advice": content,
                        "similarity": similarity,
                        "source_id": str(advice_id)
                    }
                    for content, similarity, advice_id in similar_results
                    if similarity >= 0.6  # 60% ì´ìƒë§Œ í¬í•¨
                ]
                
                if self.verbose:
                    print(f"      â†’ RAG ê²€ìƒ‰ ì™„ë£Œ: {len(book_advice)}ê°œ ê´€ë ¨ ì¡°ì–¸ ë°œê²¬")
                
            except Exception as e:
                logger.warning(f"RAG ê²€ìƒ‰ ì‹¤íŒ¨, ê¸°ë³¸ í”¼ë“œë°±ìœ¼ë¡œ ì§„í–‰: {str(e)}")
            
            # LLMì„ ì‚¬ìš©í•œ í”¼ë“œë°± ìƒì„±
            llm = ChatOpenAI(
                model="gpt-4o-mini",
                temperature=0.3,
                api_key=settings.openai_api_key
            )
            
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì±… ì¡°ì–¸ í¬í•¨)
            system_prompt = """
ë‹¹ì‹ ì€ ê°€ì¡± ëŒ€í™” ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ê°œì„  í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”.

**í”¼ë“œë°± ì‘ì„± ì›ì¹™:**
1. ê¸ì •ì ì¸ ë¶€ë¶„ì„ ë¨¼ì € ì–¸ê¸‰
2. ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ì„ êµ¬ì²´ì ìœ¼ë¡œ ì§€ì 
3. ì‹¤ì²œ ê°€ëŠ¥í•œ ê°œì„  ë°©ì•ˆ ì œì‹œ
4. ê°€ì¡± ê´€ê³„ ê°œì„ ì— ë„ì›€ì´ ë˜ëŠ” ì¡°ì–¸

**ì¶œë ¥ í˜•ì‹:**
## ì˜í•˜ê³  ìˆëŠ” ì 
- [êµ¬ì²´ì ì¸ ê¸ì •ì  í”¼ë“œë°±]

## ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„  
- [êµ¬ì²´ì ì¸ ê°œì„ ì ]

## ì‹¤ì²œ ë°©ì•ˆ
- [êµ¬ì²´ì ì¸ ì‹¤ì²œ ë°©ë²•]
"""

            # ê´€ë ¨ ì±… ì¡°ì–¸ì´ ìˆìœ¼ë©´ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
            if book_advice:
                advice_text = "\n".join([
                    f"ğŸ“š ì¡°ì–¸ {i+1} (ê´€ë ¨ë„: {advice['similarity']:.1%}): {advice['advice']}"
                    for i, advice in enumerate(book_advice)
                ])
                system_prompt += f"""

## ì°¸ê³ í•  ì „ë¬¸ê°€ ì¡°ì–¸
ë‹¤ìŒì€ ì´ ëŒ€í™” ìƒí™©ê³¼ ê´€ë ¨ëœ ì „ë¬¸ì„œì ì˜ ì¡°ì–¸ë“¤ì…ë‹ˆë‹¤ (60% ì´ìƒ ê´€ë ¨ë„):

{advice_text}

ìœ„ ì „ë¬¸ê°€ ì¡°ì–¸ë“¤ì„ ì°¸ê³ í•˜ì—¬ ë” êµ¬ì²´ì ì´ê³  ê·¼ê±° ìˆëŠ” í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”.
ì¡°ì–¸ì„ ì§ì ‘ ì¸ìš©í•˜ê±°ë‚˜ ì°¸ê³ í–ˆë‹¤ë©´ "ì „ë¬¸ê°€ ì¡°ì–¸ì— ë”°ë¥´ë©´..." ë“±ìœ¼ë¡œ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.
"""

            # ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„±
            user_message = f"""
ë‹¤ìŒ ëŒ€í™” ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í”¼ë“œë°±ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

**ë¶„ì„ ìš”ì•½:**
{summary}

**ì£¼ìš” í†µê³„:**
{statistics}

**ë¶„ì„ ì ìˆ˜:** {analysis_result.get('score', 0)}/100
**ì‹ ë¢°ë„:** {analysis_result.get('confidence_score', 0)}/100
"""

            # LLM í˜¸ì¶œ
            from langchain_core.messages import HumanMessage, SystemMessage
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_message)
            ]
            
            response = llm.invoke(messages)
            feedback = response.content
            
            if self.verbose:
                print(f"      â†’ í”¼ë“œë°± ìƒì„± ì™„ë£Œ (ê¸¸ì´: {len(feedback)}ì, ì¡°ì–¸: {len(book_advice)}ê°œ)")
            
            return {
                "status": "success",
                "feedback": feedback,
                "book_advice": book_advice,
                "rag_used": len(book_advice) > 0,
                "book_advice_count": len(book_advice)
            }
            
        except Exception as e:
            logger.error(f"RAG í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "feedback": None
            }