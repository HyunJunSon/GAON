"""
ìƒˆë¡œìš´ Agent íŒŒì´í”„ë¼ì¸
- Cleaner â†’ Analysis ì‹¤í–‰
- speaker_segments ê¸°ë°˜ ë¶„ì„
"""

import asyncio
import logging
from typing import Dict, Any, List
from datetime import datetime

from app.core.database import SessionLocal
from app.agent.crud import get_conversation_file_by_conv_id
from app.llm.agent.Cleaner.graph_cleaner import CleanerGraph
from app.llm.agent.Analysis.graph_analysis import AnalysisGraph
from app.llm.agent.Feedback.run_feedback import run_feedback

logger = logging.getLogger(__name__)


def extract_speaker_info_from_file(file_row: Dict[str, Any], db) -> Dict[str, Any]:
    """
    conversation_fileì—ì„œ speaker_segmentsì™€ ë§¤í•‘ ì •ë³´ ì¶”ì¶œ
    
    Returns:
        {
            "speaker_segments": List[Dict],
            "speaker_mapping": Dict,
            "user_gender": str,
            "user_age": int,
            "user_name": str
        }
    """
    from sqlalchemy import text
    
    speaker_segments = file_row.get("speaker_segments", [])
    speaker_mapping_raw = file_row.get("speaker_mapping", {})
    
    # ì‹¤ì œ êµ¬ì¡°: {"speaker_names": {"SPEAKER_0A": "gaon (ë‚˜)"}, "user_ids": {"SPEAKER_0A": 9}}
    speaker_mapping = speaker_mapping_raw if speaker_mapping_raw else {
        "user_ids": {},
        "speaker_names": {}
    }
    
    user_gender = "unknown"
    user_age = 0
    user_name = None
    
    # user_idsì—ì„œ ì²« ë²ˆì§¸ user ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    user_ids_map = speaker_mapping.get("user_ids", {})
    speaker_names = speaker_mapping.get("speaker_names", {})
    
    if user_ids_map:
        first_speaker = list(user_ids_map.keys())[0]
        user_name = speaker_names.get(first_speaker, "ì‚¬ìš©ì")
        user_id = user_ids_map.get(first_speaker)
        
        # DBì—ì„œ ì‹¤ì œ user ì •ë³´ ì¡°íšŒ (text SQL ì‚¬ìš©)
        if user_id:
            result = db.execute(
                text("SELECT name, age, gender FROM users WHERE id = :user_id"),
                {"user_id": user_id}
            ).fetchone()
            
            if result:
                user_name = result[0] or user_name
                user_age = result[1] or 0
                user_gender = result[2] or "unknown"
    
    return {
        "speaker_segments": speaker_segments,
        "speaker_mapping": speaker_mapping,
        "user_gender": user_gender,
        "user_age": user_age,
        "user_name": user_name
    }


async def run_agent_pipeline_with_retry(conv_id: str) -> Dict[str, Any]:
    """
    ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ Agent íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    
    Args:
        conv_id: ëŒ€í™” UUID
        
    Returns:
        dict: {
            "status": "completed" | "failed",
            "conv_id": str,
            "user_id": int,
            "analysis_id": str,
            "score": float,
            "confidence": float,
            "error": str (ì‹¤íŒ¨ ì‹œ)
        }
    """
    pipeline_start = datetime.now()
    db = SessionLocal()
    
    try:
        logger.info(f"ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹œì‘: conv_id={conv_id}")
        
        # -------------------------------------------------
        # 1. conversation_fileì—ì„œ speaker_segments ê°€ì ¸ì˜¤ê¸°
        # -------------------------------------------------
        file_row = get_conversation_file_by_conv_id(db, conv_id)
        if not file_row:
            raise RuntimeError(f"conv_id={conv_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        logger.info(f"ğŸ“ íŒŒì¼ íƒ€ì…: {file_row['file_type']}")
        
        # speaker ì •ë³´ ì¶”ì¶œ
        speaker_info = extract_speaker_info_from_file(file_row, db)
        speaker_segments = speaker_info["speaker_segments"]
        speaker_mapping = speaker_info["speaker_mapping"]
        user_gender = speaker_info["user_gender"]
        user_age = speaker_info["user_age"]
        user_name = speaker_info["user_name"]
        
        if not speaker_segments:
            raise RuntimeError("speaker_segmentsê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        
        logger.info(f"âœ… speaker_segments: {len(speaker_segments)}ê°œ")
        
        # -------------------------------------------------
        # 2. speaker_mappingì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        # -------------------------------------------------
        user_ids_map = speaker_mapping.get("user_ids", {})
        
        if not user_ids_map:
            raise RuntimeError("user_ids mappingì´ ì—†ìŠµë‹ˆë‹¤. í™”ì ë§¤í•‘ì„ ë¨¼ì € ì™„ë£Œí•´ì£¼ì„¸ìš”.")
        
        user_speaker_label = list(user_ids_map.keys())[0]
        user_id = list(user_ids_map.values())[0]
        
        speaker_names = speaker_mapping.get("speaker_names", {})
        other_speakers = [spk for spk in speaker_names.keys() if spk != user_speaker_label]
        other_speaker_label = other_speakers[0] if other_speakers else None
        other_display_name = speaker_names.get(other_speaker_label, "ìƒëŒ€ë°©")
        
        logger.info(f"ğŸ‘¤ user_id={user_id}, user_label={user_speaker_label}, other_label={other_speaker_label}")
        
        # -------------------------------------------------
        # 3. Analysis ì‹¤í–‰
        # -------------------------------------------------
        logger.info("ğŸ” Analysis ì‹¤í–‰ ì‹œì‘")
        analysis = AnalysisGraph(verbose=True)
        
        analysis_state = analysis.run(
            db=db,
            conv_id=conv_id,
            speaker_segments=speaker_segments,
            user_id=user_id,
            user_gender=user_gender,
            user_age=user_age,
            user_name=user_name,
            user_speaker_label=user_speaker_label,
            other_speaker_label=other_speaker_label,
            other_display_name=other_display_name,
        )
        
        logger.info("âœ… Analysis ì™„ë£Œ")
        
        # -------------------------------------------------
        # 4. Feedback ì‹¤í–‰ (RAG ê¸°ë°˜ ì¡°ì–¸)
        # -------------------------------------------------
        logger.info("ğŸ’¡ Feedback ì‹¤í–‰ ì‹œì‘")
        
        # AnalysisStateì—ì„œ ê²°ê³¼ ì¶”ì¶œ
        analysis_result = analysis_state.get('analysis_result', {})
        meta = analysis_state.get('meta', {})
        analysis_id = meta.get("analysis_id")
        conversation_df = analysis_state.get('conversation_df')
        
        feedback_result = run_feedback(
            conv_id=conv_id,
            id=user_id,
            conversation_df=conversation_df,
            analysis_id=analysis_id,
            db=db,
            verbose=True
        )
        
        logger.info("âœ… Feedback ì™„ë£Œ")
        
        # -------------------------------------------------
        # 5. ê²°ê³¼ ë°˜í™˜ ë° WebSocket ì•Œë¦¼
        # -------------------------------------------------
        total_time = (datetime.now() - pipeline_start).total_seconds()
        
        # AnalysisStateì—ì„œ ê²°ê³¼ ì¶”ì¶œ (dict í˜•íƒœ)
        analysis_result = analysis_state.get('analysis_result', {})
        meta = analysis_state.get('meta', {})
        
        result = {
            "status": "completed",
            "conv_id": conv_id,
            "user_id": user_id,
            "analysis_id": analysis_id,
            "score": analysis_result.get("score", 0),
            "confidence": 0.95,
            "summary": analysis_result.get("summary"),
            "statistics": analysis_result.get("statistics"),
            "style_analysis": analysis_result.get("style"),
            "feedback": feedback_result.get("advice_text") or feedback_result.get("feedback"),
            "validated": True,
            "execution_time": total_time,
        }
        
        # WebSocketìœ¼ë¡œ ë¶„ì„ ì™„ë£Œ ì•Œë¦¼ ì „ì†¡
        try:
            from app.domains.conversation.websocket import notify_analysis_complete
            await notify_analysis_complete(conv_id, result)
            logger.info("ğŸ“¡ WebSocket ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"ğŸ“¡ WebSocket ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
        
        logger.info(f"ğŸ‰ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {total_time:.2f}ì´ˆ")
        return result
        
    except Exception as e:
        logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        return {
            "status": "failed",
            "error": str(e),
            "conv_id": conv_id,
            "execution_time": (datetime.now() - pipeline_start).total_seconds()
        }
    
    finally:
        db.close()
