# app/agent/QA/nodes.py
from __future__ import annotations
from dataclasses import dataclass
from typing import Any, Dict
from app.core.config import settings
from langchain_openai import ChatOpenAI
import pandas as pd

# =====================================
# âœ… Mock DB í…Œì´ë¸” (ERD ê¸°ë°˜)
# =====================================
analysis_result_df = pd.DataFrame([
    {
        "analysis_id": 1,
        "user_id": "201",
        "conv_id": "C001",
        "summary": "ë”°ëœ»í•œ ê°€ì¡± ê°„ ëŒ€í™”",
        "style_analysis": {"emotion": "ê¸ì •ì ", "tone": "í¸ì•ˆí•¨"},
        "score": 0.82,
    }
])

# =====================================
# âœ… ScoreEvaluator (LLM ê¸°ë°˜ ì‹ ë¢°ë„ í‰ê°€)
# =====================================
@dataclass
class ScoreEvaluator:
    verbose: bool = False

    def evaluate(self, analysis_result: Dict[str, Any]) -> float:
        """
        ê°ì •, í†¤, ìš”ì•½ ë‚´ìš© ë“±ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹ ë¢°ë„ë¥¼ í‰ê°€í•˜ëŠ” LLM Agent.
        """
        llm = ChatOpenAI(model="gpt-4o-mini", api_key=settings.openai_api_key)
        prompt = f"""
        ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ì˜ ì‹ ë¢°ë„ë¥¼ 0~1 ì‚¬ì´ ì‹¤ìˆ˜ë¡œ í‰ê°€í•´ì¤˜.
        - 0.8 ì´ìƒ: ë§¤ìš° ì‹ ë¢°í•  ìˆ˜ ìˆìŒ
        - 0.65~0.8: ë³´í†µ ìˆ˜ì¤€
        - 0.65 ë¯¸ë§Œ: ì¬ë¶„ì„ í•„ìš”
        ë¶„ì„ ê²°ê³¼:
        {analysis_result}
        """
        try:
            response = llm.invoke(prompt)
            content = response.content if hasattr(response, "content") else str(response)
            # ë‹¨ìˆœíˆ LLM ê²°ê³¼ì— ìˆ˜ì¹˜ í¬í•¨ë˜ì–´ ìˆë‹¤ ê°€ì • (mock fallback)
            score = float(analysis_result.get("score", 0.8))
            if self.verbose:
                print(f"ğŸ¤– [LLM í‰ê°€ ì‘ë‹µ] {content}")
            return min(max(score, 0), 1.0)
        except Exception as e:
            print(f"âš ï¸ ì‹ ë¢°ë„ í‰ê°€ ì‹¤íŒ¨: {e}")
            return 0.0

# =====================================
# âœ… ReAnalyzer (LLM ì¬ë¶„ì„ ìˆ˜í–‰)
# =====================================
@dataclass
class ReAnalyzer:
    verbose: bool = False

    def reanalyze(self, conversation_df: pd.DataFrame, prev_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        ì´ì „ ë¶„ì„ì˜ ê²°ê³¼ë¥¼ ì°¸ê³ í•´ ëŒ€í™”ë¥¼ ë‹¤ì‹œ ë¶„ì„í•˜ì—¬ í†µí•© ê²°ê³¼ ë°˜í™˜.
        """
        llm = ChatOpenAI(model="gpt-4o-mini", api_key=settings.openai_api_key)
        text = "\n".join(conversation_df["text"].tolist())
        prompt = f"""
        ì•„ë˜ ëŒ€í™” ë‚´ìš©ì„ ë‹¤ì‹œ ë¶„ì„í•´ì¤˜. 
        ì´ì „ ë¶„ì„ ê²°ê³¼ëŠ” ì°¸ê³ ìš©ì´ì•¼. ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì¤˜.
        - emotion, tone, style, score í¬í•¨
        ëŒ€í™” ë‚´ìš©:
        {text}

        ì´ì „ ë¶„ì„ ê²°ê³¼:
        {prev_result}
        """
        try:
            response = llm.invoke(prompt)
            if self.verbose:
                print(f"ğŸ§  [ReAnalyzer LLM ì‘ë‹µ] {response.content if hasattr(response, 'content') else response}")
            # mock response
            return {
                "summary": prev_result.get("summary", "ëŒ€í™” ì¬ë¶„ì„ ê²°ê³¼"),
                "style_analysis": {"emotion": "ê¸ì •ì ", "tone": "ì°¨ë¶„í•¨"},
                "score": 0.78,
            }
        except Exception as e:
            print(f"âš ï¸ ì¬ë¶„ì„ ì‹¤íŒ¨: {e}")
            return prev_result

# =====================================
# âœ… AnalysisSaver (ìµœì¢… ê²°ê³¼ ì €ì¥)
# =====================================
@dataclass
# app/agent/QA/nodes.py
@dataclass
class AnalysisSaver:
    def save_final(self, result: Dict[str, Any], state=None) -> Dict[str, Any]:
        """
        ìµœì¢… QA ê²°ê³¼ë¥¼ DB(ë˜ëŠ” Mock DataFrame)ì— ë°˜ì˜.
        """
        global analysis_result_df
        existing = analysis_result_df[analysis_result_df["conv_id"] == state.conv_id]
        style_data = result.get("style_analysis")

        # ğŸ§© dict íƒ€ì…ì€ JSON ë¬¸ìì—´ë¡œ ë³€í™˜ (pandas ì…€ í˜¸í™˜)
        if isinstance(style_data, (dict, list)):
            import json
            style_data = json.dumps(style_data, ensure_ascii=False)

        if not existing.empty:
            idx = existing.index[0]
            analysis_result_df.loc[idx, "style_analysis"] = style_data
            analysis_result_df.loc[idx, "score"] = result.get("score")
        else:
            new_row = {
                "analysis_id": len(analysis_result_df) + 1,
                "user_id": state.user_id,
                "conv_id": state.conv_id,
                "summary": result.get("summary"),
                "style_analysis": style_data,
                "score": result.get("score"),
            }
            analysis_result_df = pd.concat(
                [analysis_result_df, pd.DataFrame([new_row])], ignore_index=True
            )

        # âœ… ìµœì¢… ê²°ê³¼ë¥¼ state.metaì— ì €ì¥
        state.meta["final_result_df"] = analysis_result_df
        return {"status": "final_saved", "rows": len(analysis_result_df)}

