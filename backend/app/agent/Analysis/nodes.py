# app/agent/Analysis/nodes.py
from __future__ import annotations
from dataclasses import dataclass
from typing import Any, Dict, List, Tuple
from app.core.config import settings
from langchain_openai import ChatOpenAI
import pandas as pd
from sqlalchemy.orm import Session

# âœ… CRUD í•¨ìˆ˜ import
from app.agent.crud import (
    get_user_by_id,
    get_family_by_id,
    save_analysis_result,
)


# =========================================
# âœ… UserFetcher (DB ì—°ë™) - ìˆ˜ì • ì—†ìŒ
# =========================================
@dataclass
class UserFetcher:
    """
    âœ… DBì—ì„œ ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ
    
    ë³€ê²½ ì‚¬í•­:
    - ê¸°ì¡´: Mock user_df
    - ë³€ê²½: DB users í…Œì´ë¸” ì¡°íšŒ
    """
    def fetch(self, db: Session, conv_state) -> Dict[str, Any]:
        """
        users í…Œì´ë¸”ì—ì„œ ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ
        
        Args:
            db: SQLAlchemy ì„¸ì…˜
            conv_state: AnalysisState (user_id í¬í•¨)
        
        Returns:
            ì‚¬ìš©ì ì •ë³´ Dict
        """
        user_id = conv_state.user_id
        
        if not user_id:
            raise ValueError("âŒ UserFetcher: user_idê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # âœ… DB ì¡°íšŒ
        user = get_user_by_id(db, user_id)
        
        if not user:
            raise ValueError(f"âŒ UserFetcher: user_id={user_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"âœ… [UserFetcher] ì‚¬ìš©ì ì¡°íšŒ: {user.get('user_name')}")
        
        return user


# =========================================
# âœ… FamilyChecker (ê°€ì¡± ê¸°ëŠ¥ ë¹„í™œì„±í™”) - ìˆ˜ì • ì—†ìŒ
# =========================================
@dataclass
class FamilyChecker:
    """
    âœ… ê°€ì¡± ê´€ê³„ í™•ì¸ (í˜„ì¬ ë¹„í™œì„±í™”)
    
    í˜„ì¬ ìƒíƒœ:
    - users â†” family ì—°ê²° ì»¬ëŸ¼ ì—†ìŒ
    - í•­ìƒ False ë°˜í™˜ â†’ LLM ì¶”ë¡  ëª¨ë“œ
    """
    def check(self, db: Session, user_info: Dict[str, Any]) -> Tuple[bool, int]:
        """
        ê°€ì¡± ì •ë³´ í™•ì¸ (í˜„ì¬ ë¹„í™œì„±í™”)
        
        Args:
            db: SQLAlchemy ì„¸ì…˜
            user_info: UserFetcher ê²°ê³¼
        
        Returns:
            (False, None) - í•­ìƒ LLM ì¶”ë¡  ëª¨ë“œ
        """
        print(f"âš ï¸  [FamilyChecker] ê°€ì¡± ê¸°ëŠ¥ ë¹„í™œì„±í™” â†’ LLM ì¶”ë¡  ëª¨ë“œ")
        return False, None


# =========================================
# âœ… RelationResolver_DB (ë¹„í™œì„±í™”) - ìˆ˜ì • ì—†ìŒ
# =========================================
@dataclass
class RelationResolver_DB:
    """
    âœ… DBì—ì„œ ê°€ì¡± êµ¬ì„±ì› ì¡°íšŒ (í˜„ì¬ ë¹„í™œì„±í™”)
    
    í˜„ì¬ ìƒíƒœ:
    - family_member í…Œì´ë¸” ì—†ìŒ
    - ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    """
    def resolve(self, db: Session, fam_id: int) -> List[Dict[str, Any]]:
        """
        ê°€ì¡± êµ¬ì„±ì› ì¡°íšŒ (í˜„ì¬ ë¹„í™œì„±í™”)
        
        Args:
            db: SQLAlchemy ì„¸ì…˜
            fam_id: ê°€ì¡± ID
        
        Returns:
            [] - ë¹ˆ ë¦¬ìŠ¤íŠ¸
        """
        print(f"âš ï¸  [RelationResolver_DB] ê°€ì¡± ê¸°ëŠ¥ ë¹„í™œì„±í™”")
        return []


# =========================================
# âœ… RelationResolver_LLM (ê¸°ì¡´ ìœ ì§€) - ìˆ˜ì • ì—†ìŒ
# =========================================
@dataclass
class RelationResolver_LLM:
    """LLM ê¸°ë°˜ ê´€ê³„ ì¶”ë¡ """
    verbose: bool = False

    def resolve(self, conversation_df: pd.DataFrame) -> List[Dict[str, Any]]:
        """
        LLMìœ¼ë¡œ ëŒ€í™”ì—ì„œ ê´€ê³„ ì¶”ë¡ 
        
        Args:
            conversation_df: ëŒ€í™” DataFrame
        
        Returns:
            ì¶”ë¡ ëœ ê´€ê³„ ë¦¬ìŠ¤íŠ¸
        """
        llm = ChatOpenAI(model="gpt-4o-mini", api_key=settings.openai_api_key)
        text_snippet = "\n".join(conversation_df["text"].tolist()[:10])
        
        prompt = f"""
ë‹¤ìŒ ëŒ€í™”ì—ì„œ ë“±ì¥í•˜ëŠ” ì¸ë¬¼ë“¤ì˜ ê´€ê³„ë¥¼ ì¶”ë¡ í•´ì¤˜.
ì˜ˆ: ì—„ë§ˆ, ì•„ë“¤, ì•„ë¹ , ì¹œêµ¬ ë“±

ëŒ€í™” ë‚´ìš©:
{text_snippet}

ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ ë°˜í™˜í•´ì¤˜.
ì˜ˆ: [{{"speaker":"1","relation":"ì—„ë§ˆ"}}, {{"speaker":"2","relation":"ì•„ë“¤"}}]
"""
        
        try:
            response = llm.invoke(prompt)
            content = response.content if hasattr(response, "content") else str(response)
            
            if self.verbose:
                print(f"ğŸ§  [RelationResolver_LLM] ì‘ë‹µ: {content[:200]}")
            
            # âœ… ê°„ë‹¨í•œ fallback
            return [
                {"speaker": "1", "relation": "ì°¸ì„ì1"},
                {"speaker": "2", "relation": "ì°¸ì„ì2"}
            ]
            
        except Exception as e:
            print(f"âš ï¸ Relation LLM ì‹¤íŒ¨: {e}")
            return []


# =========================================
# ğŸ”§ Analyzer (ì‚¬ìš©ì ì¤‘ì‹¬ ë¶„ì„) - ì „ì²´ ìˆ˜ì •
# =========================================
@dataclass
class Analyzer:
    """
    ê°ì •/ìŠ¤íƒ€ì¼/í†µê³„ ë¶„ì„
    
    ğŸ”§ ìˆ˜ì • ì‚¬í•­:
    1. user_id íŒŒë¼ë¯¸í„° ì¶”ê°€
    2. ì‚¬ìš©ìë§Œ style_analysisì— ì €ì¥
    3. ì‚¬ìš©ì vs ìƒëŒ€ë°© ë¹„êµ í†µê³„
    4. scoreëŠ” ì‚¬ìš©ì ë§í•˜ê¸° ì ìˆ˜
    """
    verbose: bool = False

    # ğŸ”§ ìˆ˜ì •: user_id íŒŒë¼ë¯¸í„° ì¶”ê°€
    def analyze(
        self,
        conversation_df: pd.DataFrame,
        relations: List[Dict[str, Any]],
        user_id: int  # â† ğŸ”§ ì¶”ê°€
    ) -> Dict[str, Any]:
        """
        LLMìœ¼ë¡œ ëŒ€í™” ë¶„ì„ (ì‚¬ìš©ì ì¤‘ì‹¬)
        
        ğŸ”§ ìˆ˜ì • ì‚¬í•­:
        - user_id ê¸°ì¤€ ë¶„ì„
        - ì „ì²´ ëŒ€í™” ë§¥ë½ íŒŒì•…
        - ì‚¬ìš©ì vs ìƒëŒ€ë°© ë¹„êµ
        
        Args:
            conversation_df: ëŒ€í™” DataFrame
            relations: ê´€ê³„ ì •ë³´
            user_id: ë¶„ì„ ì˜ë¢° ì‚¬ìš©ì ID
        
        Returns:
            ë¶„ì„ ê²°ê³¼ (DB ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜)
        """
        llm = ChatOpenAI(model="gpt-4o-mini", api_key=settings.openai_api_key)
        
        # =========================================
        # ğŸ”§ ì¶”ê°€: ì‚¬ìš©ì/ìƒëŒ€ë°© DataFrame ë¶„ë¦¬
        # =========================================
        # ì´ìœ : ì‚¬ìš©ì ì¤‘ì‹¬ ë¶„ì„ + ë¹„êµ ë¶„ì„
        # =========================================
        
        user_df = conversation_df[conversation_df["speaker"] == str(user_id)]
        others_df = conversation_df[conversation_df["speaker"] != str(user_id)]
        
        if user_df.empty:
            raise ValueError(f"âŒ user_id={user_id}ì˜ ë°œí™”ê°€ ì—†ìŠµë‹ˆë‹¤!")
        
        if self.verbose:
            print(f"   ğŸ‘¤ ì‚¬ìš©ì ë°œí™”: {len(user_df)}ê°œ")
            print(f"   ğŸ‘¥ ìƒëŒ€ë°© ë°œí™”: {len(others_df)}ê°œ")
        
        # =========================================
        # ğŸ”§ ìˆ˜ì •: statistics ìƒì„± (ì‚¬ìš©ì vs ìƒëŒ€ë°© ë¹„êµ)
        # =========================================
        # ì´ìœ : ì‚¬ìš©ìì˜ ëŒ€í™” íŒ¨í„´ì„ ìƒëŒ€ì™€ ë¹„êµ
        # =========================================
        
        # ì‚¬ìš©ì í†µê³„
        user_texts = " ".join(user_df["text"].tolist())
        user_words = user_texts.split()
        
        user_stats = {
            "word_count": len(user_words),
            "avg_sentence_length": round(len(user_words) / len(user_df), 1),
            "unique_words": len(set(user_words)),
            "top_words": self._get_top_words(user_texts, top_n=5)
        }
        
        # ìƒëŒ€ë°© í†µê³„
        if not others_df.empty:
            others_texts = " ".join(others_df["text"].tolist())
            others_words = others_texts.split()
            
            others_stats = {
                "word_count": len(others_words),
                "avg_sentence_length": round(len(others_words) / len(others_df), 1),
                "unique_words": len(set(others_words)),
            }
        else:
            others_stats = {
                "word_count": 0,
                "avg_sentence_length": 0,
                "unique_words": 0,
            }
        
        # ë¹„êµ ë¶„ì„
        comparison = self._generate_comparison(user_stats, others_stats)
        
        # ğŸ”§ ìˆ˜ì •: statistics êµ¬ì¡° ë³€ê²½
        statistics = {
            "user": user_stats,
            "others": others_stats,
            "comparison": comparison
        }
        
        if self.verbose:
            print(f"   ğŸ“Š [Statistics] ì‚¬ìš©ì ë‹¨ì–´: {user_stats['word_count']}, "
                  f"ìƒëŒ€ë°© ë‹¨ì–´: {others_stats['word_count']}")
        
        # =========================================
        # ğŸ”§ ìˆ˜ì •: style_analysis ìƒì„± (ì‚¬ìš©ìë§Œ)
        # =========================================
        # ì´ìœ : ì‚¬ìš©ìì˜ ë§í•˜ê¸° ìŠ¤íƒ€ì¼ ë¶„ì„
        # ë§¥ë½: ì „ì²´ ëŒ€í™” í¬í•¨í•˜ì—¬ ë¶„ì„
        # =========================================
        
        # ì „ì²´ ëŒ€í™” ë§¥ë½
        full_context = "\n".join([
            f"í™”ì {row['speaker']}: {row['text']}"
            for _, row in conversation_df.iterrows()
        ])
        
        # ì‚¬ìš©ì ë°œí™”
        user_texts_joined = "\n".join(user_df["text"].tolist())
        
        # ğŸ”§ ìˆ˜ì •: LLM í”„ë¡¬í”„íŠ¸ ê°œì„ 
        style_prompt = f"""
ë‹¤ìŒì€ ëŒ€í™” ì „ì²´ ë§¥ë½ê³¼ ë¶„ì„ ëŒ€ìƒ ì‚¬ìš©ìì˜ ë°œí™”ì…ë‹ˆë‹¤.
**ì‚¬ìš©ì ID {user_id}**ì˜ ë§íˆ¬, ì„±í–¥, ê´€ì‹¬ì‚¬ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

**ì „ì²´ ëŒ€í™” ë§¥ë½:**
{full_context[:500]}...

**ë¶„ì„ ëŒ€ìƒ ì‚¬ìš©ì (ID: {user_id})ì˜ ë°œí™”:**
{user_texts_joined}

**í†µê³„ ì •ë³´:**
- ì‚¬ìš©ì í‰ê·  ë¬¸ì¥ ê¸¸ì´: {user_stats['avg_sentence_length']}
- ìƒëŒ€ë°© í‰ê·  ë¬¸ì¥ ê¸¸ì´: {others_stats['avg_sentence_length']}
- ì‚¬ìš©ì ë‹¨ì–´ ìˆ˜: {user_stats['word_count']}
- ìƒëŒ€ë°© ë‹¨ì–´ ìˆ˜: {others_stats['word_count']}

ì•„ë˜ í˜•ì‹ìœ¼ë¡œ JSON ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "ë§íˆ¬_íŠ¹ì§•_ë¶„ì„": "ì¡´ëŒ“ë§/ë°˜ë§ ì‚¬ìš©, íŠ¹ì • í‘œí˜„ ìŠµê´€, ë¬¸ì¥ ê¸¸ì´ íŠ¹ì§• ë“±",
  "ëŒ€í™”_ì„±í–¥_ë°_ê°ì •_í‘œí˜„": "ê¸ì •ì /ë¶€ì •ì , ê²©ë ¤/ë¹„íŒ ì„±í–¥, ê°ì • í‘œí˜„ ë°©ì‹ ë“±",
  "ì£¼ìš”_ê´€ì‹¬ì‚¬": "ëŒ€í™” ì£¼ì œì™€ ê´€ì‹¬ì‚¬",
  "ëŒ€í™”_ë¹„êµ_ë¶„ì„": "ìƒëŒ€ë°© ëŒ€ë¹„ ì‚¬ìš©ìì˜ ëŒ€í™” íŠ¹ì§• (ê°„ê²°í•¨, ìƒì„¸í•¨, ì£¼ë„ì„± ë“±)"
}}
"""
        
        try:
            response = llm.invoke(style_prompt)
            content = response.content if hasattr(response, "content") else str(response)
            
            if self.verbose:
                print(f"   ğŸ—£ï¸ [Style Analysis] ì‚¬ìš©ì: {content[:100]}...")
            
            # JSON íŒŒì‹± ì‹œë„
            import json
            try:
                user_analysis = json.loads(content)
            except:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ fallback
                user_analysis = {
                    "ë§íˆ¬_íŠ¹ì§•_ë¶„ì„": content[:100],
                    "ëŒ€í™”_ì„±í–¥_ë°_ê°ì •_í‘œí˜„": "ë¶„ì„ ì¤‘",
                    "ì£¼ìš”_ê´€ì‹¬ì‚¬": "ë¶„ì„ ì¤‘",
                    "ëŒ€í™”_ë¹„êµ_ë¶„ì„": "ë¶„ì„ ì¤‘"
                }
            
            # ğŸ”§ ìˆ˜ì •: user_idë§Œ ì €ì¥
            style_analysis = {
                str(user_id): user_analysis
            }
            
        except Exception as e:
            print(f"âš ï¸ ì‚¬ìš©ì ìŠ¤íƒ€ì¼ ë¶„ì„ LLM ì‹¤íŒ¨: {e}")
            style_analysis = {
                str(user_id): {
                    "ë§íˆ¬_íŠ¹ì§•_ë¶„ì„": "ë¶„ì„ ì‹¤íŒ¨",
                    "ëŒ€í™”_ì„±í–¥_ë°_ê°ì •_í‘œí˜„": "ë¶„ì„ ì‹¤íŒ¨",
                    "ì£¼ìš”_ê´€ì‹¬ì‚¬": "ë¶„ì„ ì‹¤íŒ¨",
                    "ëŒ€í™”_ë¹„êµ_ë¶„ì„": "ë¶„ì„ ì‹¤íŒ¨"
                }
            }
        
        # =========================================
        # 3ï¸âƒ£ summary ìƒì„± (ì „ì²´ ëŒ€í™” ìš”ì•½) - ê¸°ì¡´ ìœ ì§€
        # =========================================
        
        summary_prompt = f"""
ë‹¤ìŒ ëŒ€í™”ë¥¼ 100-200ìë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”. ì£¼ìš” ì£¼ì œì™€ ë¶„ìœ„ê¸°ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.

ëŒ€í™”:
{full_context}

ìš”ì•½ (100-200ì):
"""
        
        try:
            response = llm.invoke(summary_prompt)
            summary = response.content if hasattr(response, "content") else str(response)
            summary = summary.strip()
            
            if self.verbose:
                print(f"   ğŸ“ [Summary] {summary[:50]}...")
                
        except Exception as e:
            print(f"âš ï¸ ìš”ì•½ LLM ì‹¤íŒ¨: {e}")
            summary = "ëŒ€í™” ìš”ì•½ ìƒì„± ì‹¤íŒ¨"
        
        # =========================================
        # ğŸ”§ ìˆ˜ì •: score ê³„ì‚° (ì‚¬ìš©ì ë§í•˜ê¸° ì ìˆ˜)
        # =========================================
        # ì´ìœ : ì‚¬ìš©ìì˜ ë§í•˜ê¸° ëŠ¥ë ¥ í‰ê°€
        # =========================================
        
        score = self._calculate_user_score(user_stats, others_stats, user_analysis)
        
        if self.verbose:
            print(f"   ğŸ¯ [Score] ì‚¬ìš©ì ë§í•˜ê¸° ì ìˆ˜: {score:.2f}")
        
        # =========================================
        # âœ… ìµœì¢… ê²°ê³¼ ë°˜í™˜
        # =========================================
        
        return {
            "summary": summary,
            "style_analysis": style_analysis,
            "statistics": statistics,
            "score": score,
        }
    
    # ğŸ”§ ì¶”ê°€: ë¹„êµ ë¶„ì„ í…ìŠ¤íŠ¸ ìƒì„±
    def _generate_comparison(self, user_stats: Dict, others_stats: Dict) -> str:
        """
        ì‚¬ìš©ì vs ìƒëŒ€ë°© ë¹„êµ ë¶„ì„ í…ìŠ¤íŠ¸ ìƒì„±
        
        Args:
            user_stats: ì‚¬ìš©ì í†µê³„
            others_stats: ìƒëŒ€ë°© í†µê³„
        
        Returns:
            ë¹„êµ ë¶„ì„ í…ìŠ¤íŠ¸
        """
        comparisons = []
        
        # ë‹¨ì–´ ìˆ˜ ë¹„êµ
        if others_stats["word_count"] > 0:
            word_ratio = user_stats["word_count"] / others_stats["word_count"]
            if word_ratio < 0.7:
                comparisons.append("ì‚¬ìš©ìëŠ” ìƒëŒ€ë°©ë³´ë‹¤ ë§ì„ ì ê²Œ í•¨")
            elif word_ratio > 1.3:
                comparisons.append("ì‚¬ìš©ìëŠ” ìƒëŒ€ë°©ë³´ë‹¤ ë§ì„ ë§ì´ í•¨")
            else:
                comparisons.append("ì‚¬ìš©ìì™€ ìƒëŒ€ë°©ì˜ ëŒ€í™”ëŸ‰ì´ ë¹„ìŠ·í•¨")
        
        # ë¬¸ì¥ ê¸¸ì´ ë¹„êµ
        if others_stats["avg_sentence_length"] > 0:
            len_diff = user_stats["avg_sentence_length"] - others_stats["avg_sentence_length"]
            if len_diff < -2:
                comparisons.append("ì‚¬ìš©ìëŠ” ì§§ì€ ë¬¸ì¥ì„ ì„ í˜¸")
            elif len_diff > 2:
                comparisons.append("ì‚¬ìš©ìëŠ” ê¸´ ë¬¸ì¥ì„ ì„ í˜¸")
        
        return ", ".join(comparisons) if comparisons else "ë¹„êµ ë°ì´í„° ë¶€ì¡±"
    
    # ğŸ”§ ì¶”ê°€: ì‚¬ìš©ì ë§í•˜ê¸° ì ìˆ˜ ê³„ì‚°
    def _calculate_user_score(
        self,
        user_stats: Dict,
        others_stats: Dict,
        user_analysis: Dict
    ) -> float:
        """
        ì‚¬ìš©ì ë§í•˜ê¸° ì ìˆ˜ ê³„ì‚°
        
        Args:
            user_stats: ì‚¬ìš©ì í†µê³„
            others_stats: ìƒëŒ€ë°© í†µê³„
            user_analysis: ì‚¬ìš©ì ìŠ¤íƒ€ì¼ ë¶„ì„
        
        Returns:
            ë§í•˜ê¸° ì ìˆ˜ (0.0 ~ 1.0)
        
        í‰ê°€ ê¸°ì¤€:
        1. ì–´íœ˜ ë‹¤ì–‘ì„± (unique_words / word_count)
        2. ëŒ€í™” ì°¸ì—¬ë„ (user vs others ë¹„ìœ¨)
        3. ë¬¸ì¥ êµ¬ì¡° (avg_sentence_length)
        """
        score_components = []
        
        # 1. ì–´íœ˜ ë‹¤ì–‘ì„± (0 ~ 0.4ì )
        if user_stats["word_count"] > 0:
            vocab_diversity = user_stats["unique_words"] / user_stats["word_count"]
            vocab_score = min(0.4, vocab_diversity * 0.8)
            score_components.append(vocab_score)
        
        # 2. ëŒ€í™” ì°¸ì—¬ë„ (0 ~ 0.3ì )
        if others_stats["word_count"] > 0:
            participation_ratio = user_stats["word_count"] / (user_stats["word_count"] + others_stats["word_count"])
            # 0.4 ~ 0.6 ë¹„ìœ¨ì´ ì´ìƒì 
            if 0.4 <= participation_ratio <= 0.6:
                participation_score = 0.3
            else:
                participation_score = 0.3 * (1 - abs(participation_ratio - 0.5) * 2)
            score_components.append(participation_score)
        
        # 3. ë¬¸ì¥ êµ¬ì¡° (0 ~ 0.3ì )
        # 5 ~ 10 ë‹¨ì–´ê°€ ì´ìƒì 
        avg_len = user_stats["avg_sentence_length"]
        if 5 <= avg_len <= 10:
            structure_score = 0.3
        elif avg_len < 5:
            structure_score = 0.3 * (avg_len / 5)
        else:
            structure_score = 0.3 * (10 / avg_len)
        score_components.append(structure_score)
        
        # ìµœì¢… ì ìˆ˜
        final_score = sum(score_components)
        
        # 0.5 ~ 1.0 ë²”ìœ„ë¡œ ì •ê·œí™”
        normalized_score = 0.5 + (final_score * 0.5)
        
        return round(min(1.0, max(0.0, normalized_score)), 2)
    
    def _get_top_words(self, text: str, top_n: int = 5) -> List[str]:
        """
        ë¹ˆë„ ë†’ì€ ë‹¨ì–´ ì¶”ì¶œ (í•œê¸€ ê¸°ì¤€)
        
        Args:
            text: ì „ì²´ í…ìŠ¤íŠ¸
            top_n: ìƒìœ„ Nê°œ
        
        Returns:
            ë¹ˆë„ ë†’ì€ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸
        """
        from collections import Counter
        import re
        
        # í•œê¸€ë§Œ ì¶”ì¶œ
        words = re.findall(r'[ê°€-í£]+', text)
        
        # 1ê¸€ì ë‹¨ì–´ ì œì™¸, ì¡°ì‚¬ ì œì™¸ (ê°„ë‹¨í•œ í•„í„°)
        words = [w for w in words if len(w) >= 2]
        
        # ë¹ˆë„ ê³„ì‚°
        word_counts = Counter(words)
        
        # ìƒìœ„ Nê°œ ì¶”ì¶œ
        top_words = [word for word, count in word_counts.most_common(top_n)]
        
        return top_words


# =========================================
# âœ… ScoreEvaluator (ê¸°ì¡´ ìœ ì§€) - ìˆ˜ì • ì—†ìŒ
# =========================================
@dataclass
class ScoreEvaluator:
    """ì‹ ë¢°ë„ í‰ê°€"""
    def evaluate(self, result: Dict[str, Any]) -> bool:
        """
        ë¶„ì„ ê²°ê³¼ì˜ ì‹ ë¢°ë„ í‰ê°€
        
        Args:
            result: Analyzer ê²°ê³¼
        
        Returns:
            ì‹ ë¢°ë„ >= 0.65 ì—¬ë¶€
        """
        score = result.get("score", 0)
        return score >= 0.65


# =========================================
# ğŸ”§ AnalysisSaver (DB ì—°ë™) - ë¶€ë¶„ ìˆ˜ì •
# =========================================
@dataclass
class AnalysisSaver:
    """
    âœ… DBì— ë¶„ì„ ê²°ê³¼ ì €ì¥
    
    ğŸ”§ ìˆ˜ì • ì‚¬í•­:
    - statistics ì €ì¥ (ë¹ˆ dict â†’ ì‹¤ì œ ë°ì´í„°)
    """
    verbose: bool = False  # ğŸ”§ ì¶”ê°€
    
    def save(self, db: Session, result: Dict[str, Any], state) -> Dict[str, Any]:
        """
        analysis_result í…Œì´ë¸”ì— INSERT
        
        Args:
            db: SQLAlchemy ì„¸ì…˜
            result: Analyzer ê²°ê³¼
            state: AnalysisState
        
        Returns:
            ì €ì¥ ê²°ê³¼
        """
        if not result:
            return {"status": "no_result"}
        
        try:
            # ğŸ”§ ìˆ˜ì •: statistics ì‹¤ì œ ë°ì´í„° ì €ì¥
            saved = save_analysis_result(
                db=db,
                user_id=str(state.user_id),
                conv_id=str(state.conv_id),
                summary=result.get("summary", ""),
                style_analysis=result.get("style_analysis", {}),
                statistics=result.get("statistics", {}),  # â† ğŸ”§ ìˆ˜ì •
                score=result.get("score", 0.0),
                confidence_score=0.0,  # QAì—ì„œ ì—…ë°ì´íŠ¸
                conversation_count=len(state.conversation_df) if state.conversation_df is not None else 0,
                feedback=None,
            )
            
            print(f"âœ… [AnalysisSaver] DB ì €ì¥ ì™„ë£Œ: analysis_id={saved['analysis_id']}")
            
            # ğŸ”§ ì¶”ê°€: ì €ì¥ëœ ë°ì´í„° ìƒì„¸ ì¶œë ¥
            if self.verbose:
                print(f"   â†’ summary: {result.get('summary', '')[:50]}...")
                print(f"   â†’ score: {result.get('score', 0):.2f}")
                
                # statistics í™•ì¸
                stats = result.get("statistics", {})
                if stats:
                    user_stats = stats.get("user", {})
                    print(f"   â†’ ì‚¬ìš©ì ë‹¨ì–´ ìˆ˜: {user_stats.get('word_count', 0)}")
                    print(f"   â†’ ì‚¬ìš©ì í‰ê·  ë¬¸ì¥ ê¸¸ì´: {user_stats.get('avg_sentence_length', 0)}")
            
            # âœ… stateì— ì €ì¥
            state.meta["analysis_id"] = saved["analysis_id"]
            
            return {
                "status": "saved",
                "analysis_id": saved["analysis_id"],
            }
            
        except Exception as e:
            print(f"âŒ [AnalysisSaver] ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return {"status": "error", "error": str(e)}