# app/agent/Analysis/nodes.py
from __future__ import annotations
from dataclasses import dataclass
from typing import Any, Dict, List, Tuple
from app.core.config import settings
from langchain_openai import ChatOpenAI
import pandas as pd
from sqlalchemy.orm import Session

# âœ… CRUD í•¨ìˆ˜ import
from app.agent.crud import (
    get_user_by_id,
    get_family_by_id,
    save_analysis_result,
)


# =========================================
# âœ… UserFetcher (DB ì—°ë™)
# =========================================
@dataclass
class UserFetcher:
    """
    âœ… DBì—ì„œ ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ
    
    ë³€ê²½ ì‚¬í•­:
    - ê¸°ì¡´: Mock user_df
    - ë³€ê²½: DB users í…Œì´ë¸” ì¡°íšŒ
    """
    def fetch(self, db: Session, conv_state) -> Dict[str, Any]:
        """
        users í…Œì´ë¸”ì—ì„œ ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ
        
        Args:
            db: SQLAlchemy ì„¸ì…˜
            conv_state: AnalysisState (user_id í¬í•¨)
        
        Returns:
            ì‚¬ìš©ì ì •ë³´ Dict
        """
        user_id = conv_state.user_id
        
        if not user_id:
            raise ValueError("âŒ UserFetcher: user_idê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # âœ… DB ì¡°íšŒ
        user = get_user_by_id(db, user_id)
        
        if not user:
            raise ValueError(f"âŒ UserFetcher: user_id={user_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"âœ… [UserFetcher] ì‚¬ìš©ì ì¡°íšŒ: {user.get('user_name')}")
        
        return user


# =========================================
# âœ… FamilyChecker (DB ì—°ë™) --> ì„ì‹œë¡œ í•­ìƒ Faslse ë°˜í™˜í•˜ê²Œ êµ¬í˜„ë¨
# =========================================
# =========================================
# âœ… FamilyChecker (ê°€ì¡± ê¸°ëŠ¥ ë¹„í™œì„±í™”)
# =========================================
@dataclass
class FamilyChecker:
    """
    âœ… ê°€ì¡± ê´€ê³„ í™•ì¸ (í˜„ì¬ ë¹„í™œì„±í™”)
    
    í˜„ì¬ ìƒíƒœ:
    - users â†” family ì—°ê²° ì»¬ëŸ¼ ì—†ìŒ
    - í•­ìƒ False ë°˜í™˜ â†’ LLM ì¶”ë¡  ëª¨ë“œ
    """
    def check(self, db: Session, user_info: Dict[str, Any]) -> Tuple[bool, int]:
        """
        ê°€ì¡± ì •ë³´ í™•ì¸ (í˜„ì¬ ë¹„í™œì„±í™”)
        
        Args:
            db: SQLAlchemy ì„¸ì…˜
            user_info: UserFetcher ê²°ê³¼
        
        Returns:
            (False, None) - í•­ìƒ LLM ì¶”ë¡  ëª¨ë“œ
        """
        print(f"âš ï¸  [FamilyChecker] ê°€ì¡± ê¸°ëŠ¥ ë¹„í™œì„±í™” â†’ LLM ì¶”ë¡  ëª¨ë“œ")
        return False, None


# =========================================
# âœ… RelationResolver_DB (ë¹„í™œì„±í™”)
# =========================================
@dataclass
class RelationResolver_DB:
    """
    âœ… DBì—ì„œ ê°€ì¡± êµ¬ì„±ì› ì¡°íšŒ (í˜„ì¬ ë¹„í™œì„±í™”)
    
    í˜„ì¬ ìƒíƒœ:
    - family_member í…Œì´ë¸” ì—†ìŒ
    - ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    """
    def resolve(self, db: Session, fam_id: int) -> List[Dict[str, Any]]:
        """
        ê°€ì¡± êµ¬ì„±ì› ì¡°íšŒ (í˜„ì¬ ë¹„í™œì„±í™”)
        
        Args:
            db: SQLAlchemy ì„¸ì…˜
            fam_id: ê°€ì¡± ID
        
        Returns:
            [] - ë¹ˆ ë¦¬ìŠ¤íŠ¸
        """
        print(f"âš ï¸  [RelationResolver_DB] ê°€ì¡± ê¸°ëŠ¥ ë¹„í™œì„±í™”")
        return []


# =========================================
# âœ… RelationResolver_LLM (ê¸°ì¡´ ìœ ì§€)
# =========================================
@dataclass
class RelationResolver_LLM:
    """LLM ê¸°ë°˜ ê´€ê³„ ì¶”ë¡ """
    verbose: bool = False

    def resolve(self, conversation_df: pd.DataFrame) -> List[Dict[str, Any]]:
        """
        LLMìœ¼ë¡œ ëŒ€í™”ì—ì„œ ê´€ê³„ ì¶”ë¡ 
        
        Args:
            conversation_df: ëŒ€í™” DataFrame
        
        Returns:
            ì¶”ë¡ ëœ ê´€ê³„ ë¦¬ìŠ¤íŠ¸
        """
        llm = ChatOpenAI(model="gpt-4o-mini", api_key=settings.openai_api_key)
        text_snippet = "\n".join(conversation_df["text"].tolist()[:10])
        
        prompt = f"""
ë‹¤ìŒ ëŒ€í™”ì—ì„œ ë“±ì¥í•˜ëŠ” ì¸ë¬¼ë“¤ì˜ ê´€ê³„ë¥¼ ì¶”ë¡ í•´ì¤˜.
ì˜ˆ: ì—„ë§ˆ, ì•„ë“¤, ì•„ë¹ , ì¹œêµ¬ ë“±

ëŒ€í™” ë‚´ìš©:
{text_snippet}

ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ ë°˜í™˜í•´ì¤˜.
ì˜ˆ: [{{"speaker":"1","relation":"ì—„ë§ˆ"}}, {{"speaker":"2","relation":"ì•„ë“¤"}}]
"""
        
        try:
            response = llm.invoke(prompt)
            content = response.content if hasattr(response, "content") else str(response)
            
            if self.verbose:
                print(f"ğŸ§  [RelationResolver_LLM] ì‘ë‹µ: {content[:200]}")
            
            # âœ… ê°„ë‹¨í•œ fallback
            return [
                {"speaker": "1", "relation": "ì°¸ì„ì1"},
                {"speaker": "2", "relation": "ì°¸ì„ì2"}
            ]
            
        except Exception as e:
            print(f"âš ï¸ Relation LLM ì‹¤íŒ¨: {e}")
            return []


# =========================================
# âœ… Analyzer
# =========================================
@dataclass
class Analyzer:
    """ê°ì •/ìŠ¤íƒ€ì¼/í†µê³„ ë¶„ì„"""
    verbose: bool = False

    def analyze(self, conversation_df: pd.DataFrame, relations: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        LLMìœ¼ë¡œ ëŒ€í™” ë¶„ì„
        
        ğŸ”§ ìˆ˜ì • ì‚¬í•­:
        1. statistics ìƒì„± (ë‹¨ì–´ ìˆ˜, í‰ê·  ë¬¸ì¥ ê¸¸ì´ ë“±)
        2. style_analysis ìƒì„± (í™”ìë³„ ë§íˆ¬/ì„±í–¥/ê´€ì‹¬ì‚¬)
        3. summary ìƒì„± (LLM ê¸°ë°˜ ëŒ€í™” ìš”ì•½)
        
        Args:
            conversation_df: ëŒ€í™” DataFrame
            relations: ê´€ê³„ ì •ë³´
        
        Returns:
            ë¶„ì„ ê²°ê³¼ (DB ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜)
        """
        llm = ChatOpenAI(model="gpt-4o-mini", api_key=settings.openai_api_key)
        
        # =========================================
        # 1ï¸âƒ£ statistics ìƒì„± (ê¸°ë³¸ í†µê³„)
        # =========================================
        # ì´ìœ : ëŒ€í™”ì˜ ì •ëŸ‰ì  íŠ¹ì§• ë¶„ì„
        # =========================================
        
        all_texts = " ".join(conversation_df["text"].tolist())
        words = all_texts.split()
        
        statistics = {
            "word_count": len(words),  # ì´ ë‹¨ì–´ ìˆ˜
            "avg_sentence_length": round(len(words) / len(conversation_df), 1),  # í‰ê·  ë¬¸ì¥ ê¸¸ì´
            "unique_words": len(set(words)),  # ê³ ìœ  ë‹¨ì–´ ìˆ˜
            "top_words": self._get_top_words(all_texts, top_n=5)  # ë¹ˆë„ ë†’ì€ ë‹¨ì–´ 5ê°œ
        }
        
        if self.verbose:
            print(f"   ğŸ“Š [Statistics] ë‹¨ì–´ ìˆ˜: {statistics['word_count']}, "
                  f"ê³ ìœ  ë‹¨ì–´: {statistics['unique_words']}")
        
        # =========================================
        # 2ï¸âƒ£ style_analysis ìƒì„± (í™”ìë³„ ë¶„ì„)
        # =========================================
        # ì´ìœ : ê° í™”ìì˜ ë§íˆ¬/ì„±í–¥/ê´€ì‹¬ì‚¬ ë¶„ì„
        # =========================================
        
        style_analysis = {}
        
        # í™”ìë³„ë¡œ ë¶„ì„
        unique_speakers = conversation_df["speaker"].unique()
        
        for speaker in unique_speakers:
            speaker_texts = conversation_df[conversation_df["speaker"] == speaker]["text"].tolist()
            speaker_text_joined = "\n".join(speaker_texts)
            
            # LLM í”„ë¡¬í”„íŠ¸
            prompt = f"""
ë‹¤ìŒ ëŒ€í™”ì—ì„œ í™”ì {speaker}ì˜ ë§íˆ¬, ì„±í–¥, ê´€ì‹¬ì‚¬ë¥¼ ë¶„ì„í•´ì¤˜.

í™”ì {speaker}ì˜ ë°œí™”:
{speaker_text_joined}

ì•„ë˜ í˜•ì‹ìœ¼ë¡œ JSON ì‘ë‹µí•´ì¤˜:
{{
  "ë§íˆ¬_íŠ¹ì§•_ë¶„ì„": "ì¡´ëŒ“ë§/ë°˜ë§ ì‚¬ìš©, íŠ¹ì • í‘œí˜„ ìŠµê´€ ë“±",
  "ëŒ€í™”_ì„±í–¥_ë°_ê°ì •_í‘œí˜„": "ê¸ì •ì /ë¶€ì •ì , ê²©ë ¤/ë¹„íŒ ì„±í–¥ ë“±",
  "ì£¼ìš”_ê´€ì‹¬ì‚¬": "ëŒ€í™” ì£¼ì œì™€ ê´€ì‹¬ì‚¬"
}}
"""
            
            try:
                response = llm.invoke(prompt)
                content = response.content if hasattr(response, "content") else str(response)
                
                if self.verbose:
                    print(f"   ğŸ—£ï¸ [Style Analysis] í™”ì {speaker}: {content[:100]}...")
                
                # JSON íŒŒì‹± ì‹œë„
                import json
                try:
                    speaker_analysis = json.loads(content)
                except:
                    # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ fallback
                    speaker_analysis = {
                        "ë§íˆ¬_íŠ¹ì§•_ë¶„ì„": content[:100],
                        "ëŒ€í™”_ì„±í–¥_ë°_ê°ì •_í‘œí˜„": "ë¶„ì„ ì¤‘",
                        "ì£¼ìš”_ê´€ì‹¬ì‚¬": "ë¶„ì„ ì¤‘"
                    }
                
                style_analysis[str(speaker)] = speaker_analysis
                
            except Exception as e:
                print(f"âš ï¸ í™”ì {speaker} ìŠ¤íƒ€ì¼ ë¶„ì„ LLM ì‹¤íŒ¨: {e}")
                style_analysis[str(speaker)] = {
                    "ë§íˆ¬_íŠ¹ì§•_ë¶„ì„": "ë¶„ì„ ì‹¤íŒ¨",
                    "ëŒ€í™”_ì„±í–¥_ë°_ê°ì •_í‘œí˜„": "ë¶„ì„ ì‹¤íŒ¨",
                    "ì£¼ìš”_ê´€ì‹¬ì‚¬": "ë¶„ì„ ì‹¤íŒ¨"
                }
        
        # =========================================
        # 3ï¸âƒ£ summary ìƒì„± (ì „ì²´ ëŒ€í™” ìš”ì•½)
        # =========================================
        # ì´ìœ : ëŒ€í™” ì „ì²´ ë§¥ë½ íŒŒì•…
        # =========================================
        
        full_text = "\n".join([
            f"í™”ì {row['speaker']}: {row['text']}"
            for _, row in conversation_df.iterrows()
        ])
        
        summary_prompt = f"""
ë‹¤ìŒ ëŒ€í™”ë¥¼ 100-200ìë¡œ ìš”ì•½í•´ì¤˜. ì£¼ìš” ì£¼ì œì™€ ë¶„ìœ„ê¸°ë¥¼ í¬í•¨í•´ì¤˜.

ëŒ€í™”:
{full_text}

ìš”ì•½ (100-200ì):
"""
        
        try:
            response = llm.invoke(summary_prompt)
            summary = response.content if hasattr(response, "content") else str(response)
            summary = summary.strip()
            
            if self.verbose:
                print(f"   ğŸ“ [Summary] {summary[:50]}...")
                
        except Exception as e:
            print(f"âš ï¸ ìš”ì•½ LLM ì‹¤íŒ¨: {e}")
            summary = "ëŒ€í™” ìš”ì•½ ìƒì„± ì‹¤íŒ¨"
        
        # =========================================
        # 4ï¸âƒ£ score ê³„ì‚° (ê°„ë‹¨í•œ ì ìˆ˜ ì‚°ì •)
        # =========================================
        # ì´ìœ : ëŒ€í™” í’ˆì§ˆ ì ìˆ˜í™”
        # =========================================
        
        # ê°„ë‹¨í•œ ì ìˆ˜ ë¡œì§ (ì¶”í›„ ê°œì„  ê°€ëŠ¥)
        score = min(1.0, (statistics["word_count"] / 100) * 0.5 + 0.5)
        score = round(score, 2)
        
        # =========================================
        # âœ… ìµœì¢… ê²°ê³¼ ë°˜í™˜
        # =========================================
        
        return {
            "summary": summary,
            "style_analysis": style_analysis,
            "statistics": statistics,
            "score": score,
        }
    
    def _get_top_words(self, text: str, top_n: int = 5) -> List[str]:
        """
        ë¹ˆë„ ë†’ì€ ë‹¨ì–´ ì¶”ì¶œ (í•œê¸€ ê¸°ì¤€)
        
        Args:
            text: ì „ì²´ í…ìŠ¤íŠ¸
            top_n: ìƒìœ„ Nê°œ
        
        Returns:
            ë¹ˆë„ ë†’ì€ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸
        """
        from collections import Counter
        import re
        
        # í•œê¸€ë§Œ ì¶”ì¶œ
        words = re.findall(r'[ê°€-í£]+', text)
        
        # 1ê¸€ì ë‹¨ì–´ ì œì™¸, ì¡°ì‚¬ ì œì™¸ (ê°„ë‹¨í•œ í•„í„°)
        words = [w for w in words if len(w) >= 2]
        
        # ë¹ˆë„ ê³„ì‚°
        word_counts = Counter(words)
        
        # ìƒìœ„ Nê°œ ì¶”ì¶œ
        top_words = [word for word, count in word_counts.most_common(top_n)]
        
        return top_words


# =========================================
# âœ… ScoreEvaluator (ê¸°ì¡´ ìœ ì§€)
# =========================================
@dataclass
class ScoreEvaluator:
    """ì‹ ë¢°ë„ í‰ê°€"""
    def evaluate(self, result: Dict[str, Any]) -> bool:
        """
        ë¶„ì„ ê²°ê³¼ì˜ ì‹ ë¢°ë„ í‰ê°€
        
        Args:
            result: Analyzer ê²°ê³¼
        
        Returns:
            ì‹ ë¢°ë„ >= 0.65 ì—¬ë¶€
        """
        score = result.get("score", 0)
        return score >= 0.65


# =========================================
# âœ… AnalysisSaver (DB ì—°ë™)
# =========================================
@dataclass
class AnalysisSaver:
    """
    âœ… DBì— ë¶„ì„ ê²°ê³¼ ì €ì¥
    
    ë³€ê²½ ì‚¬í•­:
    - ê¸°ì¡´: Mock analysis_result_df
    - ë³€ê²½: DB analysis_result í…Œì´ë¸” INSERT
    """
    def save(self, db: Session, result: Dict[str, Any], state) -> Dict[str, Any]:
        """
        analysis_result í…Œì´ë¸”ì— INSERT
        
        Args:
            db: SQLAlchemy ì„¸ì…˜
            result: Analyzer ê²°ê³¼
            state: AnalysisState
        
        Returns:
            ì €ì¥ ê²°ê³¼
        """
        if not result:
            return {"status": "no_result"}
        
        try:
            # âœ… DB INSERT
            saved = save_analysis_result(
                db=db,
                user_id=str(state.user_id),
                conv_id=str(state.conv_id),
                summary=result.get("summary", ""),
                style_analysis=result.get("style_analysis", {}),
                statistics={},  # ì¶”í›„ ì¶”ê°€
                score=result.get("score", 0.0),
                confidence_score=0.0,  # QAì—ì„œ ì—…ë°ì´íŠ¸
                conversation_count=len(state.conversation_df) if state.conversation_df is not None else 0,
                feedback=None,
            )
            
            print(f"âœ… [AnalysisSaver] DB ì €ì¥ ì™„ë£Œ: analysis_id={saved['analysis_id']}")
            
            # âœ… stateì— ì €ì¥
            state.meta["analysis_id"] = saved["analysis_id"]
            
            return {
                "status": "saved",
                "analysis_id": saved["analysis_id"],
            }
            
        except Exception as e:
            print(f"âŒ [AnalysisSaver] ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return {"status": "error", "error": str(e)}