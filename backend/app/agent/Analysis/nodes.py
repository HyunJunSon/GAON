# app/agent/Analysis/nodes.py
from __future__ import annotations
from dataclasses import dataclass
from typing import Any, Dict, List, Tuple
from app.core.config import settings
from langchain_openai import ChatOpenAI
import pandas as pd
from sqlalchemy.orm import Session
from collections import Counter
import re
import json

# âœ… CRUD í•¨ìˆ˜ import
from app.agent.crud import (
    get_user_by_id,
    get_family_by_id,
    save_analysis_result,
)


# =========================================
# âœ… UserFetcher (DB ì—°ë™)
# =========================================
@dataclass
class UserFetcher:
    """
    âœ… DBì—ì„œ ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ
    
    ë³€ê²½ ì‚¬í•­:
    - ê¸°ì¡´: Mock user_df
    - ë³€ê²½: DB users í…Œì´ë¸” ì¡°íšŒ
    """
    def fetch(self, db: Session, conv_state) -> Dict[str, Any]:
        """
        users í…Œì´ë¸”ì—ì„œ ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ
        
        Args:
            db: SQLAlchemy ì„¸ì…˜
            conv_state: AnalysisState (id í¬í•¨)
        
        Returns:
            ì‚¬ìš©ì ì •ë³´ Dict
        """
        id = conv_state.id
        
        if not id:
            raise ValueError("âŒ UserFetcher: idê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # âœ… DB ì¡°íšŒ
        user = get_user_by_id(db, id)
        
        if not user:
            raise ValueError(f"âŒ UserFetcher: id={id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"âœ… [UserFetcher] ì‚¬ìš©ì ì¡°íšŒ: {user.get('user_name')}")
        
        return user


# =========================================
# âœ… FamilyChecker (ê°€ì¡± ê¸°ëŠ¥ ë¹„í™œì„±í™”) - ìˆ˜ì • ì—†ìŒ
# =========================================
@dataclass
class FamilyChecker:
    """
    âœ… ê°€ì¡± ê´€ê³„ í™•ì¸ (í˜„ì¬ ë¹„í™œì„±í™”)
    
    í˜„ì¬ ìƒíƒœ:
    - users â†” family ì—°ê²° ì»¬ëŸ¼ ì—†ìŒ
    - í•­ìƒ False ë°˜í™˜ â†’ LLM ì¶”ë¡  ëª¨ë“œ
    """
    def check(self, db: Session, user_info: Dict[str, Any]) -> Tuple[bool, int]:
        """
        ê°€ì¡± ì •ë³´ í™•ì¸ (í˜„ì¬ ë¹„í™œì„±í™”)
        
        Args:
            db: SQLAlchemy ì„¸ì…˜
            user_info: UserFetcher ê²°ê³¼
        
        Returns:
            (False, None) - í•­ìƒ LLM ì¶”ë¡  ëª¨ë“œ
        """
        print(f"âš ï¸  [FamilyChecker] ê°€ì¡± ê¸°ëŠ¥ ë¹„í™œì„±í™” â†’ LLM ì¶”ë¡  ëª¨ë“œ")
        return False, None


# =========================================
# âœ… RelationResolver_DB (ë¹„í™œì„±í™”)
# =========================================
@dataclass
class RelationResolver_DB:
    """
    âœ… DBì—ì„œ ê°€ì¡± êµ¬ì„±ì› ì¡°íšŒ (í˜„ì¬ ë¹„í™œì„±í™”)
    
    í˜„ì¬ ìƒíƒœ:
    - family_member í…Œì´ë¸” ì—†ìŒ
    - ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    """
    def resolve(self, db: Session, fam_id: int) -> List[Dict[str, Any]]:
        """
        ê°€ì¡± êµ¬ì„±ì› ì¡°íšŒ (í˜„ì¬ ë¹„í™œì„±í™”)
        
        Args:
            db: SQLAlchemy ì„¸ì…˜
            fam_id: ê°€ì¡± ID
        
        Returns:
            [] - ë¹ˆ ë¦¬ìŠ¤íŠ¸
        """
        print(f"âš ï¸  [RelationResolver_DB] ê°€ì¡± ê¸°ëŠ¥ ë¹„í™œì„±í™”")
        return []


# =========================================
# âœ… RelationResolver_LLM 
# =========================================
@dataclass
class RelationResolver_LLM:
    """LLM ê¸°ë°˜ ê´€ê³„ ì¶”ë¡ """
    verbose: bool = False

    def resolve(self, conversation_df: pd.DataFrame) -> List[Dict[str, Any]]:
        """
        LLMìœ¼ë¡œ ëŒ€í™”ì—ì„œ ê´€ê³„ ì¶”ë¡ 
        
        Args:
            conversation_df: ëŒ€í™” DataFrame
        
        Returns:
            ì¶”ë¡ ëœ ê´€ê³„ ë¦¬ìŠ¤íŠ¸
        """
        llm = ChatOpenAI(model="gpt-4o-mini", api_key=settings.openai_api_key)
        text_snippet = "\n".join(conversation_df["text"].tolist()[:10])
        
        prompt = f"""
ë‹¤ìŒ ëŒ€í™”ì—ì„œ ë“±ì¥í•˜ëŠ” ì¸ë¬¼ë“¤ì˜ ê´€ê³„ë¥¼ ì¶”ë¡ í•´ì¤˜.
ì˜ˆ: ì—„ë§ˆ, ì•„ë“¤, ì•„ë¹ , ì¹œêµ¬ ë“±

ëŒ€í™” ë‚´ìš©:
{text_snippet}

ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ ë°˜í™˜í•´ì¤˜.
ì˜ˆ: [{{"speaker":1,"relation":"ì—„ë§ˆ"}}, {{"speaker":2,"relation":"ì•„ë“¤"}}]
speakerëŠ” ë°˜ë“œì‹œ int í˜•íƒœë¡œ ë°˜í™˜í•´ì•¼í•´.
"""
        
        try:
            response = llm.invoke(prompt)
            content = response.content if hasattr(response, "content") else str(response)
            
            if self.verbose:
                print(f"ğŸ§  [RelationResolver_LLM] ì‘ë‹µ: {content[:200]}")
            
            # âœ… ê°„ë‹¨í•œ fallback
            return [
                {"speaker": 1, "relation": "ì°¸ì„ì1"},
                {"speaker": 2, "relation": "ì°¸ì„ì2"}
            ]
            
        except Exception as e:
            print(f"âš ï¸ Relation LLM ì‹¤íŒ¨: {e}")
            return []


# =========================================
# ğŸ”§ Analyzer (ì‚¬ìš©ì ì¤‘ì‹¬ ë¶„ì„)
# =========================================

@dataclass
class Analyzer:
        """
        ê°ì •/ìŠ¤íƒ€ì¼/í†µê³„ ë¶„ì„
        
        ğŸ”§ ìˆ˜ì • ì‚¬í•­:
        1. id íŒŒë¼ë¯¸í„° ì¶”ê°€
        2. ì‚¬ìš©ìë§Œ style_analysisì— ì €ì¥
        3. ì‚¬ìš©ì vs ìƒëŒ€ë°© ë¹„êµ í†µê³„
        4. scoreëŠ” ì‚¬ìš©ì ë§í•˜ê¸° ì ìˆ˜
        5. summaryëŠ” AIê°€ ìƒì„±í•œ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ (êµ¬ì¡°í™”)
        """
        verbose: bool = False

        def analyze(
            self,
            conversation_df: pd.DataFrame,
            relations: List[Dict[str, Any]],
            id: int
        ) -> Dict[str, Any]:
            """
            LLMìœ¼ë¡œ ëŒ€í™” ë¶„ì„ (ì‚¬ìš©ì ì¤‘ì‹¬)
            
            Args:
                conversation_df: ëŒ€í™” DataFrame
                relations: ê´€ê³„ ì •ë³´
                id: ë¶„ì„ ì˜ë¢° ì‚¬ìš©ì ID
            
            Returns:
                ë¶„ì„ ê²°ê³¼ (DB ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜)
            """
            llm = ChatOpenAI(model="gpt-4o-mini", api_key=settings.openai_api_key)
            
            # =========================================
            # 0ï¸âƒ£ ì‚¬ìš©ì/ìƒëŒ€ë°© DataFrame ë¶„ë¦¬
            # =========================================
            
            user_df = conversation_df[conversation_df["speaker"] == int(id)]
            others_df = conversation_df[conversation_df["speaker"] != int(id)]
            
            if user_df.empty:
                raise ValueError(f"âŒ id={id}ì˜ ë°œí™”ê°€ ì—†ìŠµë‹ˆë‹¤!")
            
            if self.verbose:
                print(f"   ğŸ‘¤ ì‚¬ìš©ì ë°œí™”: {len(user_df)}ê°œ")
                print(f"   ğŸ‘¥ ìƒëŒ€ë°© ë°œí™”: {len(others_df)}ê°œ")
            
            # =========================================
            # 1ï¸âƒ£ statistics ìƒì„± (ì‚¬ìš©ì vs ìƒëŒ€ë°© ë¹„êµ)
            # =========================================
            
            user_texts = " ".join(user_df["text"].tolist())
            user_words = user_texts.split()
            
            user_stats = {
                "word_count": len(user_words),
                "avg_sentence_length": round(len(user_words) / len(user_df), 1),
                "unique_words": len(set(user_words)),
                "top_words": self._get_top_words(user_texts, top_n=5)
            }
            
            if not others_df.empty:
                others_texts = " ".join(others_df["text"].tolist())
                others_words = others_texts.split()
                
                others_stats = {
                    "word_count": len(others_words),
                    "avg_sentence_length": round(len(others_words) / len(others_df), 1),
                    "unique_words": len(set(others_words)),
                }
            else:
                others_stats = {
                    "word_count": 0,
                    "avg_sentence_length": 0,
                    "unique_words": 0,
                }
            
            comparison = self._generate_comparison(user_stats, others_stats)
            
            statistics = {
                "user": user_stats,
                "others": others_stats,
                "comparison": comparison
            }
            
            if self.verbose:
                print(f"   ğŸ“Š [Statistics] ì‚¬ìš©ì ë‹¨ì–´: {user_stats['word_count']}, "
                    f"ìƒëŒ€ë°© ë‹¨ì–´: {others_stats['word_count']}")
            
            # =========================================
            # 2ï¸âƒ£ style_analysis ìƒì„± (ì‚¬ìš©ìë§Œ, AI ë¶„ì„)
            # =========================================
            
            full_context = "\n".join([
                f"í™”ì {row['speaker']}: {row['text']}"
                for _, row in conversation_df.iterrows()
            ])
            
            user_texts_joined = "\n".join(user_df["text"].tolist())
            
            style_prompt = f"""
    ë‹¤ìŒì€ ëŒ€í™” ì „ì²´ ë§¥ë½ê³¼ ë¶„ì„ ëŒ€ìƒ ì‚¬ìš©ìì˜ ë°œí™”ì…ë‹ˆë‹¤.
    **ì‚¬ìš©ì ID {id}**ì˜ ë§íˆ¬, ì„±í–¥, ê´€ì‹¬ì‚¬ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

    **ì „ì²´ ëŒ€í™” ë§¥ë½:**
    {full_context[:500]}...

    **ë¶„ì„ ëŒ€ìƒ ì‚¬ìš©ì (ID: {id})ì˜ ë°œí™”:**
    {user_texts_joined}

    **í†µê³„ ì •ë³´:**
    - ì‚¬ìš©ì í‰ê·  ë¬¸ì¥ ê¸¸ì´: {user_stats['avg_sentence_length']}
    - ìƒëŒ€ë°© í‰ê·  ë¬¸ì¥ ê¸¸ì´: {others_stats['avg_sentence_length']}
    - ì‚¬ìš©ì ë‹¨ì–´ ìˆ˜: {user_stats['word_count']}
    - ìƒëŒ€ë°© ë‹¨ì–´ ìˆ˜: {others_stats['word_count']}

    ì•„ë˜ í˜•ì‹ìœ¼ë¡œ JSON ì‘ë‹µí•´ì£¼ì„¸ìš”:
    {{
    "ë§íˆ¬_íŠ¹ì§•_ë¶„ì„": "ì¡´ëŒ“ë§/ë°˜ë§ ì‚¬ìš©, íŠ¹ì • í‘œí˜„ ìŠµê´€, ë¬¸ì¥ ê¸¸ì´ íŠ¹ì§• ë“±",
    "ëŒ€í™”_ì„±í–¥_ë°_ê°ì •_í‘œí˜„": "ê¸ì •ì /ë¶€ì •ì , ê²©ë ¤/ë¹„íŒ ì„±í–¥, ê°ì • í‘œí˜„ ë°©ì‹ ë“±",
    "ëŒ€í™”_ë¹„êµ_ë¶„ì„": "ìƒëŒ€ë°© ëŒ€ë¹„ ì‚¬ìš©ìì˜ ëŒ€í™” íŠ¹ì§• (ê°„ê²°í•¨, ìƒì„¸í•¨, ì£¼ë„ì„± ë“±)"
    }}
    """
            
            try:
                response = llm.invoke(style_prompt)
                content = response.content if hasattr(response, "content") else str(response)
                
                if self.verbose:
                    print(f"   ğŸ—£ï¸ [Style Analysis] ì‚¬ìš©ì: {content[:100]}...")
                
                try:
                    user_analysis = json.loads(content)
                except:
                    user_analysis = {
                        "ë§íˆ¬_íŠ¹ì§•_ë¶„ì„": content[:100],
                        "ëŒ€í™”_ì„±í–¥_ë°_ê°ì •_í‘œí˜„": "ë¶„ì„ ì¤‘",
                        "ëŒ€í™”_ë¹„êµ_ë¶„ì„": "ë¶„ì„ ì¤‘"
                    }
                
                style_analysis = {
                    str(id): user_analysis
                }
                
            except Exception as e:
                print(f"âš ï¸ ì‚¬ìš©ì ìŠ¤íƒ€ì¼ ë¶„ì„ LLM ì‹¤íŒ¨: {e}")
                style_analysis = {
                    str(id): {
                        "ë§íˆ¬_íŠ¹ì§•_ë¶„ì„": "ë¶„ì„ ì‹¤íŒ¨",
                        "ëŒ€í™”_ì„±í–¥_ë°_ê°ì •_í‘œí˜„": "ë¶„ì„ ì‹¤íŒ¨",
                        "ëŒ€í™”_ë¹„êµ_ë¶„ì„": "ë¶„ì„ ì‹¤íŒ¨"
                    }
                }
            
            # =========================================
            # 3ï¸âƒ£ score ê³„ì‚° (ì‚¬ìš©ì ë§í•˜ê¸° ì ìˆ˜)
            # =========================================
            
            score = self._calculate_user_score(user_stats, others_stats, user_analysis)
            
            if self.verbose:
                print(f"   ğŸ¯ [Score] ì‚¬ìš©ì ë§í•˜ê¸° ì ìˆ˜: {score:.2f}")
            
            # =========================================
            # ğŸ”§ 4ï¸âƒ£ summary ìƒì„± (AI ê¸°ë°˜ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ)
            # =========================================
            # ğŸ¯ ëª©ì : RAG ì…ë ¥ìš© êµ¬ì¡°í™”ëœ ì¢…í•© ë¦¬í¬íŠ¸
            # ğŸ¤– ë°©ì‹: LLMì´ í†µê³„ + ìŠ¤íƒ€ì¼ ë°ì´í„°ë¥¼ ì½ê³  í•´ì„
            # =========================================
            
            summary = self._generate_comprehensive_summary(
                llm=llm,
                conversation_df=conversation_df,
                id=id,
                user_df=user_df,
                user_stats=user_stats,
                others_stats=others_stats,
                comparison=comparison,
                user_analysis=user_analysis,
                score=score,
                full_context=full_context
            )
            
            if self.verbose:
                print(f"   ğŸ“ [Summary] {len(summary)}ì ìƒì„± (AI ë¶„ì„)")
            
            # =========================================
            # âœ… ìµœì¢… ê²°ê³¼ ë°˜í™˜
            # =========================================
            
            return {
                "summary": summary,  # â† AIê°€ ìƒì„±í•œ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ
                "style_analysis": style_analysis,
                "statistics": statistics,
                "score": score,
            }
        
        # =========================================
        # ğŸ”§ ìƒˆë¡œ ì¶”ê°€: AI ê¸°ë°˜ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±
        # =========================================
        
        def _generate_comprehensive_summary(
            self,
            llm: ChatOpenAI,
            conversation_df: pd.DataFrame,
            id: int,
            user_df: pd.DataFrame,
            user_stats: Dict,
            others_stats: Dict,
            comparison: str,
            user_analysis: Dict,
            score: float,
            full_context: str
        ) -> str:
            """
            AI ê¸°ë°˜ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±
            
            Args:
                llm: LLM ì¸ìŠ¤í„´ìŠ¤
                conversation_df: ì „ì²´ ëŒ€í™” DataFrame
                id: ì‚¬ìš©ì ID
                user_df: ì‚¬ìš©ì ë°œí™” DataFrame
                user_stats: ì‚¬ìš©ì í†µê³„
                others_stats: ìƒëŒ€ë°© í†µê³„
                comparison: ë¹„êµ ë¶„ì„ í…ìŠ¤íŠ¸
                user_analysis: ìŠ¤íƒ€ì¼ ë¶„ì„ ê²°ê³¼
                score: ë§í•˜ê¸° ì ìˆ˜
                full_context: ì „ì²´ ëŒ€í™” ë§¥ë½
            
            Returns:
                êµ¬ì¡°í™”ëœ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ (AI ìƒì„±)
            """
            
            # ë°œí™” ìƒ˜í”Œ ì¤€ë¹„
            sample_utterances = '\n'.join([
                f"- {text[:100]}{'...' if len(text) > 100 else ''}"
                for text in user_df.head(5)['text'].tolist()
            ])
            
            # AI í”„ë¡¬í”„íŠ¸
            summary_prompt = f"""
    ë‹¹ì‹ ì€ ëŒ€í™” ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ì œê³µëœ í†µê³„ ë°ì´í„°ì™€ ì‹¤ì œ ë°œí™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ **ì‚¬ìš©ì ID {id}**ì˜ ëŒ€í™” ìŠ¤íƒ€ì¼ê³¼ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ëŠ¥ë ¥ì„ ì‹¬ì¸µ ë¶„ì„í•œ ì¢…í•© ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.

    **ë¶„ì„ ì§€ì¹¨:**
    1. ë‹¨ìˆœ ìˆ˜ì¹˜ ë‚˜ì—´ì´ ì•„ë‹Œ, **ìˆ˜ì¹˜ê°€ ì˜ë¯¸í•˜ëŠ” ë°”ë¥¼ í•´ì„**
    2. ë°œí™” ìƒ˜í”Œì—ì„œ ë“œëŸ¬ë‚˜ëŠ” **í‘œí˜„ ë°©ì‹, íƒœë„, íŠ¹ì§• íŒŒì•…**
    3. **ê°•ì ê³¼ ê°œì„ ì ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ**
    4. ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±
    5. **ëª¨ë“  ì„¹ì…˜ì„ ë¹ ì§ì—†ì´ í¬í•¨** (RAG ì…ë ¥ ëª©ì )

    **ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ ì´ êµ¬ì¡° ì¤€ìˆ˜):**

    ==================================================
    ğŸ“Š ëŒ€í™” ë¶„ì„ ì¢…í•© ë¦¬í¬íŠ¸
    ==================================================

    [ë¶„ì„ ëŒ€ìƒ] ì‚¬ìš©ì ID: {id}
    [ëŒ€í™” ê·œëª¨] ì „ì²´ {len(conversation_df)}íšŒ ë°œí™” (ì‚¬ìš©ì: {len(user_df)}íšŒ, ìƒëŒ€ë°©: {len(conversation_df) - len(user_df)}íšŒ)

    --------------------------------------------------
    ğŸ¯ ë§í•˜ê¸° ì ìˆ˜: {score:.2f}/1.00
    --------------------------------------------------

    ğŸ“ˆ í†µê³„ ë¶„ì„
    â€¢ ì‚¬ìš©ì ì´ ë‹¨ì–´ ìˆ˜: {user_stats['word_count']}ê°œ
    â€¢ ì‚¬ìš©ì í‰ê·  ë¬¸ì¥ ê¸¸ì´: {user_stats['avg_sentence_length']}ë‹¨ì–´
    â€¢ ì‚¬ìš©ì ê³ ìœ  ë‹¨ì–´ ìˆ˜: {user_stats['unique_words']}ê°œ
    â€¢ ì‚¬ìš©ì ìì£¼ ì‚¬ìš©í•œ ë‹¨ì–´: {', '.join(user_stats['top_words'])}

    â€¢ ìƒëŒ€ë°© ì´ ë‹¨ì–´ ìˆ˜: {others_stats['word_count']}ê°œ
    â€¢ ìƒëŒ€ë°© í‰ê·  ë¬¸ì¥ ê¸¸ì´: {others_stats['avg_sentence_length']}ë‹¨ì–´

    â€¢ ë¹„êµ ë¶„ì„: {comparison}

    **ğŸ¤– AI í•´ì„:**
    (ìœ„ ìˆ˜ì¹˜ë“¤ì´ ì˜ë¯¸í•˜ëŠ” ë°”ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ í•´ì„)

    ğŸ—£ï¸ ë§íˆ¬ íŠ¹ì§• ë¶„ì„
    {user_analysis.get('ë§íˆ¬_íŠ¹ì§•_ë¶„ì„', 'ë¶„ì„ ì—†ìŒ')}

    **ğŸ¤– AI ì‹¬ì¸µ ë¶„ì„:**
    (ì‹¤ì œ ë°œí™” ìƒ˜í”Œì„ ë°”íƒ•ìœ¼ë¡œ ë§íˆ¬ì˜ íŠ¹ì§•ì„ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„, 2-3ë¬¸ì¥)

    ğŸ’¬ ëŒ€í™” ì„±í–¥ ë° ê°ì • í‘œí˜„
    {user_analysis.get('ëŒ€í™”_ì„±í–¥_ë°_ê°ì •_í‘œí˜„', 'ë¶„ì„ ì—†ìŒ')}

    **ğŸ¤– AI ì‹¬ì¸µ ë¶„ì„:**
    (ë°œí™”ì—ì„œ ë“œëŸ¬ë‚˜ëŠ” ì„±í–¥ê³¼ ê°ì • í‘œí˜„ ë°©ì‹ì„ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„, 2-3ë¬¸ì¥)

    ğŸ¯ ì£¼ìš” ê´€ì‹¬ì‚¬
    {user_analysis.get('ì£¼ìš”_ê´€ì‹¬ì‚¬', 'ë¶„ì„ ì—†ìŒ')}

    ğŸ“Š ìƒëŒ€ë°©ê³¼ì˜ ë¹„êµ
    {user_analysis.get('ëŒ€í™”_ë¹„êµ_ë¶„ì„', 'ë¶„ì„ ì—†ìŒ')}

    **ğŸ¤– AI ì¢…í•© í‰ê°€:**
    (ê°•ì  2ê°€ì§€, ê°œì„ ì  1ê°€ì§€, ì¶”ì²œ ì‚¬í•­ 1ê°€ì§€ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ, 4-5ë¬¸ì¥)

    ==================================================

    **ì œê³µëœ ë°ì´í„°:**

    **ì‹¤ì œ ë°œí™” ìƒ˜í”Œ (ìµœê·¼ 5ê°œ):**
    {sample_utterances}

    **ì „ì²´ ëŒ€í™” ë§¥ë½ (ì¼ë¶€):**
    {full_context[:300]}...

    ---

    ìœ„ í˜•ì‹ì— ë§ì¶° **êµ¬ì¡°í™”ëœ ë³´ê³ ì„œ**ë¥¼ ì‘ì„±í•˜ë˜, **ğŸ¤– AI í•´ì„/ë¶„ì„ ì„¹ì…˜**ì—ëŠ” ë‹¨ìˆœ ë°˜ë³µì´ ì•„ë‹Œ ì‹¤ì§ˆì ì¸ í†µì°°ì„ ë‹´ì•„ì£¼ì„¸ìš”.
    """
            
            try:
                response = llm.invoke(summary_prompt)
                summary = response.content if hasattr(response, "content") else str(response)
                summary = summary.strip()
                
                if self.verbose:
                    print(f"   âœ… AI ê¸°ë°˜ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
                
                return summary
                
            except Exception as e:
                print(f"âš ï¸ AI ì¢…í•© ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
                
                # Fallback: í…œí”Œë¦¿ ê¸°ë°˜ ë³´ê³ ì„œ
                return self._generate_fallback_summary(
                    id=id,
                    conversation_df=conversation_df,
                    user_df=user_df,
                    user_stats=user_stats,
                    others_stats=others_stats,
                    comparison=comparison,
                    user_analysis=user_analysis,
                    score=score
                )
        
        def _generate_fallback_summary(
            self,
            id: int,
            conversation_df: pd.DataFrame,
            user_df: pd.DataFrame,
            user_stats: Dict,
            others_stats: Dict,
            comparison: str,
            user_analysis: Dict,
            score: float
        ) -> str:
            """
            Fallback: í…œí”Œë¦¿ ê¸°ë°˜ ìš”ì•½ (LLM ì‹¤íŒ¨ ì‹œ)
            """
            summary_parts = [
                "=" * 50,
                "ğŸ“Š ëŒ€í™” ë¶„ì„ ì¢…í•© ë¦¬í¬íŠ¸",
                "=" * 50,
                f"\n[ë¶„ì„ ëŒ€ìƒ] ì‚¬ìš©ì ID: {id}",
                f"[ëŒ€í™” ê·œëª¨] ì „ì²´ {len(conversation_df)}íšŒ ë°œí™” (ì‚¬ìš©ì: {len(user_df)}íšŒ, ìƒëŒ€ë°©: {len(conversation_df) - len(user_df)}íšŒ)",
                f"\n{'-' * 50}",
                f"ğŸ¯ ë§í•˜ê¸° ì ìˆ˜: {score:.2f}/1.00",
                f"{'-' * 50}",
                f"\nğŸ“ˆ í†µê³„ ë¶„ì„",
                f"  â€¢ ì‚¬ìš©ì ì´ ë‹¨ì–´ ìˆ˜: {user_stats['word_count']}ê°œ",
                f"  â€¢ ì‚¬ìš©ì í‰ê·  ë¬¸ì¥ ê¸¸ì´: {user_stats['avg_sentence_length']}ë‹¨ì–´",
                f"  â€¢ ì‚¬ìš©ì ê³ ìœ  ë‹¨ì–´ ìˆ˜: {user_stats['unique_words']}ê°œ",
                f"  â€¢ ì‚¬ìš©ì ìì£¼ ì‚¬ìš©í•œ ë‹¨ì–´: {', '.join(user_stats['top_words'])}",
                f"\n  â€¢ ìƒëŒ€ë°© ì´ ë‹¨ì–´ ìˆ˜: {others_stats['word_count']}ê°œ",
                f"  â€¢ ìƒëŒ€ë°© í‰ê·  ë¬¸ì¥ ê¸¸ì´: {others_stats['avg_sentence_length']}ë‹¨ì–´",
                f"\n  â€¢ ë¹„êµ ë¶„ì„: {comparison}",
                f"\nğŸ—£ï¸ ë§íˆ¬ íŠ¹ì§• ë¶„ì„",
                f"  {user_analysis.get('ë§íˆ¬_íŠ¹ì§•_ë¶„ì„', 'ë¶„ì„ ì—†ìŒ')}",
                f"\nğŸ’¬ ëŒ€í™” ì„±í–¥ ë° ê°ì • í‘œí˜„",
                f"  {user_analysis.get('ëŒ€í™”_ì„±í–¥_ë°_ê°ì •_í‘œí˜„', 'ë¶„ì„ ì—†ìŒ')}",
                f"\nğŸ¯ ì£¼ìš” ê´€ì‹¬ì‚¬",
                f"  {user_analysis.get('ì£¼ìš”_ê´€ì‹¬ì‚¬', 'ë¶„ì„ ì—†ìŒ')}",
                f"\nğŸ“Š ìƒëŒ€ë°©ê³¼ì˜ ë¹„êµ",
                f"  {user_analysis.get('ëŒ€í™”_ë¹„êµ_ë¶„ì„', 'ë¶„ì„ ì—†ìŒ')}",
                f"\n{'=' * 50}",
            ]
            
            return "\n".join(summary_parts)
        
        # =========================================
        # ê¸°ì¡´ í—¬í¼ ë©”ì„œë“œë“¤
        # =========================================
        
        def _generate_comparison(self, user_stats: Dict, others_stats: Dict) -> str:
            """ì‚¬ìš©ì vs ìƒëŒ€ë°© ë¹„êµ ë¶„ì„ í…ìŠ¤íŠ¸ ìƒì„±"""
            comparisons = []
            
            if others_stats["word_count"] > 0:
                word_ratio = user_stats["word_count"] / others_stats["word_count"]
                if word_ratio < 0.7:
                    comparisons.append("ì‚¬ìš©ìëŠ” ìƒëŒ€ë°©ë³´ë‹¤ ë§ì„ ì ê²Œ í•¨")
                elif word_ratio > 1.3:
                    comparisons.append("ì‚¬ìš©ìëŠ” ìƒëŒ€ë°©ë³´ë‹¤ ë§ì„ ë§ì´ í•¨")
                else:
                    comparisons.append("ì‚¬ìš©ìì™€ ìƒëŒ€ë°©ì˜ ëŒ€í™”ëŸ‰ì´ ë¹„ìŠ·í•¨")
            
            if others_stats["avg_sentence_length"] > 0:
                len_diff = user_stats["avg_sentence_length"] - others_stats["avg_sentence_length"]
                if len_diff < -2:
                    comparisons.append("ì‚¬ìš©ìëŠ” ì§§ì€ ë¬¸ì¥ì„ ì„ í˜¸")
                elif len_diff > 2:
                    comparisons.append("ì‚¬ìš©ìëŠ” ê¸´ ë¬¸ì¥ì„ ì„ í˜¸")
            
            return ", ".join(comparisons) if comparisons else "ë¹„êµ ë°ì´í„° ë¶€ì¡±"
        
        def _calculate_user_score(
            self,
            user_stats: Dict,
            others_stats: Dict,
            user_analysis: Dict
        ) -> float:
            """ì‚¬ìš©ì ë§í•˜ê¸° ì ìˆ˜ ê³„ì‚° (0.0 ~ 1.0)"""
            score_components = []
            
            # 1. ì–´íœ˜ ë‹¤ì–‘ì„± (0 ~ 0.4ì )
            if user_stats["word_count"] > 0:
                vocab_diversity = user_stats["unique_words"] / user_stats["word_count"]
                vocab_score = min(0.4, vocab_diversity * 0.8)
                score_components.append(vocab_score)
            
            # 2. ëŒ€í™” ì°¸ì—¬ë„ (0 ~ 0.3ì )
            if others_stats["word_count"] > 0:
                participation_ratio = user_stats["word_count"] / (user_stats["word_count"] + others_stats["word_count"])
                if 0.4 <= participation_ratio <= 0.6:
                    participation_score = 0.3
                else:
                    participation_score = 0.3 * (1 - abs(participation_ratio - 0.5) * 2)
                score_components.append(participation_score)
            
            # 3. ë¬¸ì¥ êµ¬ì¡° (0 ~ 0.3ì )
            avg_len = user_stats["avg_sentence_length"]
            if 5 <= avg_len <= 10:
                structure_score = 0.3
            elif avg_len < 5:
                structure_score = 0.3 * (avg_len / 5)
            else:
                structure_score = 0.3 * (10 / avg_len)
            score_components.append(structure_score)
            
            final_score = sum(score_components)
            normalized_score = 0.5 + (final_score * 0.5)
            
            return round(min(1.0, max(0.0, normalized_score)), 2)
        
        def _get_top_words(self, text: str, top_n: int = 5) -> List[str]:
            """ë¹ˆë„ ë†’ì€ ë‹¨ì–´ ì¶”ì¶œ (í•œê¸€ ê¸°ì¤€)"""
            words = re.findall(r'[ê°€-í£]+', text)
            words = [w for w in words if len(w) >= 2]
            word_counts = Counter(words)
            top_words = [word for word, count in word_counts.most_common(top_n)]
            return top_words


# =========================================
# âœ… ScoreEvaluator 
# =========================================
@dataclass
class ScoreEvaluator:
    """ì‹ ë¢°ë„ í‰ê°€"""
    def evaluate(self, result: Dict[str, Any]) -> bool:
        """
        ë¶„ì„ ê²°ê³¼ì˜ ì‹ ë¢°ë„ í‰ê°€
        
        Args:
            result: Analyzer ê²°ê³¼
        
        Returns:
            ì‹ ë¢°ë„ >= 0.65 ì—¬ë¶€
        """
        score = result.get("score", 0)
        return score >= 0.65


# =========================================
# ğŸ”§ AnalysisSaver
# =========================================
@dataclass
class AnalysisSaver:
    """
    âœ… DBì— ë¶„ì„ ê²°ê³¼ ì €ì¥
    
    ğŸ”§ ìˆ˜ì • ì‚¬í•­:
    - statistics ì €ì¥ (ë¹ˆ dict â†’ ì‹¤ì œ ë°ì´í„°)
    """
    verbose: bool = False  # ğŸ”§ ì¶”ê°€
    
    def save(self, db: Session, result: Dict[str, Any], state) -> Dict[str, Any]:
        """
        analysis_result í…Œì´ë¸”ì— INSERT
        
        Args:
            db: SQLAlchemy ì„¸ì…˜
            result: Analyzer ê²°ê³¼
            state: AnalysisState
        
        Returns:
            ì €ì¥ ê²°ê³¼
        """
        if not result:
            return {"status": "no_result"}
        
        try:
            print("ğŸ’¾ [DEBUG] AnalysisSaver.save() ì§„ì…")
            print(f"ğŸ’¾ state.id={state.id}, conv_id={state.conv_id}")
            print(f"ğŸ’¾ result keys={list(result.keys()) if result else None}")


            saved = save_analysis_result(
                db=db,
                id=str(state.id),
                conv_id=str(state.conv_id),
                summary=result.get("summary", ""),
                style_analysis=result.get("style_analysis", {}),
                statistics=result.get("statistics", {}),  # â† ğŸ”§ ìˆ˜ì •
                score=result.get("score", 0.0),
                confidence_score=0.0,  # QAì—ì„œ ì—…ë°ì´íŠ¸
                conversation_count=len(state.conversation_df) if state.conversation_df is not None else 0,
                feedback=None,
            )
            
            print(f"âœ… [AnalysisSaver] DB ì €ì¥ ì™„ë£Œ: analysis_id={saved['analysis_id']}")
            
            # ğŸ”§ ì¶”ê°€: ì €ì¥ëœ ë°ì´í„° ìƒì„¸ ì¶œë ¥
            if self.verbose:
                print(f"   â†’ summary: {result.get('summary', '')[:50]}...")
                print(f"   â†’ score: {result.get('score', 0):.2f}")
                
                # statistics í™•ì¸
                stats = result.get("statistics", {})
                if stats:
                    user_stats = stats.get("user", {})
                    print(f"   â†’ ì‚¬ìš©ì ë‹¨ì–´ ìˆ˜: {user_stats.get('word_count', 0)}")
                    print(f"   â†’ ì‚¬ìš©ì í‰ê·  ë¬¸ì¥ ê¸¸ì´: {user_stats.get('avg_sentence_length', 0)}")
            
            # âœ… stateì— ì €ì¥
            state.meta["analysis_id"] = saved["analysis_id"]
            
            return {
                "status": "saved",
                "analysis_id": saved["analysis_id"],
            }
            
        except Exception as e:
            print(f"âŒ [AnalysisSaver] ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return {"status": "error", "error": str(e)}