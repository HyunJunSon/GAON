# =========================================
# app/agent/Analysis/nodes.py  (FINAL + DEBUG + FIXED)
# =========================================

from __future__ import annotations
from dataclasses import dataclass
from typing import Dict, Any, List
import pandas as pd
import json
from collections import Counter
from dotenv import load_dotenv
load_dotenv()

# ---------------------------------
# NLP / Text Processing
# ---------------------------------
from kiwipiepy import Kiwi
kiwi = Kiwi()

# ---------------------------------
# Dialect + Prosody Normalizer
# ---------------------------------
from app.agent.Analysis.dialect_normalizer import DialectProsodyNormalizer

# ---------------------------------
# LLM
# ---------------------------------
from langchain_openai import ChatOpenAI

# ---------------------------------
# DB CRUD
# ---------------------------------
from app.agent.crud import save_analysis_result


# =========================================================
# TEXT FEATURE UTILITIES
# =========================================================

def extract_content_words(text: str):
    """Kiwi Token ê°ì²´ë¥¼ ì§ì ‘ ì²˜ë¦¬í•˜ì—¬ ë‚´ìš©ì–´ ì¶”ì¶œ"""

    analyses = kiwi.analyze(text)

    if not analyses:
        return []

    # Kiwi ê²°ê³¼ í˜•ì‹: [( [Token(), Token(), ...], score )]
    morphs = analyses[0][0]   # Token ê°ì²´ ë¦¬ìŠ¤íŠ¸

    # í¬í•¨í•  íƒœê·¸
    content_prefixes = ("NN", "VV", "VA", "MAG", "IC", "NP", "XR", "VX", "SL")

    result = []
    for m in morphs:
        tag = m.tag
        form = m.form

        # prefixë¡œ í•„í„° (ì˜ˆ: NNG, NNP, VV+ì–´ë¯¸ ë“± ëª¨ë‘ ì¡í˜)
        if tag.startswith(content_prefixes):
            result.append(form)

    return result



def calculate_mattr(words: List[str], window: int = 25):
    """Moving-Average Type-Token Ratio (MATTR)"""
    if len(words) < window:
        return len(set(words)) / len(words) if words else 0

    scores = []
    for i in range(len(words) - window + 1):
        win = words[i:i + window]
        scores.append(len(set(win)) / window)

    return sum(scores) / len(scores)


# =========================================================
# 1) Stage 1~6 Analyzer (í…ìŠ¤íŠ¸ + prosody + trigger)
# =========================================================
@dataclass
class Analyzer:
    verbose: bool = False

    def analyze(
        self,
        speaker_segments: List[Dict[str, Any]],
        user_id: int,
        user_gender: str,
        user_age: int,
        user_speaker_label: str,
        other_speaker_label: str,
        other_display_name: str
    ):

        # ----------------------------------
        # 1) DataFrame ìƒì„±
        # ----------------------------------
        df = pd.DataFrame([{
            "speaker": seg["speaker"],
            "text": seg["text"]
        } for seg in speaker_segments])

        # ğŸ” DEBUG â€” DF ì „ì²´ ì¶œë ¥
        print("\n[DEBUG] DF created:")
        print(df.head(10))

        # ----------------------------------
        # 2) í…ìŠ¤íŠ¸ Feature
        # ----------------------------------
        user_df = df[df["speaker"] == user_speaker_label]
        other_df = df[df["speaker"] != user_speaker_label]

        print("\n[DEBUG] user_df:", user_df.head())
        print("[DEBUG] other_df:", other_df.head())

        user_text = " ".join(user_df["text"].tolist())
        other_text = " ".join(other_df["text"].tolist())

        print("\n[DEBUG] user_text:", user_text)
        print("[DEBUG] other_text:", other_text)

        user_words = extract_content_words(user_text)
        other_words = extract_content_words(other_text)

        print("\n[DEBUG] user_words:", user_words)
        print("[DEBUG] other_words:", other_words)

        statistics = {
            "user": {
                "token_count": len(user_words),
                "mattr": calculate_mattr(user_words),
                "unique_words": len(set(user_words)),
                "top_words": Counter(user_words).most_common(5),
            },
            "others": {
                "token_count": len(other_words),
                "mattr": calculate_mattr(other_words),
            }
        }

        # ----------------------------------
        # 3) Prosody Normalization
        # ----------------------------------
        normalizer = DialectProsodyNormalizer()
        prosody_norm = normalizer.normalize(speaker_segments)

        # ----------------------------------
        # 4) Surrogate (ê°„ë‹¨í•œ ë§¥ë½ íŒíŠ¸)
        # ----------------------------------
        surrogate = {
            "relationship_pattern": "neutral",
            "emotional_trajectory_hint": "stable",
        }

        # ----------------------------------
        # 5) Trigger Detection
        # ----------------------------------
        trigger = self._detect_triggers(speaker_segments, prosody_norm)

        return {
            "statistics": statistics,
            "prosody_norm": prosody_norm,
            "surrogate": surrogate,
            "trigger": trigger,
            "df": df,
        }


    # =========================================================
    # Trigger (deviation ê¸°ë°˜ rule)
    # =========================================================
    def _detect_triggers(self, segments, prosody_norm):
        deviations = [
            r.get("emotional_deviation", 0)
            for r in prosody_norm.get("turn_prosody", [])
            if r.get("emotional_deviation") is not None
        ]

        if not deviations:
            return {"trigger_detected": False, "intensity": 0.0, "emotion_shift": None}

        max_dev = max(abs(d) for d in deviations)

        trigger_detected = max_dev > 20
        intensity = min(max_dev / 40, 1)

        return {
            "trigger_detected": trigger_detected,
            "intensity": round(float(intensity), 3),
            "emotion_shift": "abrupt_change" if trigger_detected else "stable"
        }


# =========================================================
# 2) Stage 7 â€” LLM STYLE ANALYZER
# =========================================================
@dataclass
class SafetyLLMAnalyzer:
    def analyze(
        self,
        df: pd.DataFrame,
        user_speaker_label: str,
        user_gender: str,
        user_age: int,
        stats: Dict[str, Any],
        prosody_norm: Dict[str, Any],
        surrogate: Dict[str, Any],
        trigger: Dict[str, Any]
    ):

        # ğŸ” DEBUG â€” LLM ì…ë ¥ ë¬¸ì¥ í™•ì¸
        print("\n[DEBUG] LLMAnalyzer user_text:\n",
              "\n".join(df[df["speaker"] == user_speaker_label]["text"].tolist()))
        print("\n[DEBUG] LLMAnalyzer full_context:\n",
              "\n".join(df["text"].tolist()))

        llm = ChatOpenAI(model="gpt-4o-mini")

        user_text = "\n".join(df[df["speaker"] == user_speaker_label]["text"].tolist())
        full_context = "\n".join(df["text"].tolist())

        # ----------------------------
        # ğŸ”¥ PROMPT ìƒì„±
        # ----------------------------
        prompt = f"""
ë‹¹ì‹ ì€ ëŒ€í™” ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.í•œêµ­ì–´ë¡œ ë‹µí•˜ì„¸ìš”.
ë‹¤ìŒì€ ì „ì²´ ëŒ€í™” ë‚´ìš©ì…ë‹ˆë‹¤. ì „ì²´ ë°œí™”ì—ì„œ ëŒ€í™”ì˜ ë§¥ë½ì„ ì´í•´í•œ í›„, ë§¥ë½ì— ê·¼ê±°í•˜ì—¬ ì‚¬ìš©ì ì •ë³´ë¥¼ ì¶”ê°€ì ìœ¼ë¡œ í™•ì¸í•˜ê³  ì‚¬ìš©ìì˜ ë°œí™” ìŠ¤íƒ€ì¼ì„ JSONìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.

{full_context}

ì‚¬ìš©ì({user_speaker_label}) ë°œí™”ë§Œ:
{user_text}

ì‚¬ìš©ì ì •ë³´:
- ë‚˜ì´: {user_age}
- ì„±ë³„: {user_gender}

í…ìŠ¤íŠ¸ í†µê³„:
{json.dumps(stats, ensure_ascii=False)}

ìŒí–¥Â·ì–µì–‘ ë¶„ì„:
{json.dumps(prosody_norm, ensure_ascii=False)}

ë§¥ë½ íŒíŠ¸:
{json.dumps(surrogate, ensure_ascii=False)}

íŠ¸ë¦¬ê±° ì •ë³´:
{json.dumps(trigger, ensure_ascii=False)}

ë‹¤ìŒì„ JSONìœ¼ë¡œ ì¶œë ¥:
{{
  "tone": "...",
  "prosody": "...",
  "emotion_pattern": "...",
  "strengths": "...",
  "risks": "...",
  "politeness": 0.0,
  "empathy": 0.0,
  "aggressiveness": 0.0
}}
"""

        # ----------------------------
        # ğŸ”¥ LLMì—ê²Œ ì „ë‹¬ë˜ëŠ” Prompt ì „ì²´ë¥¼ ì™„ì „ ì¶œë ¥
        # ----------------------------
        print("\n================= [DEBUG] LLM PROMPT INPUT =================")
        print(prompt)
        print("============================================================\n")

        # ----------------------------
        # LLM í˜¸ì¶œ
        # ----------------------------
        resp = llm.invoke(prompt)
        raw = resp.content if hasattr(resp, "content") else str(resp)

        try:
            return json.loads(raw)
        except:
            return {"raw_text": raw}


# =========================================================
# 3) Stage 8 â€” LLM SUMMARY BUILDER 
# =========================================================
@dataclass
class SummaryBuilder:
    def build(
        self,
        user_name: str,
        df: pd.DataFrame,
        user_speaker_label: str,
        user_gender: str,
        user_age: int,
        style: Dict[str, Any],
        statistics: Dict[str, Any],
        prosody_norm: Dict[str, Any],
        surrogate: Dict[str, Any],
        trigger: Dict[str, Any],
    ):

        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.2)
        full_context = "\n".join(df["text"].tolist())
        user_text = "\n".join(df[df["speaker"] == user_speaker_label]["text"].tolist())

        # ---------------------------------------------------
        # â˜… SummaryBuilder Prompt
        # ---------------------------------------------------
        prompt = f"""
ë‹¹ì‹ ì€ ëŒ€í™” ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒì€ ì „ì²´ ëŒ€í™” ë§¥ë½ê³¼ ë¶„ì„ ì •ë³´ì…ë‹ˆë‹¤.
ì „ì²´ ë§¥ë½ì„ ê¸°ë°˜ìœ¼ë¡œ ì¢…í•©ì ì¸ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ êµ¬ì¡°í™”í•´ì„œ ê³ ê¸‰ ì¸ì‚¬ì´íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”. ë¶„ëŸ‰ì€ 500~700ì ë‚´ì™¸ë¡œ í•©ë‹ˆë‹¤.

# ì „ì²´ ëŒ€í™” ë‚´ìš©
{full_context}

# ì‚¬ìš©ì({user_speaker_label}) ë°œí™”ë§Œ
{user_text}

# ì‚¬ìš©ì ì •ë³´
- ì´ë¦„: {user_name}
- ë‚˜ì´: {user_age}
- ì„±ë³„: {user_gender}

# ìŠ¤íƒ€ì¼ ë¶„ì„ ê²°ê³¼
{json.dumps(style, ensure_ascii=False, indent=2)}

# í…ìŠ¤íŠ¸ í†µê³„
{json.dumps(statistics, ensure_ascii=False, indent=2)}

# ProsodyÂ·ì–µì–‘ ë¶„ì„
{json.dumps(prosody_norm, ensure_ascii=False, indent=2)}

# Surrogate ê´€ê³„ íŒíŠ¸
{json.dumps(surrogate, ensure_ascii=False, indent=2)}

# Trigger ì •ë³´
{json.dumps(trigger, ensure_ascii=False, indent=2)}

ğŸ“Œ ì‘ì„± ê·œì¹™:
- ì²« ë¬¸ì¥ì€ {user_name}ë‹˜ì˜ ì „ì²´ ë§í•˜ê¸° í•µì‹¬ íŠ¹ì§•ì„ ìš”ì•½
- ëŒ€í™” full_contextì—ì„œ ë“œëŸ¬ë‚œ ê°ì •ì /ë§¥ë½ì  íŠ¹ì§•ì„ ë¬¸ì¥ìœ¼ë¡œ í’€ì–´ì„œ ë°˜ë“œì‹œ ë°˜ì˜
- í…ìŠ¤íŠ¸ í†µê³„ì˜ mattrì˜ ì •ì˜ì™€ ì ìˆ˜ì— ëŒ€í•œ í•´ì„ ë°˜ì˜ (Moving-Average Type-Token Ratio (MATTR)
    if len(words) < window:
        return len(set(words)) / len(words) if words else 0

    scores = []
    for i in range(len(words) - window + 1):
        win = words[i:i + window]
        scores.append(len(set(win)) / window)

    return sum(scores) / len(scores))
- tone, emotion, prosody, ìƒí˜¸ì‘ìš© íŠ¹ì§•, ìœ„í—˜ ìš”ì†Œë¥¼ ìš”ì†Œ ê·¸ëŒ€ë¡œ ì‘ì„±í•˜ëŠ” ê²ƒì´ ì•„ë‹Œ, ì „ë¬¸ê°€ê°€ í’€ì–´ì„œ í•´ì„¤í•˜ë“¯ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì„œìˆ 
- ë¶„ì„ ê²°ê³¼ì— ëŒ€í•œ ê·¼ê±°ë¥¼ í•´ì„í•´ì„œ ì„œìˆ 
- í•˜ë‚˜ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨ìœ¼ë¡œ ì‘ì„±í•˜ë˜, í‰ê°€í•œë‹¤ëŠ” ë¬¸ì¥ì´ë‚˜ ë‹¨ì–¸í•˜ëŠ” í‘œí˜„ì€ ì§€ì–‘
"""

        resp = llm.invoke(prompt)
        summary = resp.content if hasattr(resp, "content") else str(resp)
        return summary.strip()


# =========================================================
# 4) Stage 9 â€” TEMPERATURE SCORER
# =========================================================
@dataclass
class TemperatureScorer:
    def score(self, style, prosody_norm, trigger):
        politeness = float(style.get("politeness", 0.5))
        empathy = float(style.get("empathy", 0.5))
        aggressiveness = float(style.get("aggressiveness", 0.2))

        # ì•ˆì •ì„± ì˜í–¥ ì™„í™”
        deviation = prosody_norm.get("mean_observed_slope", 0)
        stability = 1.0 - min(abs(deviation) / 60, 1)   # 40 â†’ 60

        # ì „ì²´ ì˜¨ë„ ê¸°ë°˜ (ì ìˆ˜ ë†’ê²Œ ë³´ì •)
        warmth_base = (
            0.35 * politeness +        # 0.30 â†’ 0.35
            0.35 * empathy +           # 0.30 â†’ 0.35
            0.15 * stability +         # 0.20 â†’ 0.15
            0.15 * (1 - aggressiveness) # 0.20 â†’ 0.15
        )

        # Trigger íŒ¨ë„í‹° ì™„í™” (40% â†’ 20%)
        intensity = trigger.get("intensity", 0.0)
        warmth_after_trigger = warmth_base * (1 - 0.2 * intensity)

        # ë°”ë‹¥ì€ 30ì  ë³´ì¥
        final_score = max(30, warmth_after_trigger * 100)

        return round(min(100, final_score), 2)



# =========================================================
# 5) Stage 10 SAVE TO DB
# =========================================================
@dataclass
class AnalysisSaver:
    verbose: bool = False

    def save(self, db, result, conv_id, user_id, conversation_count):
        return save_analysis_result(
            db=db,
            id=user_id,
            conv_id=conv_id,
            summary=result["summary"],
            style_analysis=result["style_analysis"],
            statistics=result["statistics"],
            score=result["temperature_score"],
            confidence_score=0.0,
            conversation_count=conversation_count
        )
