# app/agent/Cleaner/graph_cleaner.py

from __future__ import annotations
from dataclasses import dataclass, field
from typing import Any, List, Dict, Optional
from langgraph.graph import StateGraph, END
from sqlalchemy.orm import Session
import pandas as pd

# ë…¸ë“œ import
from .nodes import (
    RawFetcher,       # ì›ë¬¸(raw_content) ë¶ˆëŸ¬ì˜¤ê¸°
    DataInspector,    # turn â‰¥ 3
    TokenCounter,     # í™”ìë³„ 25 ì–´ì ˆ
    ExceptionHandler  # ì˜ˆì™¸ ì²˜ë¦¬
)


@dataclass
class CleanerState:
    db: Optional[Session] = None
    conv_id: Optional[str] = None

    raw_df: Optional[pd.DataFrame] = None
    inspected_df: Optional[pd.DataFrame] = None

    # ê²°ê³¼ ë° ê²€ì¦ ê´€ë ¨
    validated: bool = False
    issues: List[str] = field(default_factory=list)

    verbose: bool = False


# =========================================
class CleanerGraph:
    def __init__(self, verbose: bool = True):
        self.verbose = verbose

        # ğŸ”§ í•„ìš”í•œ ë…¸ë“œ ì´ˆê¸°í™”
        self.fetcher = RawFetcher()
        self.inspector = DataInspector()
        self.token_counter = TokenCounter()
        self.exception_handler = ExceptionHandler()

        # ğŸ”§ ê·¸ë˜í”„ ì •ì˜
        self.graph = StateGraph(CleanerState)
        self.graph.add_node("fetch", self.node_fetch)
        self.graph.add_node("inspect", self.node_inspect)
        self.graph.add_node("tokenize", self.node_tokenize)

        # íë¦„ ì •ì˜
        self.graph.set_entry_point("fetch")
        self.graph.add_edge("fetch", "inspect")

        # ğŸ”§ ì¡°ê±´ë¶€: inspect â†’ tokenize or END
        def inspect_cond(state: CleanerState):
            return "tokenize" if not state.issues else END

        self.graph.add_conditional_edges("inspect", inspect_cond)

        # ğŸ”§ ì¡°ê±´ë¶€: tokenize â†’ END
        def tokenize_cond(state: CleanerState):
            return END

        self.graph.add_conditional_edges("tokenize", tokenize_cond)

        self.pipeline = self.graph.compile()

    # =========================================
    # 1ï¸âƒ£ RawFetcher
    # =========================================
    def node_fetch(self, state: CleanerState):
        if self.verbose:
            print("\n[1ï¸âƒ£ RawFetcher] ì›ë¬¸(raw_content) ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦")

        try:
            state.raw_df = self.fetcher.fetch(
                db=state.db,
                conv_id=state.conv_id
            )
            print(f"   â†’ ë°œí™” {len(state.raw_df)}ê°œ ë¡œë“œ ì™„ë£Œ")
            return state
        except Exception as e:
            return self.exception_handler.handle(e)

    # =========================================
    # 2ï¸âƒ£ DataInspector (turn â‰¥ 3 ê²€ì‚¬)
    # =========================================
    def node_inspect(self, state: CleanerState):
        if self.verbose:
            print("\n[2ï¸âƒ£ DataInspector] ë°œí™” turn ê²€ì‚¬ ì¤‘â€¦")

        try:
            inspected_df, issues = self.inspector.inspect(state.raw_df, state)
            state.inspected_df = inspected_df
            state.issues.extend(issues)

            if issues:
                print(f"   âŒ ê²€ì‚¬ ì‹¤íŒ¨: {issues}")
            else:
                print("   âœ… turn ê²€ì‚¬ í†µê³¼")

            return state
        except Exception as e:
            return self.exception_handler.handle(e)

    # =========================================
    # 3ï¸âƒ£ TokenCounter (í™”ìë³„ ì–´ì ˆ â‰¥ 25 ê²€ì‚¬)
    # =========================================
    def node_tokenize(self, state: CleanerState):
        if self.verbose:
            print("\n[3ï¸âƒ£ TokenCounter] í™”ìë³„ ì–´ì ˆ ìˆ˜ ê²€ì‚¬ ì¤‘â€¦")

        try:
            df, issues = self.token_counter.count(state.inspected_df, state)
            state.issues.extend(issues)

            if issues:
                print(f"   âŒ ì–´ì ˆ ë¶€ì¡±: {issues}")
            else:
                print("   âœ… í™”ìë³„ ì–´ì ˆ ìˆ˜ ì¡°ê±´ í†µê³¼")

            return state
        except Exception as e:
            return self.exception_handler.handle(e)

    # =========================================
    # ì‹¤í–‰ ë©”ì„œë“œ
    # =========================================
    def run(self, db: Session, conv_id: str):
        if self.verbose:
            print("\nğŸš€ [CleanerGraph] ì‹¤í–‰ ì‹œì‘\n" + "=" * 60)

        state = CleanerState(
            db=db,
            conv_id=conv_id,
            verbose=self.verbose,
        )

        final_state = self.pipeline.invoke(state)

        if self.verbose:
            print("ğŸ [CleanerGraph] ì‹¤í–‰ ì¢…ë£Œ\n" + "=" * 60)

        return final_state
