from __future__ import annotations
from dataclasses import dataclass, field
from typing import Any, List, Dict, Optional
from langgraph.graph import StateGraph, END
from sqlalchemy.orm import Session
import pandas as pd

# ë…¸ë“œ import
from .nodes import (
    RawFetcher,             # raw_content + file metadata fetch
    DataInspector,          # turn â‰¥ 3
    TokenCounter,           # speakerë³„ 25 tokens
    FileTypeClassifier,     # audio/text íŒë‹¨
    AudioFeatureExtractor,  # ìŒì„± ìš”ì†Œ ì¶”ì¶œ
    ContentValidator,       # í…ìŠ¤íŠ¸ ìœ íš¨ì„± ê²€ì‚¬
    ContentMerger,          # í…ìŠ¤íŠ¸ + ìŒì„± ìš”ì†Œ ë³‘í•©
    ExceptionHandler
)


# =========================================
# STATE ì •ì˜ (audio + text ë³‘í•© ì •ë³´ í¬í•¨)
# =========================================
@dataclass
class CleanerState:
    db: Optional[Session] = None
    conv_id: Optional[str] = None

    # RAW
    raw_df: Optional[pd.DataFrame] = None
    file_type: Optional[str] = None
    audio_url: Optional[str] = None
    speaker_segments: Optional[List[Dict]] = None

    # PROCESSING
    inspected_df: Optional[pd.DataFrame] = None
    validated_df: Optional[pd.DataFrame] = None
    audio_features: Optional[List[Dict]] = None
    merged_df: Optional[pd.DataFrame] = None

    # ê²°ê³¼ ë° ê²€ì¦ ê´€ë ¨
    validated: bool = False
    issues: List[str] = field(default_factory=list)

    verbose: bool = False



# =========================================
# CLEANER GRAPH
# =========================================
class CleanerGraph:
    def __init__(self, verbose: bool = True):
        self.verbose = verbose

        # ë…¸ë“œ ì¤€ë¹„
        self.fetcher = RawFetcher()
        self.inspector = DataInspector()
        self.token_counter = TokenCounter()
        self.classifier = FileTypeClassifier()
        self.validator = ContentValidator()
        self.audio_extractor = AudioFeatureExtractor()
        self.merger = ContentMerger()
        self.exception_handler = ExceptionHandler()

        # ê·¸ë˜í”„ êµ¬ì„±
        self.graph = StateGraph(CleanerState)

        self.graph.add_node("fetch", self.node_fetch)
        self.graph.add_node("inspect", self.node_inspect)
        self.graph.add_node("tokenize", self.node_tokenize)
        self.graph.add_node("classify", self.node_classify)
        self.graph.add_node("text_validate", self.node_text_validate)
        self.graph.add_node("audio_extract", self.node_audio_extract)
        self.graph.add_node("merge", self.node_merge)

        # ì‹œì‘ì 
        self.graph.set_entry_point("fetch")

        # íë¦„ ì •ì˜
        self.graph.add_edge("fetch", "inspect")
        self.graph.add_edge("inspect", "tokenize")

        # turn/token ê²€ì‚¬ í†µê³¼ í›„ íŒŒì¼ íƒ€ì… ë¶„ê¸°
        def token_cond(state: CleanerState):
            return "classify" if not state.issues else END

        self.graph.add_conditional_edges("tokenize", token_cond)

        # text/audio classifier â†’ ë‘ ê°œ ë¶„ê¸°
        def classify_cond(state: CleanerState):
            if state.file_type == "text":
                return "text_validate"
            elif state.file_type == "audio":
                return "audio_extract"
            else:
                state.issues.append("unsupported_file_type")
                return END

        self.graph.add_conditional_edges("classify", classify_cond)

        # text flow
        self.graph.add_edge("text_validate", "merge")

        # audio flow
        self.graph.add_edge("audio_extract", "merge")

        # ë§ˆì§€ë§‰
        self.graph.add_edge("merge", END)

        # ì»´íŒŒì¼
        self.pipeline = self.graph.compile()



    # =========================================
    # 1ï¸âƒ£ RawFetcher
    # =========================================
    def node_fetch(self, state: CleanerState):
        if self.verbose:
            print("\n[1ï¸âƒ£ RawFetcher] conversation_file.raw_content ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦")

        try:
            fetch_result = self.fetcher.fetch(db=state.db, conv_id=state.conv_id)

            state.raw_df = fetch_result["df"]
            state.file_type = fetch_result["file_type"]
            state.audio_url = fetch_result["audio_url"]
            state.speaker_segments = fetch_result["speaker_segments"]

            print(f"   â†’ file_type={state.file_type}, ë°œí™” {len(state.raw_df)}ê°œ")

            return state

        except Exception as e:
            return self.exception_handler.handle(state, e)




    # =========================================
    # 2ï¸âƒ£ DataInspector
    # =========================================
    def node_inspect(self, state: CleanerState):
        if self.verbose:
            print("\n[2ï¸âƒ£ DataInspector] turn ê²€ì‚¬ ì¤‘â€¦")

        try:
            df, issues = self.inspector.inspect(state.raw_df, state)
            state.inspected_df = df
            state.issues.extend(issues)

            if issues:
                print("   âŒ turn ë¶€ì¡±:", issues)
            else:
                print("   âœ… turn ê²€ì‚¬ í†µê³¼")

            return state

        except Exception as e:
            return self.exception_handler.handle(state, e)




    # =========================================
    # 3ï¸âƒ£ TokenCounter
    # =========================================
    def node_tokenize(self, state: CleanerState):
        if self.verbose:
            print("\n[3ï¸âƒ£ TokenCounter] í™”ìë³„ 25 ì–´ì ˆ ê²€ì‚¬ ì¤‘â€¦")

        try:
            df, issues = self.token_counter.count(state.inspected_df, state)
            state.issues.extend(issues)

            if issues:
                print("   âŒ ì–´ì ˆ ë¶€ì¡±:", issues)
            else:
                print("   âœ… ì–´ì ˆ ê²€ì‚¬ í†µê³¼")

            return state

        except Exception as e:
            return self.exception_handler.handle(state, e)




    # =========================================
    # 4ï¸âƒ£ FileTypeClassifier
    # =========================================
    def node_classify(self, state: CleanerState):
        if self.verbose:
            print("\n[4ï¸âƒ£ FileTypeClassifier] íŒŒì¼ íƒ€ì… ë¶„ë¥˜ ì¤‘â€¦")

        try:
            file_type = self.classifier.classify(state.file_type)
            state.file_type = file_type
            print(f"   â†’ file_type={file_type}")

            return state

        except Exception as e:
            return self.exception_handler.handle(state, e)




    # =========================================
    # 5ï¸âƒ£ Text Flow: ContentValidator
    # =========================================
    def node_text_validate(self, state: CleanerState):
        if self.verbose:
            print("\n[5ï¸âƒ£ ContentValidator] í…ìŠ¤íŠ¸ ê²€ì¦ ì¤‘â€¦")

        try:
            validated_df = self.validator.validate(state.inspected_df)
            state.validated_df = validated_df
            return state

        except Exception as e:
            return self.exception_handler.handle(state, e)




    # =========================================
    # 6ï¸âƒ£ Audio Flow: AudioFeatureExtractor
    # =========================================
    def node_audio_extract(self, state: CleanerState):
        if self.verbose:
            print("\n[6ï¸âƒ£ AudioFeatureExtractor] ìŒì„± ë¶„ì„ ì¤‘â€¦")

        try:
            features = self.audio_extractor.extract(
                audio_url=state.audio_url,
                speaker_segments=state.speaker_segments
            )
            state.audio_features = features
            return state

        except Exception as e:
            return self.exception_handler.handle(state, e)




    # =========================================
    # 7ï¸âƒ£ ContentMerger
    # =========================================
    def node_merge(self, state: CleanerState):
        if self.verbose:
            print("\n[7ï¸âƒ£ ContentMerger] í…ìŠ¤íŠ¸ + ìŒì„± ìš”ì†Œ ë³‘í•© ì¤‘â€¦")

        try:
            merged_df = self.merger.merge(
                text_df=state.inspected_df,
                audio_features=state.audio_features
            )
            state.merged_df = merged_df
            state.validated = True
            return state

        except Exception as e:
            return self.exception_handler.handle(state, e)




    # =========================================
    # ì‹¤í–‰ ë©”ì„œë“œ
    # =========================================
    def run(self, db: Session, conv_id: str):
        if self.verbose:
            print("\nğŸš€ [CleanerGraph] ì‹¤í–‰ ì‹œì‘\n" + "=" * 60)

        state = CleanerState(
            db=db,
            conv_id=conv_id,
            verbose=self.verbose,
        )

        final_state = self.pipeline.invoke(state)

        if self.verbose:
            print("ğŸ [CleanerGraph] ì™„ë£Œ\n" + "=" * 60)

        return final_state
