from __future__ import annotations
from dataclasses import dataclass, field
from typing import Any, List, Dict, Optional
from langgraph.graph import StateGraph, END
from sqlalchemy.orm import Session
import pandas as pd

# ë…¸ë“œ import
from .nodes import (
    RawFetcher,
    DataInspector,
    TokenCounter,
    FileTypeClassifier,
    AudioFeatureExtractor,
    ContentValidator,
    ContentMerger,
    ExceptionHandler
)

# =========================================
# STATE ì •ì˜
# =========================================
@dataclass
class CleanerState:
    db: Optional[Session] = None
    conv_id: Optional[str] = None
    conversation_df: Optional[pd.DataFrame] = None   # â­ NEW

    # RAW
    raw_df: Optional[pd.DataFrame] = None
    file_type: Optional[str] = None
    audio_url: Optional[str] = None
    speaker_segments: Optional[List[Dict]] = None

    # PROCESSING
    inspected_df: Optional[pd.DataFrame] = None
    validated_df: Optional[pd.DataFrame] = None
    audio_features: Optional[List[Dict]] = None
    merged_df: Optional[pd.DataFrame] = None

    # ê²°ê³¼
    validated: bool = False
    issues: List[str] = field(default_factory=list)

    verbose: bool = False



# =========================================
# CLEANER GRAPH
# =========================================
class CleanerGraph:
    def __init__(self, verbose: bool = True):
        self.verbose = verbose

        # ë…¸ë“œ
        self.fetcher = RawFetcher()
        self.inspector = DataInspector()
        self.token_counter = TokenCounter()
        self.classifier = FileTypeClassifier()
        self.audio_extractor = AudioFeatureExtractor()
        self.validator = ContentValidator()
        self.merger = ContentMerger()
        self.exception_handler = ExceptionHandler()

        # ê·¸ë˜í”„ ì»´í¬ë„ŒíŠ¸
        self.graph = StateGraph(CleanerState)

        self.graph.add_node("fetch", self.node_fetch)
        self.graph.add_node("inspect", self.node_inspect)
        self.graph.add_node("tokenize", self.node_tokenize)
        self.graph.add_node("classify", self.node_classify)
        self.graph.add_node("text_validate", self.node_text_validate)
        self.graph.add_node("audio_extract", self.node_audio_extract)
        self.graph.add_node("merge", self.node_merge)

        self.graph.set_entry_point("fetch")

        # fetch â†’ inspect â†’ tokenize
        self.graph.add_edge("fetch", "inspect")
        self.graph.add_edge("inspect", "tokenize")

        # tokenizer pass ì—¬ë¶€
        def token_cond(state: CleanerState):
            return "classify" if not state.issues else END

        self.graph.add_conditional_edges("tokenize", token_cond)

        # classify ë¶„ê¸°
        def classify_cond(state: CleanerState):
            if state.file_type == "text":
                return "text_validate"
            elif state.file_type == "audio":
                return "audio_extract"
            else:
                state.issues.append("unsupported_file_type")
                return END

        self.graph.add_conditional_edges("classify", classify_cond)

        self.graph.add_edge("text_validate", "merge")
        self.graph.add_edge("audio_extract", "merge")

        self.graph.add_edge("merge", END)

        self.pipeline = self.graph.compile()


    # =========================================
    # 1ï¸âƒ£ RawFetcher
    # =========================================
    def node_fetch(self, state: CleanerState):
        if self.verbose:
            print("\n[1ï¸âƒ£ RawFetcher] DF or raw_content ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘â€¦")

        try:
            # â­ NEW â€” ì™¸ë¶€ conversation_df ì œê³µëœ ê²½ìš°
            if state.conversation_df is not None:
                print("   â†’ ì™¸ë¶€ DF ì‚¬ìš©í•˜ì—¬ fetch ìƒëµ (raw_content ë¯¸ì‚¬ìš©)")
                fetch_result = self.fetcher.fetch(
                    db=state.db,
                    conv_id=state.conv_id,
                    conversation_df=state.conversation_df,  # â­ NEW
                )

            else:
                # ê¸°ì¡´ DB raw_content ë°©ì‹
                fetch_result = self.fetcher.fetch(
                    db=state.db,
                    conv_id=state.conv_id
                )

            # ê³µí†µ ì €ì¥
            state.raw_df = fetch_result["df"]
            state.file_type = fetch_result["file_type"]
            state.audio_url = fetch_result["audio_url"]
            state.speaker_segments = fetch_result["speaker_segments"]

            print(f"   â†’ file_type={state.file_type}, ë°œí™” {len(state.raw_df)}ê°œ")

            return state

        except Exception as e:
            return self.exception_handler.handle(state, e)


    # =========================================
    def node_inspect(self, state: CleanerState):
        if self.verbose:
            print("\n[2ï¸âƒ£ DataInspector] turn ê²€ì‚¬ ì¤‘â€¦")

        try:
            df, issues = self.inspector.inspect(state.raw_df, state)
            state.inspected_df = df
            state.issues.extend(issues)

            if issues:
                print("   âŒ turn ë¶€ì¡±:", issues)
            else:
                print("   âœ… turn ê²€ì‚¬ í†µê³¼")
            return state
        except Exception as e:
            return self.exception_handler.handle(state, e)


    # =========================================
    def node_tokenize(self, state: CleanerState):
        if self.verbose:
            print("\n[3ï¸âƒ£ TokenCounter] í™”ìë³„ 25 ì–´ì ˆ ê²€ì‚¬ ì¤‘â€¦")

        try:
            df, issues = self.token_counter.count(state.inspected_df, state)
            state.issues.extend(issues)

            if issues:
                print("   âŒ ì–´ì ˆ ë¶€ì¡±:", issues)
            else:
                print("   âœ… ì–´ì ˆ ê²€ì‚¬ í†µê³¼")

            return state
        except Exception as e:
            return self.exception_handler.handle(state, e)


    # =========================================
    def node_classify(self, state: CleanerState):
        if self.verbose:
            print("\n[4ï¸âƒ£ FileTypeClassifier] íŒŒì¼ íƒ€ì… ë¶„ë¥˜ ì¤‘â€¦")

        try:
            state.file_type = self.classifier.classify(state.file_type)
            print(f"   â†’ file_type={state.file_type}")
            return state
        except Exception as e:
            return self.exception_handler.handle(state, e)


    # =========================================
    def node_text_validate(self, state: CleanerState):
        if self.verbose:
            print("\n[5ï¸âƒ£ ContentValidator] í…ìŠ¤íŠ¸ ê²€ì¦ ì¤‘â€¦")

        try:
            state.validated_df = self.validator.validate(state.inspected_df)
            return state
        except Exception as e:
            return self.exception_handler.handle(state, e)


    # =========================================
    def node_audio_extract(self, state: CleanerState):
        if self.verbose:
            print("\n[6ï¸âƒ£ AudioFeatureExtractor] ìŒì„± ë¶„ì„ ì¤‘â€¦")

        try:
            state.audio_features = self.audio_extractor.extract(
                audio_url=state.audio_url,
                speaker_segments=state.speaker_segments,
            )
            return state
        except Exception as e:
            return self.exception_handler.handle(state, e)


    # =========================================
    def node_merge(self, state: CleanerState):
        if self.verbose:
            print("\n[7ï¸âƒ£ ContentMerger] í…ìŠ¤íŠ¸ + ìŒì„± ë³‘í•© ì¤‘â€¦")

        try:
            state.merged_df = self.merger.merge(
                text_df=state.inspected_df,
                audio_features=state.audio_features,
            )
            state.validated = True
            return state
        except Exception as e:
            return self.exception_handler.handle(state, e)


    # =========================================
    # ì‹¤í–‰
    # =========================================
    def run(self, db: Session, conv_id: str, conversation_df=None):  
        if self.verbose:
            print("\nğŸš€ [CleanerGraph] ì‹¤í–‰ ì‹œì‘\n" + "=" * 60)

        state = CleanerState(
            db=db,
            conv_id=conv_id,
            conversation_df=conversation_df,    
            verbose=self.verbose,
        )

        final_state = self.pipeline.invoke(state)

        if self.verbose:
            print("ğŸ [CleanerGraph] ì™„ë£Œ\n" + "=" * 60)

        return final_state
