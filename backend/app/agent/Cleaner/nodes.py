from __future__ import annotations
from dataclasses import dataclass
from typing import Any, Dict, List, Tuple, Optional
import pandas as pd
import numpy as np
import requests
from sqlalchemy.orm import Session

# CRUD
from app.agent.crud import (
    get_conversation_by_id,
    get_conversation_file_by_conv_id,
)


# ===============================================================
# 1) RawFetcher
# ===============================================================
@dataclass
class RawFetcher:

    def fetch(
        self,
        db: Session = None,
        conv_id: str = None,
        conversation_df: Optional[pd.DataFrame] = None,  
        *args,
        **kwargs
    ) -> Dict[str, Any]:

        # â­ NEW â€” ì™¸ë¶€ì—ì„œ DFê°€ ë“¤ì–´ì™”ìœ¼ë©´ raw_content ë¬´ì‹œí•˜ê³  ê·¸ëŒ€ë¡œ ì‚¬ìš©
        if conversation_df is not None:
            print("âœ… [RawFetcher] ì™¸ë¶€ ì „ë‹¬ conversation_df ì‚¬ìš©")
            return {
                "df": conversation_df,
                "file_type": "external",  # ë¶„ì„ íë¦„ ìœ„í•´ íƒ€ì…ë§Œ ì„¸íŒ…
                "audio_url": None,
                "speaker_segments": None,
            }

        # ------- ê¸°ì¡´ raw_content ê¸°ë°˜ ë¡œì§ ê·¸ëŒ€ë¡œ ìœ ì§€ -------
        if db is None:
            raise ValueError("âŒ RawFetcher: db ì„¸ì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        if not conv_id:
            raise ValueError("âŒ RawFetcher: conv_id(UUID)ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        meta = get_conversation_by_id(db, conv_id)
        if not meta:
            raise ValueError(f"âŒ conversation ë©”íƒ€ì •ë³´ ì—†ìŒ (conv_id={conv_id})")

        file_row = get_conversation_file_by_conv_id(db, conv_id)
        if not file_row:
            raise ValueError(f"âŒ conversation_file row ì—†ìŒ (conv_id={conv_id})")

        # DBì— ì €ì¥ëœ ì •ë³´ ì‚¬ìš©
        file_type = file_row.get("file_type")
        audio_url = file_row.get("audio_url")
        speaker_segments = file_row.get("speaker_segments")
        raw_text = file_row.get("raw_content")

        if not raw_text:
            raise ValueError(f"âŒ raw_content ë¹„ì–´ ìˆìŒ (conv_id={conv_id})")

        df = self._to_dataframe(raw_text)

        print(f"âœ… [RawFetcher] raw_content ë¡œë“œ ì™„ë£Œ â†’ {len(df)}ê°œ ë°œí™”")

        return {
            "df": df,
            "file_type": file_type,
            "audio_url": audio_url,
            "speaker_segments": speaker_segments,
        }

    # ===============================================================
    def _to_dataframe(self, raw_text: str) -> pd.DataFrame:
        lines = raw_text.strip().split("\n")

        data = []
        current_speaker = None
        current_text = ""

        for line in lines:
            line = line.strip()
            if not line:
                continue

            if line.startswith("ì°¸ì„ì"):
                if current_speaker is not None and current_text:
                    data.append({
                        "speaker": current_speaker,
                        "text": current_text.strip(),
                    })
                parts = line.split()
                current_speaker = int(parts[1].replace(":", ""))
                current_text = ""
            else:
                current_text += line + " "

        if current_speaker is not None and current_text:
            data.append({
                "speaker": current_speaker,
                "text": current_text.strip(),
            })

        return pd.DataFrame(data)


# ===============================================================
# 2) DataInspector (turn â‰¥ 3)
# ===============================================================
@dataclass
class DataInspector:
    def inspect(self, df: pd.DataFrame, state=None) -> Tuple[pd.DataFrame, List[str]]:
        issues = []
        if len(df) < 3:
            issues.append("not_enough_turns")
        return df, issues


# ===============================================================
# 3) TokenCounter (speakerë³„ 25 tokens)
# ===============================================================
@dataclass
class TokenCounter:
    def count(self, df: pd.DataFrame, state=None) -> Tuple[pd.DataFrame, List[str]]:
        issues = []

        # â­ MODIFIED â€” speakerê°€ ë¬¸ìì—´ì¼ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ groupby
        grouped = df.groupby("speaker")["text"].apply(
            lambda x: sum(len(s.split()) for s in x)
        )

        for spk, tcount in grouped.items():
            if tcount < 25:
                issues.append(f"speaker_{spk}_not_enough_tokens")

        return df, issues


# ===============================================================
# 4) FileTypeClassifier
# ===============================================================
@dataclass
class FileTypeClassifier:
    """
    DB file_type ê¸°ë°˜ìœ¼ë¡œ text/audio ì—¬ë¶€ íŒë³„
    """

    ALLOWED_AUDIO = ["wav", "mp3", "webm", "m4a"]
    ALLOWED_TEXT = ["txt", "pdf", "doc", "docx", "external"]  # â­ NEW: external ì¶”ê°€

    def classify(self, file_type: str) -> str:
        if not file_type:
            raise ValueError("âŒ file_type ì—†ìŒ")

        file_type = file_type.lower()

        if file_type in self.ALLOWED_AUDIO:
            return "audio"
        if file_type in self.ALLOWED_TEXT:
            return "text"

        raise ValueError(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ íƒ€ì…: {file_type}")


# ===============================================================
# 5) AudioFeatureExtractor (OpenSMILE ê¸°ë°˜)
# ===============================================================
@dataclass
class AudioFeatureExtractor:
    def _load_audio(self, audio_url: str):
        import requests, io, librosa
        resp = requests.get(audio_url)
        if resp.status_code != 200:
            raise ValueError("âŒ audio_url ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")

        audio_bytes = resp.content
        y, sr = librosa.load(io.BytesIO(audio_bytes), sr=None)
        return y, sr

    def _extract_segment(self, y, sr, start, end):
        start_idx = int(start * sr)
        end_idx = int(end * sr)
        return y[start_idx:end_idx]

    def extract(self, audio_url: str, speaker_segments: List[Dict]) -> List[Dict]:
        if not audio_url:
            raise ValueError("âŒ audio_url ì—†ìŒ")

        if not speaker_segments:
            raise ValueError("âŒ speaker_segments ì—†ìŒ")

        import opensmile
        smile = opensmile.Smile(
            feature_set=opensmile.FeatureSet.eGeMAPSv02,
            feature_level=opensmile.FeatureLevel.Functionals,
        )

        y, sr = self._load_audio(audio_url)
        results = []

        for seg in speaker_segments:
            speaker = seg["speaker"]
            start = seg["start"]
            end = seg["end"]

            try:
                chunk = self._extract_segment(y, sr, start, end)
                if len(chunk) == 0:
                    continue

                import soundfile as sf
                import tempfile

                with tempfile.NamedTemporaryFile(suffix=".wav") as tmp_wav:
                    sf.write(tmp_wav.name, chunk, sr)
                    feats = smile.process_file(tmp_wav.name)

                feat_dict = feats.iloc[0].to_dict()

                results.append({
                    "speaker": speaker,
                    "start": start,
                    "end": end,
                    "features": feat_dict,
                })

            except Exception as e:
                print(f"âŒ Audio segment ì²˜ë¦¬ ì‹¤íŒ¨: {speaker}, {start}-{end}: {e}")
                continue

        print(f"ğŸ›ï¸ [AudioFeatureExtractor_v2] {len(results)}ê°œ segment íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ")
        return results


# ===============================================================
# 6) ContentValidator (í…ìŠ¤íŠ¸ ì „ìš©)
# ===============================================================
@dataclass
class ContentValidator:
    def validate(self, df: pd.DataFrame) -> pd.DataFrame:
        return df

    def _parse_batch_response(self, response: str, original_batch: List[str]) -> List[str]:
        lines = response.strip().split('\n')
        cleaned_batch = []

        for i, original in enumerate(original_batch, 1):
            found = False
            for line in lines:
                if line.strip().startswith(f"{i}."):
                    cleaned_text = line.strip()[2:].strip()
                    cleaned_batch.append(cleaned_text)
                    found = True
                    break

            if not found:
                cleaned_batch.append(original)

        return cleaned_batch


# ===============================================================
# 7) ContentMerger
# ===============================================================
@dataclass
class ContentMerger:
    def merge(self, text_df: pd.DataFrame, audio_features: Optional[List[Dict]]) -> pd.DataFrame:
        df = text_df.copy()
        df["audio_features"] = None

        if not audio_features:
            return df

        from collections import defaultdict, deque

        seg_dict = defaultdict(deque)
        for seg in audio_features:
            seg_dict[seg["speaker"]].append(seg)

        for idx, row in df.iterrows():
            spk = row["speaker"]

            if spk in seg_dict and len(seg_dict[spk]) > 0:
                seg = seg_dict[spk].popleft()
                df.at[idx, "audio_features"] = seg["features"]
            else:
                df.at[idx, "audio_features"] = None

        return df


# ===============================================================
# ExceptionHandler
# ===============================================================
@dataclass
class ExceptionHandler:
    def handle(self, state, err: Exception):
        if hasattr(state, "issues"):
            state.issues.append(str(err))
        state.validated = False
        return state
