# app/agent/Cleaner/nodes.py
from __future__ import annotations
from dataclasses import dataclass
from datetime import datetime
from typing import Any, Dict, List, Tuple
from app.core.config import settings  # âœ… LLM í‚¤ ì‚¬ìš©
from langchain_openai import ChatOpenAI  # âœ… LLM ì—°ê²°
import uuid

try:
    import pandas as pd
except Exception:
    pd = None

# âœ… DB ì—°ë™ ì¶”ê°€
from sqlalchemy.orm import Session
from app.agent.crud import (
    get_conversation_by_id,
    get_conversation_by_pk,
    conversation_to_dataframe,
)


# =========================================
# âœ… RawFetcher (DB ì—°ë™)
# =========================================
@dataclass
class RawFetcher:
    """
    âœ… DBì—ì„œ conversation ì¡°íšŒ
    
    ë³€ê²½ ì‚¬í•­:
    - ê¸°ì¡´: SAMPLE_DIALOG (í•˜ë“œì½”ë”©)
    - ë³€ê²½: DBì—ì„œ conversation ì¡°íšŒ
    """
    def fetch(self, db: Session = None, conv_id: str = None, pk_id: int = None, *args, **kwargs) -> Any:
        """
        DBì—ì„œ conversation ì¡°íšŒ í›„ DataFrame ë°˜í™˜
        
        Args:
            db: SQLAlchemy ì„¸ì…˜
            conv_id: ëŒ€í™” UUID (ì„ íƒ)
            pk_id: ëŒ€í™” PK ID (ì„ íƒ)
        
        Returns:
            DataFrame (speaker, text, timestamp)
        """
        if db is None:
            raise ValueError("âŒ RawFetcher: db ì„¸ì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # âœ… DBì—ì„œ conversation ì¡°íšŒ
        if conv_id:
            conversation = get_conversation_by_id(db, conv_id)
        elif pk_id:
            conversation = get_conversation_by_pk(db, pk_id)
        else:
            raise ValueError("âŒ RawFetcher: conv_id ë˜ëŠ” pk_idë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.")
        
        if not conversation:
            raise ValueError(f"âŒ RawFetcher: conversationì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (conv_id={conv_id}, pk_id={pk_id})")
        
        print(f"âœ… [RawFetcher] ëŒ€í™” ì¡°íšŒ ì„±ê³µ: {conversation['cont_title'][:50]}...")
        
        # âœ… conversation â†’ DataFrame ë³€í™˜
        df = conversation_to_dataframe(conversation)
        
        print(f"   â†’ DataFrame ìƒì„±: {len(df)}ê°œ ë°œí™”")
        
        return df


# =========================================
# âœ… RawInspector (ê¸°ì¡´ ìœ ì§€)
# =========================================
@dataclass
class RawInspector:
    """í™”ì, ì—…ë¡œë”(user_id) ê²€ì¦"""
    def inspect(self, raw: Any, state=None) -> Tuple[Any, List[str]]:
        issues: List[str] = []
        if pd is not None and isinstance(raw, pd.DataFrame):
            df = raw.copy()
            unique_speakers = set(df["speaker"].astype(str))

            # âœ… í™”ì 2ëª… ì´ìƒì¸ì§€ í™•ì¸
            if len(unique_speakers) < 2:
                issues.append("not_enough_speakers")

            # âœ… ì—…ë¡œë”(user_id)ê°€ í™”ì ì¤‘ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            if state and getattr(state, "user_id", None):
                if str(state.user_id) not in unique_speakers:
                    issues.append("uploader_not_in_speakers")
            else:
                issues.append("missing_user_id")

            # âœ… timestamp ëˆ„ë½ ì—¬ë¶€
            if "timestamp" not in df.columns or df["timestamp"].isnull().any():
                issues.append("missing_timestamp")

            # âœ… ì°¸ì—¬ì ëª©ë¡(user_ids) ê°±ì‹ 
            if state:
                state.user_ids = list(unique_speakers)

            return df, issues

        return raw, ["unsupported_raw_type"]


# =========================================
# âœ… ConversationCleaner (ê¸°ì¡´ ìœ ì§€)
# =========================================
@dataclass
class ConversationCleaner:
    """LLMì„ ì‚¬ìš©í•´ ë¬¸ì¥ ì •ì œ ë° ë…¸ì´ì¦ˆ ì œê±°"""
    verbose: bool = False

    def clean(self, df: Any, state=None) -> Any:
        if pd is not None and isinstance(df, pd.DataFrame):
            out = df.copy()
            llm = ChatOpenAI(model="gpt-4o-mini", api_key=settings.openai_api_key)

            cleaned = []
            for text in out["text"]:
                prompt = f"ë‹¤ìŒ ë¬¸ì¥ì—ì„œ ì² ì ì˜¤ë¥˜ë‚˜ ì´ìƒí•œ ê¸°í˜¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìˆ˜ì •í•´ì¤˜:\n{text}"
                if self.verbose:
                    print(f"ğŸª¶ [Cleaner LLM ì…ë ¥] {text}")
                try:
                    response = llm.invoke(prompt)
                    cleaned_text = (
                        response.content
                        if hasattr(response, "content")
                        else str(response)
                    )
                    cleaned.append(cleaned_text)
                    if self.verbose:
                        print(f"âœ… [Cleaner LLM ê²°ê³¼] {cleaned_text}")
                except Exception as e:
                    cleaned.append(text)
                    print(f"âš ï¸ LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            out["text"] = cleaned
            return out
        return df


# =========================================
# âœ… ConversationValidator (ê¸°ì¡´ ìœ ì§€)
# =========================================
@dataclass
class ConversationValidator:
    """ëŒ€í™”ì˜ ë¶„ì„ ê°€ëŠ¥ì„± íŒë‹¨"""
    verbose: bool = False

    def validate(self, df: Any, state=None) -> Tuple[bool, List[str]]:
        issues: List[str] = []
        if pd is not None and isinstance(df, pd.DataFrame):
            # âœ… í‹°í‚¤íƒ€ì¹´ 3ì„¸íŠ¸(6íšŒ ì´ìƒ) ì—¬ë¶€
            speakers = df["speaker"].tolist()
            tiktaka = sum(speakers[i] != speakers[i - 1] for i in range(1, len(speakers)))
            if tiktaka < 6:
                issues.append("not_enough_tiktaka")

            llm_ok, reason = self._llm_judge(df)
            if not llm_ok:
                issues.append(f"llm_rejected:{reason}")
            return (len(issues) == 0), issues
        return False, ["unsupported_type"]

    def _llm_judge(self, df: Any) -> Tuple[bool, str]:
        """LLMìœ¼ë¡œ ê°ì • ë¶„ì„ ì í•© ì—¬ë¶€ íŒë‹¨"""
        llm = ChatOpenAI(model="gpt-4o-mini", api_key=settings.openai_api_key)
        text = "\n".join(df["text"].astype(str).tolist()[:6])
        prompt = f"ë‹¤ìŒ ëŒ€í™”ê°€ ê°ì •ë¶„ì„ì— ì í•©í•œê°€? 'ì í•©' ë˜ëŠ” 'ë¶€ì í•©'ìœ¼ë¡œë§Œ ëŒ€ë‹µ:\n{text}"
        try:
            response = llm.invoke(prompt)
            reply = response.content if hasattr(response, "content") else str(response)
            if self.verbose:
                print(f"ğŸ¤– [Validator LLM ì‘ë‹µ] {reply}")
            return "ë¶€ì í•©" not in reply, reply
        except Exception as e:
            return False, str(e)


# =========================================
# âœ… ConversationSaver (ìˆ˜ì • - DB ì´ë¯¸ ìˆìœ¼ë¯€ë¡œ ìŠ¤í‚µ)
# =========================================
@dataclass
class ConversationSaver:
    """
    âœ… conversation í…Œì´ë¸”ì— ì €ì¥ (ì´ë¯¸ DBì— ìˆìœ¼ë¯€ë¡œ í˜„ì¬ëŠ” ìŠ¤í‚µ)
    
    ë³€ê²½ ì‚¬í•­:
    - ê¸°ì¡´: DataFrame â†’ conversation í…Œì´ë¸” INSERT
    - ë³€ê²½: ì´ë¯¸ DBì— ìˆìœ¼ë¯€ë¡œ ë©”íƒ€ë°ì´í„°ë§Œ stateì— ì €ì¥
    """
    def save(self, df: Any, state=None) -> Dict[str, Any]:
        """
        ì´ë¯¸ DBì— conversationì´ ì¡´ì¬í•˜ë¯€ë¡œ ìŠ¤í‚µ
        stateì— ë©”íƒ€ë°ì´í„°ë§Œ ì €ì¥
        """
        try:
            # âœ… ì´ë¯¸ DBì— ì €ì¥ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ë©”íƒ€ì •ë³´ë§Œ ë°˜í™˜
            if state and hasattr(state, "conv_id"):
                return {
                    "status": "already_saved",
                    "conversation_id": state.conv_id,
                    "message": "ëŒ€í™”ëŠ” ì´ë¯¸ DBì— ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
                }
            
            return {"status": "skipped"}

        except Exception as e:
            return {"status": "error", "error": str(e)}


# =========================================
# âœ… ExceptionHandler ê·¸ëŒ€ë¡œ ìœ ì§€
# =========================================
@dataclass
class ExceptionHandler:
    """ì˜ˆì™¸ë¥¼ í‘œì¤€í™”í•˜ì—¬ ë°˜í™˜"""
    def handle(self, err: Exception) -> Dict[str, Any]:
        return {"status": "error", "error": str(err)}