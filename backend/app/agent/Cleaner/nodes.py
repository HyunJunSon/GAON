# app/agent/Cleaner/nodes.py
from __future__ import annotations
from dataclasses import dataclass
from datetime import datetime
from typing import Any, Dict, List, Tuple
from app.core.config import settings  # âœ… LLM í‚¤ ì‚¬ìš©
from langchain_openai import ChatOpenAI  # âœ… LLM ì—°ê²°
import uuid

try:
    import pandas as pd
except Exception:
    pd = None

# âœ… DB ì—°ë™ ì¶”ê°€
from sqlalchemy.orm import Session
from app.agent.crud import (
    get_conversation_by_id,
    get_conversation_by_pk,
    conversation_to_dataframe,
)


# =========================================
# âœ… RawFetcher (DB ì—°ë™)
# =========================================
@dataclass
class RawFetcher:
    """
    âœ… DBì—ì„œ conversation ì¡°íšŒ
    
    ë³€ê²½ ì‚¬í•­:
    - ê¸°ì¡´: SAMPLE_DIALOG (í•˜ë“œì½”ë”©)
    - ë³€ê²½: DBì—ì„œ conversation ì¡°íšŒ
    """
    def fetch(self, db: Session = None, conv_id: str = None, *args, **kwargs) -> Any:
        if db is None:
            raise ValueError("âŒ RawFetcher: db ì„¸ì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        if not conv_id:
            raise ValueError("âŒ RawFetcher: conv_id(UUID)ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        conversation = get_conversation_by_id(db, conv_id)
        if not conversation:
            raise ValueError(f"âŒ RawFetcher: conversationì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (conv_id={conv_id})")

        print(f"âœ… [RawFetcher] ëŒ€í™” ì¡°íšŒ ì„±ê³µ: {conversation['title'][:50]}...")
        df = conversation_to_dataframe(conversation)
        print(f"   â†’ DataFrame ìƒì„±: {len(df)}ê°œ ë°œí™”")
        return df



# =========================================
# âœ… RawInspector (ê¸°ì¡´ ìœ ì§€)
# =========================================
@dataclass
class RawInspector:
    """í™”ì, ì—…ë¡œë”(id) ê²€ì¦"""
    def inspect(self, raw: Any, state=None) -> Tuple[Any, List[str]]:
        issues: List[str] = []
        if pd is not None and isinstance(raw, pd.DataFrame):
            df = raw.copy()
            unique_speakers = set(df["speaker"].astype(str))

            # âœ… í™”ì 2ëª… ì´ìƒì¸ì§€ í™•ì¸
            if len(unique_speakers) < 2:
                issues.append("not_enough_speakers")

            # âœ… ì—…ë¡œë”(id)ê°€ í™”ì ì¤‘ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            if state and getattr(state, "id", None):
                if str(state.id) not in unique_speakers:
                    issues.append("uploader_not_in_speakers")
            else:
                issues.append("missing_user_id")

            # âœ… timestamp ëˆ„ë½ ì—¬ë¶€
            if "timestamp" not in df.columns or df["timestamp"].isnull().any():
                issues.append("missing_timestamp")

            # âœ… ì°¸ì—¬ì ëª©ë¡(user_ids) ê°±ì‹ 
            if state:
                state.user_ids = list(unique_speakers)

            return df, issues

        return raw, ["unsupported_raw_type"]


# =========================================
# âœ… ConversationCleaner (ê¸°ì¡´ ìœ ì§€)
# =========================================
@dataclass
class ConversationCleaner:
    """LLMì„ ì‚¬ìš©í•´ ë¬¸ì¥ ì •ì œ ë° ë…¸ì´ì¦ˆ ì œê±° (ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”)"""
    verbose: bool = False
    batch_size: int = 10  # í•œ ë²ˆì— ì²˜ë¦¬í•  ë¬¸ì¥ ìˆ˜

    def clean(self, df: Any, state=None) -> Any:
        if pd is not None and isinstance(df, pd.DataFrame):
            out = df.copy()
            llm = ChatOpenAI(model="gpt-4o-mini", api_key=settings.openai_api_key)

            texts = out["text"].tolist()
            cleaned = []
            
            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
            for i in range(0, len(texts), self.batch_size):
                batch = texts[i:i + self.batch_size]
                
                # ë°°ì¹˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
                batch_prompt = "ë‹¤ìŒ ë¬¸ì¥ë“¤ì—ì„œ ì² ì ì˜¤ë¥˜ë‚˜ ì´ìƒí•œ ê¸°í˜¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìˆ˜ì •í•´ì¤˜. ê° ë¬¸ì¥ì„ ë²ˆí˜¸ì™€ í•¨ê»˜ ìˆ˜ì •í•´ì„œ ë°˜í™˜í•´ì¤˜:\n\n"
                for j, text in enumerate(batch, 1):
                    batch_prompt += f"{j}. {text}\n"
                
                if self.verbose:
                    print(f"ğŸª¶ [Cleaner LLM ë°°ì¹˜ {i//self.batch_size + 1}] {len(batch)}ê°œ ë¬¸ì¥ ì²˜ë¦¬ ì¤‘...")
                
                try:
                    response = llm.invoke(batch_prompt)
                    cleaned_text = (
                        response.content
                        if hasattr(response, "content")
                        else str(response)
                    )
                    
                    # ì‘ë‹µì—ì„œ ê°œë³„ ë¬¸ì¥ ì¶”ì¶œ
                    batch_cleaned = self._parse_batch_response(cleaned_text, batch)
                    cleaned.extend(batch_cleaned)
                    
                    if self.verbose:
                        print(f"âœ… [Cleaner LLM ë°°ì¹˜ ì™„ë£Œ] {len(batch_cleaned)}ê°œ ë¬¸ì¥ ì •ì œë¨")
                        
                except Exception as e:
                    # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš©
                    cleaned.extend(batch)
                    print(f"âš ï¸ ë°°ì¹˜ LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            
            out["text"] = cleaned
            return out
        return df
    
    def _parse_batch_response(self, response: str, original_batch: List[str]) -> List[str]:
        """ë°°ì¹˜ ì‘ë‹µì—ì„œ ê°œë³„ ë¬¸ì¥ ì¶”ì¶œ"""
        lines = response.strip().split('\n')
        cleaned_batch = []
        
        for i, original in enumerate(original_batch, 1):
            # ë²ˆí˜¸ë¡œ ì‹œì‘í•˜ëŠ” ë¼ì¸ ì°¾ê¸°
            found = False
            for line in lines:
                if line.strip().startswith(f"{i}."):
                    cleaned_text = line.strip()[2:].strip()  # "1. " ì œê±°
                    cleaned_batch.append(cleaned_text)
                    found = True
                    break
            
            if not found:
                # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš©
                cleaned_batch.append(original)
        
        return cleaned_batch


# =========================================
# âœ… ConversationValidator (ê¸°ì¡´ ìœ ì§€)
# =========================================
@dataclass
class ConversationValidator:
    """ëŒ€í™”ì˜ ë¶„ì„ ê°€ëŠ¥ì„± íŒë‹¨"""
    verbose: bool = False

    def validate(self, df: Any, state=None) -> Tuple[bool, List[str]]:
        issues: List[str] = []
        if pd is not None and isinstance(df, pd.DataFrame):
            # âœ… í‹°í‚¤íƒ€ì¹´ 3ì„¸íŠ¸(6íšŒ ì´ìƒ) ì—¬ë¶€
            speakers = df["speaker"].tolist()
            tiktaka = sum(speakers[i] != speakers[i - 1] for i in range(1, len(speakers)))
            if tiktaka < 6:
                issues.append("not_enough_tiktaka")

            llm_ok, reason = self._llm_judge(df)
            if not llm_ok:
                issues.append(f"llm_rejected:{reason}")
            return (len(issues) == 0), issues
        return False, ["unsupported_type"]

    def _llm_judge(self, df: Any) -> Tuple[bool, str]:
        """LLMìœ¼ë¡œ ê°ì • ë¶„ì„ ì í•© ì—¬ë¶€ íŒë‹¨"""
        llm = ChatOpenAI(model="gpt-4o-mini", api_key=settings.openai_api_key)
        text = "\n".join(df["text"].astype(str).tolist()[:6])
        prompt = f"ë‹¤ìŒ ëŒ€í™”ê°€ ê°ì •ë¶„ì„ì— ì í•©í•œê°€? 'ì í•©' ë˜ëŠ” 'ë¶€ì í•©'ìœ¼ë¡œë§Œ ëŒ€ë‹µ:\n{text}"
        try:
            response = llm.invoke(prompt)
            reply = response.content if hasattr(response, "content") else str(response)
            if self.verbose:
                print(f"ğŸ¤– [Validator LLM ì‘ë‹µ] {reply}")
            return "ë¶€ì í•©" not in reply, reply
        except Exception as e:
            return False, str(e)


# =========================================
# âœ… ConversationSaver (ìˆ˜ì • - DB ì´ë¯¸ ìˆìœ¼ë¯€ë¡œ ìŠ¤í‚µ)
# =========================================
@dataclass
class ConversationSaver:
    """
    âœ… conversation í…Œì´ë¸”ì— ì €ì¥ (ì´ë¯¸ DBì— ìˆìœ¼ë¯€ë¡œ í˜„ì¬ëŠ” ìŠ¤í‚µ)
    
    ë³€ê²½ ì‚¬í•­:
    - ê¸°ì¡´: DataFrame â†’ conversation í…Œì´ë¸” INSERT
    - ë³€ê²½: ì´ë¯¸ DBì— ìˆìœ¼ë¯€ë¡œ ë©”íƒ€ë°ì´í„°ë§Œ stateì— ì €ì¥
    """
    def save(self, df: Any, state=None) -> Dict[str, Any]:
        """
        ì´ë¯¸ DBì— conversationì´ ì¡´ì¬í•˜ë¯€ë¡œ ìŠ¤í‚µ
        stateì— ë©”íƒ€ë°ì´í„°ë§Œ ì €ì¥
        """
        try:
            # âœ… ì´ë¯¸ DBì— ì €ì¥ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ë©”íƒ€ì •ë³´ë§Œ ë°˜í™˜
            if state and hasattr(state, "conv_id"):
                return {
                    "status": "already_saved",
                    "conversation_id": state.conv_id,
                    "message": "ëŒ€í™”ëŠ” ì´ë¯¸ DBì— ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
                }
            
            return {"status": "skipped"}

        except Exception as e:
            return {"status": "error", "error": str(e)}


# =========================================
# âœ… ExceptionHandler ê·¸ëŒ€ë¡œ ìœ ì§€
# =========================================
@dataclass
class ExceptionHandler:
    """ì˜ˆì™¸ë¥¼ í‘œì¤€í™”í•˜ì—¬ ë°˜í™˜"""
    def handle(self, err: Exception) -> Dict[str, Any]:
        return {"status": "error", "error": str(err)}