# app/agent/Cleaner/nodes.py 

from __future__ import annotations
from dataclasses import dataclass
from typing import Any, Dict, List, Tuple, Optional
import pandas as pd
import numpy as np
import requests
import librosa

from sqlalchemy.orm import Session

# CRUD
from app.agent.crud import (
    get_conversation_by_id,
    get_conversation_file_by_conv_id,
)


# ===============================================================
# 1) RawFetcher
# ===============================================================
@dataclass
class RawFetcher:
    """
    DBì—ì„œ conversation_file.raw_content ë° file_type/audio_url/speaker_segments ë¥¼ ì½ì–´
    â†’ DataFrame(df)ì™€ ë©”íƒ€ ì •ë³´ ë°˜í™˜
    """

    def fetch(self, db: Session = None, conv_id: str = None, *args, **kwargs) -> Dict[str, Any]:
        if db is None:
            raise ValueError("âŒ RawFetcher: db ì„¸ì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        if not conv_id:
            raise ValueError("âŒ RawFetcher: conv_id(UUID)ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        meta = get_conversation_by_id(db, conv_id)
        if not meta:
            raise ValueError(f"âŒ conversation ë©”íƒ€ì •ë³´ ì—†ìŒ (conv_id={conv_id})")

        file_row = get_conversation_file_by_conv_id(db, conv_id)
        if not file_row:
            raise ValueError(f"âŒ conversation_file row ì—†ìŒ (conv_id={conv_id})")

        # DBì— ì €ìž¥ëœ ì •ë³´ ì‚¬ìš©
        file_type = file_row.get("file_type")
        audio_url = file_row.get("audio_url")
        speaker_segments = file_row.get("speaker_segments")
        raw_text = file_row.get("raw_content")

        if not raw_text:
            raise ValueError(f"âŒ raw_content ë¹„ì–´ ìžˆìŒ (conv_id={conv_id})")

        df = self._to_dataframe(raw_text)

        print(f"âœ… [RawFetcher] raw_content ë¡œë“œ ì™„ë£Œ â†’ {len(df)}ê°œ ë°œí™”")

        return {
            "df": df,
            "file_type": file_type,
            "audio_url": audio_url,
            "speaker_segments": speaker_segments,
        }

    # ===============================================================
    def _to_dataframe(self, raw_text: str) -> pd.DataFrame:
        lines = raw_text.strip().split("\n")

        data = []
        current_speaker = None
        current_text = ""

        for line in lines:
            line = line.strip()
            if not line:
                continue

            if line.startswith("ì°¸ì„ìž"):
                if current_speaker is not None and current_text:
                    data.append({
                        "speaker": current_speaker,
                        "text": current_text.strip(),
                    })
                parts = line.split()
                current_speaker = int(parts[1].replace(":", ""))
                current_text = ""
            else:
                current_text += line + " "

        if current_speaker is not None and current_text:
            data.append({
                "speaker": current_speaker,
                "text": current_text.strip(),
            })

        return pd.DataFrame(data)


# ===============================================================
# 2) DataInspector (turn â‰¥ 3)
# ===============================================================
@dataclass
class DataInspector:
    def inspect(self, df: pd.DataFrame, state=None) -> Tuple[pd.DataFrame, List[str]]:
        issues = []
        if len(df) < 3:
            issues.append("not_enough_turns")
        return df, issues


# ===============================================================
# 3) TokenCounter (speakerë³„ 25 tokens)
# ===============================================================
@dataclass
class TokenCounter:
    def count(self, df: pd.DataFrame, state=None) -> Tuple[pd.DataFrame, List[str]]:
        issues = []
        grouped = df.groupby("speaker")["text"].apply(
            lambda x: sum(len(s.split()) for s in x)
        )

        for spk, tcount in grouped.items():
            if tcount < 25:
                issues.append(f"speaker_{spk}_not_enough_tokens")

        return df, issues


# ===============================================================
# 4) FileTypeClassifier
# ===============================================================
@dataclass
class FileTypeClassifier:
    """
    DB file_type ê¸°ë°˜ìœ¼ë¡œ text/audio ì—¬ë¶€ íŒë³„
    """

    ALLOWED_AUDIO = ["wav", "mp3", "webm", "m4a"]
    ALLOWED_TEXT = ["txt", "pdf", "doc", "docx"]

    def classify(self, file_type: str) -> str:
        if not file_type:
            raise ValueError("âŒ file_type ì—†ìŒ")

        file_type = file_type.lower()

        if file_type in self.ALLOWED_AUDIO:
            return "audio"
        if file_type in self.ALLOWED_TEXT:
            return "text"

        raise ValueError(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ íƒ€ìž…: {file_type}")


# ===============================================================
# 5) AudioFeatureExtractor
# ===============================================================
@dataclass
class AudioFeatureExtractor:
    """
    speaker_segments = [
        {"speaker": 1, "start": 0.0, "end": 2.4},
        {"speaker": 2, "start": 2.5, "end": 4.2},
    ]
    audio_urlì—ì„œ êµ¬ê°„ë³„ audio ì‹ í˜¸ë¥¼ ìž˜ë¼ì„œ íŠ¹ì§• ì¶”ì¶œ
    """

    def extract(self, audio_url: str, speaker_segments: List[Dict]) -> List[Dict]:

        if not audio_url:
            raise ValueError("âŒ audio_url ì—†ìŒ (audio íŒŒì¼ì´ ì•„ë‹˜)")

        # GCP URL ë‹¤ìš´ë¡œë“œ
        resp = requests.get(audio_url)
        if resp.status_code != 200:
            raise ValueError("âŒ audio_url ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")

        audio_bytes = resp.content

        # librosaë¡œ ë¡œë“œ (ë©”ëª¨ë¦¬ ìŠ¤íŠ¸ë¦¼)
        import io
        y, sr = librosa.load(io.BytesIO(audio_bytes), sr=None)

        features = []

        for seg in speaker_segments or []:
            start = int(seg["start"] * sr)
            end = int(seg["end"] * sr)
            chunk = y[start:end]

            if len(chunk) == 0:
                continue

            # íŠ¹ì§• ì¶”ì¶œ
            pitch = librosa.yin(chunk, fmin=50, fmax=500).mean()
            energy = float(np.mean(chunk ** 2))
            tempo, _ = librosa.beat.beat_track(y=chunk, sr=sr)

            features.append({
                "speaker": seg["speaker"],
                "start": seg["start"],
                "end": seg["end"],
                "pitch": float(pitch),
                "energy": energy,
                "tempo": float(tempo),
            })

        print(f"ðŸŽ›ï¸ [AudioFeatureExtractor] {len(features)}ê°œ ë°œí™” audio íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ")
        return features


# ===============================================================
# 6) ContentValidator (í…ìŠ¤íŠ¸ ì „ìš©)
# ===============================================================
@dataclass
class ContentValidator:
    """
    í…ìŠ¤íŠ¸ ì „ìš© í›„ì²˜ë¦¬ (í•„ìš”í•˜ë©´ ì¶”ê°€ ê·œì¹™ ì ìš© ê°€ëŠ¥)
    """
    def validate(self, df: pd.DataFrame) -> pd.DataFrame:
        # í˜„ìž¬ëŠ” ê·¸ëŒ€ë¡œ pass
        return df
    
    def _parse_batch_response(self, response: str, original_batch: List[str]) -> List[str]:
        """ë°°ì¹˜ ì‘ë‹µì—ì„œ ê°œë³„ ë¬¸ìž¥ ì¶”ì¶œ"""
        lines = response.strip().split('\n')
        cleaned_batch = []
        
        for i, original in enumerate(original_batch, 1):
            # ë²ˆí˜¸ë¡œ ì‹œìž‘í•˜ëŠ” ë¼ì¸ ì°¾ê¸°
            found = False
            for line in lines:
                if line.strip().startswith(f"{i}."):
                    cleaned_text = line.strip()[2:].strip()  # "1. " ì œê±°
                    cleaned_batch.append(cleaned_text)
                    found = True
                    break
            
            if not found:
                # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš©
                cleaned_batch.append(original)
        
        return cleaned_batch


# ===============================================================
# 7) ContentMerger (text + audio features)
# ===============================================================
@dataclass
class ContentMerger:
    """
    audio_features ë¥¼ speaker-match ê¸°ë°˜ìœ¼ë¡œ dfì— merge
    """

    def merge(self, text_df: pd.DataFrame, audio_features: Optional[List[Dict]]) -> pd.DataFrame:

        df = text_df.copy()
        df["pitch"] = None
        df["energy"] = None
        df["tempo"] = None

        if audio_features:
            for feat in audio_features:
                spk = feat["speaker"]

                # í•´ë‹¹ speakerì˜ ì²« ë²ˆì§¸ ë°œí™”ì— ë¶™ì´ê¸°
                idx_list = df.index[df["speaker"] == spk].tolist()
                if not idx_list:
                    continue

                first_idx = idx_list[0]
                df.at[first_idx, "pitch"] = feat["pitch"]
                df.at[first_idx, "energy"] = feat["energy"]
                df.at[first_idx, "tempo"] = feat["tempo"]

        return df


# ===============================================================
# ExceptionHandler
# ===============================================================
@dataclass
class ExceptionHandler:
    def handle(self, err: Exception) -> Dict[str, Any]:
        return {"status": "error", "error": str(err)}

