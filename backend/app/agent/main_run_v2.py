# ============================================
# app/agent/main_run_new.py  (ğŸ†• NEW)
# Cleaner â†’ Analysisë§Œ ì‹¤í–‰í•˜ëŠ” ì „ìš© ëŸ°ë„ˆ
# ============================================

import json
import pandas as pd
from sqlalchemy.orm import Session

from app.core.database import SessionLocal
from app.agent.crud import get_conversation_file_by_conv_id
from app.agent.Cleaner.graph_cleaner import CleanerGraph
from app.agent.Analysis.graph_analysis import AnalysisGraph
from dotenv import load_dotenv
load_dotenv()


# ============================================
# âœ” DataFrame ë³€í™˜ í•¨ìˆ˜
# ============================================
def segments_to_dataframe(segments, speaker_names, user_ids):
    rows = []

    for seg in segments:
        spk = seg["speaker"]
        text = seg["text"]

        # 1) ì‚¬ìš©ì ë³¸ì¸ user_id ë§¤í•‘
        if spk in user_ids:
            speaker_id = user_ids[spk]   # int ê·¸ëŒ€ë¡œ
        else:
            # 2) ì‚¬ìš©ì ì™¸ ë‹¤ë¥¸ í™”ìëŠ” ì´ë¦„ ë˜ëŠ” speaker label ì‚¬ìš©
            #    (ì´ë¦„ ìš°ì„ )
            speaker_id = speaker_names.get(spk, spk)

        rows.append({
            "speaker": speaker_id,    # ìˆ«ì or ì´ë¦„
            "text": text
        })

    return pd.DataFrame(rows)



# ============================================
# âœ” ì‹¤í–‰ í•¨ìˆ˜
# ============================================
def run_cleaner_analysis(conv_id: str, user_id: int):
    db: Session = SessionLocal()

    # 1. DBì—ì„œ conversation_file ë¶ˆëŸ¬ì˜¤ê¸°
    file_row = get_conversation_file_by_conv_id(db, conv_id)
    if not file_row:
        raise RuntimeError(f"[ERROR] conv_id={conv_id} ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    speaker_segments = file_row.get("speaker_segments")
    speaker_mapping = file_row.get("speaker_mapping")

    if speaker_segments is None:
        raise RuntimeError("speaker_segments ê°€ DBì— ì—†ìŠµë‹ˆë‹¤.")

    if speaker_mapping is None:
        speaker_mapping = {}

    # JSON í•„ë“œ íŒŒì‹±
    if isinstance(speaker_segments, str):
        speaker_segments = json.loads(speaker_segments)

    if isinstance(speaker_mapping, str):
        speaker_mapping = json.loads(speaker_mapping)

    # 2. segments ê¸°ë°˜ DF ìƒì„±
    conversation_df = segments_to_dataframe(
        segments=speaker_segments,
        speaker_names=speaker_mapping.get("speaker_names", {}),
        user_ids=speaker_mapping.get("user_ids", {})
    )

    print("\nğŸ“„ [DEBUG] ìƒì„±ëœ conversation_df")
    print(conversation_df)

    # 3. Cleaner ì‹¤í–‰
    print("\nğŸ§¹ Running Cleaner...")
    cleaner = CleanerGraph(verbose=True)

    cleaner_state = cleaner.run(
        db=db,
        conv_id=conv_id,
        conversation_df=conversation_df
    )

    # cleaner_state.merged_df ì‚¬ìš©
    cleaned_df = cleaner_state.get("merged_df")

    print("\nğŸ§¼ [CLEANED DF]")
    print(cleaned_df)

    # 4. Analysis ì‹¤í–‰
    print("\nğŸ” Running Analysis...")
    analysis = AnalysisGraph(verbose=True)
    analysis_state = analysis.run(
        db=db,
        conversation_df=cleaned_df,
        audio_features=cleaner_state.get("audio_features"),
        id=user_id,
        conv_id=conv_id
    )

    print("\nğŸ“Š [ANALYSIS RESULT]")
    print({
        "analysis_id": analysis_state.meta.get("analysis_id"),
        "conv_id": conv_id,
        "id": user_id,
        "statistics": analysis_state.statistics,
        "style_analysis": analysis_state.style_analysis,
        "summary": analysis_state.summary,
        "temperature_score": analysis_state.temperature_score,
        "validated": analysis_state.validated,
    })

    return analysis_state



# ============================================
# CLI ì‹¤í–‰
# ============================================
if __name__ == "__main__":
    TEST_CONV_ID = "7dfbcb88-e175-4233-898d-aa78bb94f970"
    TEST_USER_ID = 1

    run_cleaner_analysis(TEST_CONV_ID, TEST_USER_ID)
